# Introduction



## What are Agents?

Agents are autonomous programs that use language models to achieve tasks. They solve problems by running tools, accessing knowledge and memory to improve responses.

Instead of a rigid binary definition, let's think of Agents in terms of agency and autonomy.

* **Level 0**: Agents with no tools (basic inference tasks).
* **Level 1**: Agents with tools for autonomous task execution.
* **Level 2**: Agents with knowledge, combining memory and reasoning.
* **Level 3**: Teams of agents collaborating on complex workflows.

<img height="200" src="https://mintlify.s3.us-west-1.amazonaws.com/agno/images/agent.png" style={{ borderRadius: '8px' }} />

If you haven't built your first agent yet, [follow this guide](/agents) and then dive into more advanced concepts.

## Example: Research Agent

Let's create a research agent that can search the web using DuckDuckGo, scrape the top links using Newspaper4k and write a research report for us. Ideally we'll use specialized tools (like Exa) but let's start with the free tools first.

<Note>
  The description and instructions are converted to the system message and the input is passed as the user message. Set `debug_mode=True` to view logs behind the scenes.
</Note>

<Steps>
  <Step title="Create Research Agent">
    Create a file `research_agent.py`

    ```python research_agent.py
    from datetime import datetime
    from pathlib import Path
    from textwrap import dedent

    from agno.agent import Agent
    from agno.models.openai import OpenAIChat
    from agno.tools.exa import ExaTools

    today = datetime.now().strftime("%Y-%m-%d")

    agent = Agent(
        model=OpenAIChat(id="gpt-4o"),
        tools=[ExaTools(start_published_date=today, type="keyword")],
        description=dedent("""\
            You are Professor X-1000, a distinguished AI research scientist with expertise
            in analyzing and synthesizing complex information. Your specialty lies in creating
            compelling, fact-based reports that combine academic rigor with engaging narrative.

            Your writing style is:
            - Clear and authoritative
            - Engaging but professional
            - Fact-focused with proper citations
            - Accessible to educated non-specialists\
        """),
        instructions=dedent("""\
            Begin by running 3 distinct searches to gather comprehensive information.
            Analyze and cross-reference sources for accuracy and relevance.
            Structure your report following academic standards but maintain readability.
            Include only verifiable facts with proper citations.
            Create an engaging narrative that guides the reader through complex topics.
            End with actionable takeaways and future implications.\
        """),
        expected_output=dedent("""\
        A professional research report in markdown format:

        # {Compelling Title That Captures the Topic's Essence}

        ## Executive Summary
        {Brief overview of key findings and significance}

        ## Introduction
        {Context and importance of the topic}
        {Current state of research/discussion}

        ## Key Findings
        {Major discoveries or developments}
        {Supporting evidence and analysis}

        ## Implications
        {Impact on field/society}
        {Future directions}

        ## Key Takeaways
        - {Bullet point 1}
        - {Bullet point 2}
        - {Bullet point 3}

        ## References
        - [Source 1](link) - Key finding/quote
        - [Source 2](link) - Key finding/quote
        - [Source 3](link) - Key finding/quote

        ---
        Report generated by Professor X-1000
        Advanced Research Systems Division
        Date: {current_date}\
        """),
        markdown=True,
        show_tool_calls=True,
        add_datetime_to_instructions=True,
    )

    # Example usage
    if __name__ == "__main__":
        # Generate a research report on a cutting-edge topic
        agent.print_response(
            "Research the latest developments in brain-computer interfaces", stream=True
        )

    # More example prompts to try:
    """
    Try these research topics:
    1. "Analyze the current state of solid-state batteries"
    2. "Research recent breakthroughs in CRISPR gene editing"
    3. "Investigate the development of autonomous vehicles"
    4. "Explore advances in quantum machine learning"
    5. "Study the impact of artificial intelligence on healthcare"
    """
    ```
  </Step>

  <Step title="Run the agent">
    Install libraries

    ```shell
    pip install openai exa-py agno
    ```

    Run the agent

    ```shell
    python research_agent.py
    ```
  </Step>
</Steps>


# Knowledge



**Agents use knowledge to supplement their training data with domain expertise**.

Knowledge is stored in a vector database and provides agents with business context at query time, helping them respond in a context-aware manner. The general syntax is:

```python
from agno.agent import Agent, AgentKnowledge

# Create a knowledge base for the Agent
knowledge_base = AgentKnowledge(vector_db=...)

# Add information to the knowledge base
knowledge_base.load_text("The sky is blue")

# Add the knowledge base to the Agent and
# give it a tool to search the knowledge base as needed
agent = Agent(knowledge=knowledge_base, search_knowledge=True)
```

You can give your agent access to your knowledge base in the following ways:

* You can set `search_knowledge=True` to provide a `search_knowledge_base()` tool to your agent. This is automatically added if you provide a knowledgebase.
* You can set `add_references=True` to automatically add references from the knowledge base. Optionally pass your own `retriever` callable with the following signature:

```
def retriever(agent: Agent, query: str, num_documents: Optional[int], **kwargs) -> Optional[list[dict]]:
  ...
```

* You can set `update_knowledge=True` to provide a `add_to_knowledge()` tool to your agent allowing it to update the knowledgebase.

## Vector Databases

While any type of storage can act as a knowledge base, vector databases offer the best solution for retrieving relevant results from dense information quickly. Here's how vector databases are used with Agents:

<Steps>
  <Step title="Chunk the information">
    Break down the knowledge into smaller chunks to ensure our search query
    returns only relevant results.
  </Step>

  <Step title="Load the knowledge base">
    Convert the chunks into embedding vectors and store them in a vector
    database.
  </Step>

  <Step title="Search the knowledge base">
    When the user sends a message, we convert the input message into an
    embedding and "search" for nearest neighbors in the vector database.
  </Step>
</Steps>

## Example: RAG Agent with a PDF Knowledge Base

Let's build a **RAG Agent** that answers questions from a PDF.

### Step 1: Run PgVector

Let's use `PgVector` as our vector db as it can also provide storage for our Agents.

Install [docker desktop](https://docs.docker.com/desktop/install/mac-install/) and run **PgVector** on port **5532** using:

```bash
docker run -d \
  -e POSTGRES_DB=ai \
  -e POSTGRES_USER=ai \
  -e POSTGRES_PASSWORD=ai \
  -e PGDATA=/var/lib/postgresql/data/pgdata \
  -v pgvolume:/var/lib/postgresql/data \
  -p 5532:5432 \
  --name pgvector \
  agno/pgvector:16
```

### Step 2: Traditional RAG

Retrieval Augmented Generation (RAG) means **"stuffing the prompt with relevant information"** to improve the model's response. This is a 2 step process:

1. Retrieve relevant information from the knowledge base.
2. Augment the prompt to provide context to the model.

Let's build a **traditional RAG** Agent that answers questions from a PDF of recipes.

<Steps>
  <Step title="Install libraries">
    Install the required libraries using pip

    <CodeGroup>
      ```bash Mac
      pip install -U pgvector pypdf "psycopg[binary]" sqlalchemy
      ```

      ```bash Windows
      pip install -U pgvector pypdf "psycopg[binary]" sqlalchemy
      ```
    </CodeGroup>
  </Step>

  <Step title="Create a Traditional RAG Agent">
    Create a file `traditional_rag.py` with the following contents

    ```python traditional_rag.py
    from agno.agent import Agent
    from agno.models.openai import OpenAIChat
    from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
    from agno.vectordb.pgvector import PgVector, SearchType

    db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
    knowledge_base = PDFUrlKnowledgeBase(
        # Read PDF from this URL
        urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
        # Store embeddings in the `ai.recipes` table
        vector_db=PgVector(table_name="recipes", db_url=db_url, search_type=SearchType.hybrid),
    )
    # Load the knowledge base: Comment after first run
    knowledge_base.load(upsert=True)

    agent = Agent(
        model=OpenAIChat(id="gpt-4o"),
        knowledge=knowledge_base,
        # Enable RAG by adding references from AgentKnowledge to the user prompt.
        add_references=True,
        # Set as False because Agents default to `search_knowledge=True`
        search_knowledge=False,
        markdown=True,
        # debug_mode=True,
    )
    agent.print_response("How do I make chicken and galangal in coconut milk soup")
    ```
  </Step>

  <Step title="Run the agent">
    Run the agent (it takes a few seconds to load the knowledge base).

    <CodeGroup>
      ```bash Mac
      python traditional_rag.py
      ```

      ```bash Windows
      python traditional_rag.py
      ```
    </CodeGroup>

    <br />
  </Step>
</Steps>

<Accordion title="How to use local PDFs" icon="file-pdf" iconType="duotone">
  If you want to use local PDFs, use a `PDFKnowledgeBase` instead

  ```python agent.py
  from agno.knowledge.pdf import PDFKnowledgeBase

  ...
  knowledge_base = PDFKnowledgeBase(
      path="data/pdfs",
      vector_db=PgVector(
          table_name="pdf_documents",
          db_url=db_url,
      ),
  )
  ...
  ```
</Accordion>

### Step 3: Agentic RAG

With traditional RAG above, `add_references=True` always adds information from the knowledge base to the prompt, regardless of whether it is relevant to the question or helpful.

With Agentic RAG, we let the Agent decide **if** it needs to access the knowledge base and what search parameters it needs to query the knowledge base.

Set `search_knowledge=True` and `read_chat_history=True`, giving the Agent tools to search its knowledge and chat history on demand.

<Steps>
  <Step title="Create an Agentic RAG Agent">
    Create a file `agentic_rag.py` with the following contents

    ```python agentic_rag.py
    from agno.agent import Agent
    from agno.models.openai import OpenAIChat
    from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
    from agno.vectordb.pgvector import PgVector, SearchType

    db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
    knowledge_base = PDFUrlKnowledgeBase(
        urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
        vector_db=PgVector(table_name="recipes", db_url=db_url, search_type=SearchType.hybrid),
    )
    # Load the knowledge base: Comment out after first run
    knowledge_base.load(upsert=True)

    agent = Agent(
        model=OpenAIChat(id="gpt-4o"),
        knowledge=knowledge_base,
        # Add a tool to search the knowledge base which enables agentic RAG.
        search_knowledge=True,
        # Add a tool to read chat history.
        read_chat_history=True,
        show_tool_calls=True,
        markdown=True,
        # debug_mode=True,
    )
    agent.print_response("How do I make chicken and galangal in coconut milk soup", stream=True)
    agent.print_response("What was my last question?", markdown=True)
    ```
  </Step>

  <Step title="Run the agent">
    Run the agent

    <CodeGroup>
      ```bash Mac
      python agentic_rag.py
      ```

      ```bash Windows
      python agentic_rag.py
      ```
    </CodeGroup>

    <Note>
      Notice how it searches the knowledge base and chat history when needed
    </Note>
  </Step>
</Steps>

## Attributes

| Parameter                  | Type                                  | Default | Description                                                                                                                                                                                                 |
| -------------------------- | ------------------------------------- | ------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `knowledge`                | `AgentKnowledge`                      | `None`  | Provides the knowledge base used by the agent.                                                                                                                                                              |
| `search_knowledge`         | `bool`                                | `True`  | Adds a tool that allows the Model to search the knowledge base (aka Agentic RAG). Enabled by default when `knowledge` is provided.                                                                          |
| `add_references`           | `bool`                                | `False` | Enable RAG by adding references from AgentKnowledge to the user prompt.                                                                                                                                     |
| `retriever`                | `Callable[..., Optional[list[dict]]]` | `None`  | Function to get context to add to the user message. This function is called when add\_references is True.                                                                                                   |
| `context_format`           | `Literal['json', 'yaml']`             | `json`  | Specifies the format for RAG, either "json" or "yaml".                                                                                                                                                      |
| `add_context_instructions` | `bool`                                | `False` | If True, add instructions for using the context to the system prompt (if knowledge is also provided). For example: add an instruction to prefer information from the knowledge base over its training data. |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/agent_concepts/knowledge)


# Memory



Agno provides 3 types of memory for Agents:

1. **Chat History:** The message history of the session. Agno will store the sessions in a database for you, and retrieve them when you resume a session.
2. **User Memories:** Notes and insights about the user, this helps the model personalize the response to the user.
3. **Summaries:** A summary of the conversation, which is added to the prompt when chat history gets too long.

Before we dive in, let's understand the terminology:

* **Session:** Each conversation with an Agent is called a **session**. Sessions are identified by a `session_id`.
* **Run:** Every interaction (i.e. chat) within a session is called a **run**. Runs are identified by a `run_id`.
* **Messages:** are the individual messages sent to and received from the model. They have a `role` (`system`, `user` or `assistant`) and `content`.

<Tip>
  **Sessions** are equivalent to **threads** in the OpenAI Assistant API.
</Tip>

## Built-in Memory

Every Agent comes with built-in memory that can be used to access the historical **runs** and **messages**. Access it using `agent.memory`

<Expandable title="AgentMemory">
  <ResponseField name="runs" type="list[AgentRun]">
    The list of runs between the user and agent. Each run contains the input message and output response.
  </ResponseField>

  <ResponseField name="messages" type="list[Message]">
    The full list of messages sent to the model, including system prompt, tool calls etc.
  </ResponseField>
</Expandable>

You can give your agent access to memory in the following ways:

* You can set `add_history_to_messages=True` and `num_history_responses=5` to add the previous 5 messages automatically to every message sent to the agent.
* You can set `read_chat_history=True` to provide a `get_chat_history()` tool to your agent allowing it to read any message in the entire chat history.
* You can set `read_tool_call_history=True` to provide a `get_tool_call_history()` tool to your agent allowing it to read tool calls in reverse chronological order.

### Example

```python agent_memory.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from rich.pretty import pprint

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    # Set add_history_to_messages=true to add the previous chat history to the messages sent to the Model.
    add_history_to_messages=True,
    # Number of historical responses to add to the messages.
    num_history_responses=3,
    description="You are a helpful assistant that always responds in a polite, upbeat and positive manner.",
)

# -*- Create a run
agent.print_response("Share a 2 sentence horror story", stream=True)
# -*- Print the messages in the memory
pprint([m.model_dump(include={"role", "content"}) for m in agent.memory.messages])

# -*- Ask a follow up question that continues the conversation
agent.print_response("What was my first message?", stream=True)
# -*- Print the messages in the memory
pprint([m.model_dump(include={"role", "content"}) for m in agent.memory.messages])
```

## Persistent Memory

The built-in memory only lasts while the session is active. To persist memory across sessions, we can store Agent sessions in a database using `AgentStorage`.

Storage is a necessary component when building user facing AI products as any production application will require users to be able to "continue" their conversation with the Agent.

Let's test this out, create a file `persistent_memory.py` with the following code:

```python persistent_memory.py
import json

from rich.console import Console
from rich.panel import Panel
from rich.json import JSON

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.storage.agent.sqlite import SqliteAgentStorage

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    # Store agent sessions in a database
    storage=SqliteAgentStorage(table_name="agent_sessions", db_file="tmp/agent_storage.db"),
    # Set add_history_to_messages=true to add the previous chat history to the messages sent to the Model.
    add_history_to_messages=True,
    # Number of historical responses to add to the messages.
    num_history_responses=3,
    # The session_id is used to identify the session in the database
    # You can resume any session by providing a session_id
    # session_id="xxxx-xxxx-xxxx-xxxx",
    # Description creates a system prompt for the agent
    description="You are a helpful assistant that always responds in a polite, upbeat and positive manner.",
)

console = Console()

def print_chat_history(agent):
    # -*- Print history
    console.print(
        Panel(
            JSON(json.dumps([m.model_dump(include={"role", "content"}) for m in agent.memory.messages]), indent=4),
            title=f"Chat History for session_id: {agent.session_id}",
            expand=True,
        )
    )


# -*- Create a run
agent.print_response("Share a 2 sentence horror story", stream=True)
# -*- Print the chat history
print_chat_history(agent)

# -*- Ask a follow up question that continues the conversation
agent.print_response("What was my first message?", stream=True)
# -*- Print the chat history
print_chat_history(agent)
```

### Run the agent

Install dependencies and run the agent:

```shell
pip install openai sqlalchemy agno

python persistent_memory.py
```

You can view the agent sessions in the sqlite database and continue any conversation by providing the same `session_id`.

Read more in the [storage](/agents/storage) section.

## User preferences and conversation summaries

Along with storing chat history and run messages, `AgentMemory` can be extended to automatically classify and store user preferences and conversation summaries.

To do this, add a `db` to `AgentMemory` and set `create_user_memories=True` and `create_session_summary=True`

User memories are stored in the `AgentMemory` whereas session summaries are stored in the `AgentStorage` table with the rest of the session information.

<Note>
  User preferences and conversation summaries are currently only compatible with
  `OpenAI` and `OpenAILike` models. While Persistent Memory is compatible with
  all model providers.
</Note>

## Example

```python personalized_memories_and_summaries.py
from rich.pretty import pprint

from agno.agent import Agent, AgentMemory
from agno.models.openai import OpenAIChat
from agno.memory.db.postgres import PgMemoryDb
from agno.storage.agent.postgres import PostgresAgentStorage

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    # Store the memories and summary in a database
    memory=AgentMemory(
        db=PgMemoryDb(table_name="agent_memory", db_url=db_url), create_user_memories=True, create_session_summary=True
    ),
    # Store agent sessions in a database
    storage=PostgresAgentStorage(table_name="personalized_agent_sessions", db_url=db_url),
    # Show debug logs so you can see the memory being created
    # debug_mode=True,
)

# -*- Share personal information
agent.print_response("My name is john billings?", stream=True)
# -*- Print memories
pprint(agent.memory.memories)
# -*- Print summary
pprint(agent.memory.summary)

# -*- Share personal information
agent.print_response("I live in nyc?", stream=True)
# -*- Print memories
pprint(agent.memory.memories)
# -*- Print summary
pprint(agent.memory.summary)

# -*- Share personal information
agent.print_response("I'm going to a concert tomorrow?", stream=True)
# -*- Print memories
pprint(agent.memory.memories)
# -*- Print summary
pprint(agent.memory.summary)

# Ask about the conversation
agent.print_response("What have we been talking about, do you know my name?", stream=True)
```

## Attributes

| Parameter                          | Type          | Default         | Description                                                                                                     |
| ---------------------------------- | ------------- | --------------- | --------------------------------------------------------------------------------------------------------------- |
| `memory`                           | `AgentMemory` | `AgentMemory()` | Agent's memory object used for storing and retrieving information.                                              |
| `add_history_to_messages`          | `bool`        | `False`         | If true, adds the chat history to the messages sent to the Model. Also known as `add_chat_history_to_messages`. |
| `num_history_responses`            | `int`         | `3`             | Number of historical responses to add to the messages.                                                          |
| `create_user_memories`             | `bool`        | `False`         | If true, create and store personalized memories for the user.                                                   |
| `update_user_memories_after_run`   | `bool`        | `True`          | If true, update memories for the user after each run.                                                           |
| `create_session_summary`           | `bool`        | `False`         | If true, create and store session summaries.                                                                    |
| `update_session_summary_after_run` | `bool`        | `True`          | If true, update session summaries after each run.                                                               |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/agent_concepts/memory)


# Multimodal Agents



Agno agents support text, image, audio and video inputs and can generate text, image, audio and video outputs. For a complete overview, please checkout the [compatibility matrix](/models/compatibility).

## Multimodal inputs to an agent

Let's create an agent that can understand images and make tool calls as needed

### Image Agent

```python image_agent.py
from agno.agent import Agent
from agno.media import Image
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

agent.print_response(
    "Tell me about this image and give me the latest news about it.",
    images=[
        Image(
            url="https://upload.wikimedia.org/wikipedia/commons/0/0c/GoldenGateBridge-001.jpg"
        )
    ],
    stream=True,
)
```

Run the agent:

```shell
python image_agent.py
```

Similar to images, you can also use audio and video as an input.

### Audio Agent

```python audio_agent.py
import base64

import requests
from agno.agent import Agent, RunResponse  # noqa
from agno.media import Audio
from agno.models.openai import OpenAIChat

# Fetch the audio file and convert it to a base64 encoded string
url = "https://openaiassets.blob.core.windows.net/$web/API/docs/audio/alloy.wav"
response = requests.get(url)
response.raise_for_status()
wav_data = response.content

agent = Agent(
    model=OpenAIChat(id="gpt-4o-audio-preview", modalities=["text"]),
    markdown=True,
)
agent.print_response(
    "What is in this audio?", audio=[Audio(content=wav_data, format="wav")]
)
```

### Video Agent

<Note>Currently Agno only supports video as an input for Gemini models.</Note>

```python video_agent.py
from pathlib import Path

from agno.agent import Agent
from agno.media import Video
from agno.models.google import Gemini

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp"),
    markdown=True,
)

# Please download "GreatRedSpot.mp4" using
# wget https://storage.googleapis.com/generativeai-downloads/images/GreatRedSpot.mp4
video_path = Path(__file__).parent.joinpath("GreatRedSpot.mp4")

agent.print_response("Tell me about this video", videos=[Video(filepath=video_path)])
```

## Multimodal outputs from an agent

Similar to providing multimodal inputs, you can also get multimodal outputs from an agent.

### Image Generation

The following example demonstrates how to generate an image using DALL-E with an agent.

```python image_agent.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.dalle import DalleTools

image_agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    tools=[DalleTools()],
    description="You are an AI agent that can generate images using DALL-E.",
    instructions="When the user asks you to create an image, use the `create_image` tool to create the image.",
    markdown=True,
    show_tool_calls=True,
)

image_agent.print_response("Generate an image of a white siamese cat")

images = image_agent.get_images()
if images and isinstance(images, list):
    for image_response in images:
        image_url = image_response.url
        print(image_url)
```

### Audio Response

The following example demonstrates how to obtain both text and audio responses from an agent. The agent will respond with text and audio bytes that can be saved to a file.

```python audio_agent.py
from agno.agent import Agent, RunResponse
from agno.models.openai import OpenAIChat
from agno.utils.audio import write_audio_to_file

agent = Agent(
    model=OpenAIChat(
        id="gpt-4o-audio-preview",
        modalities=["text", "audio"],
        audio={"voice": "alloy", "format": "wav"},
    ),
    markdown=True,
)
response: RunResponse = agent.run("Tell me a 5 second scary story")

# Save the response audio to a file
if response.response_audio is not None:
    write_audio_to_file(
        audio=agent.run_response.response_audio.content, filename="tmp/scary_story.wav"
    )
```

## Multimodal inputs and outputs together

You can create Agents that can take multimodal inputs and return multimodal outputs. The following example demonstrates how to provide a combination of audio and text inputs to an agent and obtain both text and audio outputs.

### Audio input and Audio output

```python audio_agent.py
import base64

import requests
from agno.agent import Agent
from agno.media import Audio
from agno.models.openai import OpenAIChat
from agno.utils.audio import write_audio_to_file

# Fetch the audio file and convert it to a base64 encoded string
url = "https://openaiassets.blob.core.windows.net/$web/API/docs/audio/alloy.wav"
response = requests.get(url)
response.raise_for_status()
wav_data = response.content

agent = Agent(
    model=OpenAIChat(
        id="gpt-4o-audio-preview",
        modalities=["text", "audio"],
        audio={"voice": "alloy", "format": "wav"},
    ),
    markdown=True,
)

agent.run("What's in these recording?", audio=[Audio(content=wav_data, format="wav")])

if agent.run_response.response_audio is not None:
    write_audio_to_file(
        audio=agent.run_response.response_audio.content, filename="tmp/result.wav"
    )
```


# Prompts



We prompt Agents using `description` and `instructions` and a number of other settings. These settings are used to build the **system** message that is sent to the language model.

Understanding how these prompts are created will help you build better Agents.

The 2 key parameters are:

1. **Description**: A description that guides the overall behaviour of the agent.
2. **Instructions**: A list of precise, task-specific instructions on how to achieve its goal.

<Note>
  Description and instructions only provide a formatting benefit, we do not alter or abstract any information and you can always set the `system_message` to provide your own system prompt.
</Note>

## System message

The system message is created using `description`, `instructions` and a number of other settings. The `description` is added to the start of the system message and `instructions` are added as a list after `Instructions`. For example:

```python instructions.py
from agno.agent import Agent

agent = Agent(
    description="You are a famous short story writer asked to write for a magazine",
    instructions=["You are a pilot on a plane flying from Hawaii to Japan."],
    markdown=True,
    debug_mode=True,
)
agent.print_response("Tell me a 2 sentence horror story.", stream=True)
```

Will translate to (set `debug_mode=True` to view the logs):

```js
DEBUG    ============== system ==============
DEBUG    You are a famous short story writer asked to write for a magazine

         ## Instructions
         - You are a pilot on a plane flying from Hawaii to Japan.
         - Use markdown to format your answers.
DEBUG    ============== user ==============
DEBUG    Tell me a 2 sentence horror story.
DEBUG    ============== assistant ==============
DEBUG    As the autopilot disengaged inexplicably mid-flight over the Pacific, the pilot glanced at the copilot's seat
         only to find it empty despite his every recall of a full crew boarding. Hands trembling, he looked into the
         cockpit's rearview mirror and found his own reflection grinning back with blood-red eyes, whispering,
         "There's no escape, not at 30,000 feet."
DEBUG    **************** METRICS START ****************
DEBUG    * Time to first token:         0.4518s
DEBUG    * Time to generate response:   1.2594s
DEBUG    * Tokens per second:           63.5243 tokens/s
DEBUG    * Input tokens:                59
DEBUG    * Output tokens:               80
DEBUG    * Total tokens:                139
DEBUG    * Prompt tokens details:       {'cached_tokens': 0}
DEBUG    * Completion tokens details:   {'reasoning_tokens': 0}
DEBUG    **************** METRICS END ******************
```

## Set the system message directly

You can manually set the system message using the `system_message` parameter.

```python
from agno.agent import Agent

agent = Agent(system_message="Share a 2 sentence story about")
agent.print_response("Love in the year 12000.")
```

## User message

The input `message` sent to the `Agent.run()` or `Agent.print_response()` functions is used as the user message.

## Default system message

The Agent creates a default system message that can be customized using the following parameters:

| Parameter                      | Type             | Default  | Description                                                                                                                                                             |
| ------------------------------ | ---------------- | -------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `description`                  | `str`            | `None`   | A description of the Agent that is added to the start of the system message.                                                                                            |
| `task`                         | `str`            | `None`   | Describe the task the agent should achieve.                                                                                                                             |
| `instructions`                 | `List[str]`      | `None`   | List of instructions added to the system prompt in `<instructions>` tags. Default instructions are also created depending on values for `markdown`, `output_model` etc. |
| `additional_context`           | `str`            | `None`   | Additional context added to the end of the system message.                                                                                                              |
| `expected_output`              | `str`            | `None`   | Provide the expected output from the Agent. This is added to the end of the system message.                                                                             |
| `extra_instructions`           | `List[str]`      | `None`   | List of extra instructions added to the default system prompt. Use these when you want to add some extra instructions at the end of the default instructions.           |
| `prevent_hallucinations`       | `bool`           | `False`  | If True, add instructions to return "I don't know" when the agent does not know the answer.                                                                             |
| `prevent_prompt_injection`     | `bool`           | `False`  | If True, add instructions to prevent prompt injection attacks.                                                                                                          |
| `limit_tool_access`            | `bool`           | `False`  | If True, add instructions for limiting tool access to the default system prompt if tools are provided                                                                   |
| `markdown`                     | `bool`           | `False`  | Add an instruction to format the output using markdown.                                                                                                                 |
| `add_datetime_to_instructions` | `bool`           | `False`  | If True, add the current datetime to the prompt to give the agent a sense of time. This allows for relative times like "tomorrow" to be used in the prompt              |
| `system_prompt`                | `str`            | `None`   | System prompt: provide the system prompt as a string                                                                                                                    |
| `system_prompt_template`       | `PromptTemplate` | `None`   | Provide the system prompt as a PromptTemplate.                                                                                                                          |
| `use_default_system_message`   | `bool`           | `True`   | If True, build a default system message using agent settings and use that.                                                                                              |
| `system_message_role`          | `str`            | `system` | Role for the system message.                                                                                                                                            |

<Tip>
  Disable the default system message by setting `use_default_system_message=False`.
</Tip>

## Default user message

The Agent creates a default user message, which is either the input message or a message with the `context` if `enable_rag=True`. The default user message can be customized using:

| Parameter                  | Type                     | Default | Description                                                                                                                                                                                              |
| -------------------------- | ------------------------ | ------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `enable_rag`               | `bool`                   | `False` | Enable RAG by adding references from the knowledge base to the prompt.                                                                                                                                   |
| `add_rag_instructions`     | `bool`                   | `False` | If True, adds instructions for using the RAG to the system prompt (if knowledge is also provided). For example: add an instruction to prefer information from the knowledge base over its training data. |
| `add_history_to_messages`  | `bool`                   | `False` | If true, adds the chat history to the messages sent to the Model.                                                                                                                                        |
| `num_history_responses`    | `int`                    | `3`     | Number of historical responses to add to the messages.                                                                                                                                                   |
| `user_prompt`              | `Union[List, Dict, str]` | `None`  | Provide the user prompt as a string. Note: this will ignore the message sent to the run function.                                                                                                        |
| `user_prompt_template`     | `PromptTemplate`         | `None`  | Provide the user prompt as a PromptTemplate.                                                                                                                                                             |
| `use_default_user_message` | `bool`                   | `True`  | If True, build a default user prompt using references and chat history.                                                                                                                                  |
| `user_message_role`        | `str`                    | `user`  | Role for the user message.                                                                                                                                                                               |

<Tip>
  Disable the default user message by setting `use_default_user_message=False`.
</Tip>


# Reasoning



Reasoning is an **experimental feature** that enables an `Agent` to think through a problem step-by-step before jumping into a response. The Agent works through different ideas, validating and correcting as needed. Once it reaches a final answer, it will validate and provide a response. Let's give it a try. Create a file `reasoning_agent.py`

```python reasoning_agent.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

task = (
    "Three missionaries and three cannibals need to cross a river. "
    "They have a boat that can carry up to two people at a time. "
    "If, at any time, the cannibals outnumber the missionaries on either side of the river, the cannibals will eat the missionaries. "
    "How can all six people get across the river safely? Provide a step-by-step solution and show the solutions as an ascii diagram"
)

reasoning_agent = Agent(model=OpenAIChat(id="gpt-4o"), reasoning=True, markdown=True, structured_outputs=True)
reasoning_agent.print_response(task, stream=True, show_full_reasoning=True)
```

Run the Reasoning Agent:

```bash
pip install -U agno openai

export OPENAI_API_KEY=***

python reasoning_agent.py
```

Agno Agents can leverage **specialized reasoning models** alongside the primary Agent model. These models are dedicated to reasoning rather than handling the main Agent tasks. Their responses are appended as messages to the Agent, integrating into the message history sent to the primary Agent model.

Currently, Groq and DeepSeek models are supported for external reasoning. Below is an example `Agent` that uses a `Groq` model for reasoning but uses the `OpenAI` model for the main `Agent`.

```python groq_reasoning.py
from agno.agent import Agent
from agno.models.groq import Groq
from agno.models.openai import OpenAIChat

reasoning_agent = Agent(model=OpenAIChat(id="gpt-4o"), reasoning_model=Groq(id="deepseek-r1-distill-llama-70b"))
reasoning_agent.print_response(task, stream=True)
```

Run the Reasoning Agent:

```bash
pip install -U agno openai groq

export OPENAI_API_KEY=***
export GROQ_API_KEY=***

python groq_reasoning.py
```

## How to use reasoning

To add reasoning, set `reasoning=True` or set `reasoning_model` to a supported reasoning model. If you do not set `reasoning_model`, the primary `Agent` model will be used for reasoning.

```python deepseek_reasoning.py
from agno.models.openai import OpenAIChat
from agno.models.deepseek import DeepSeek

reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-4o-2024-08-06"),
    reasoning_model=DeepSeek(id="deepseek-reasoner"),
)
reasoning_agent.print_response("How many 'r' are in the word 'supercalifragilisticexpialidocious'?", stream=True)
```

```bash
pip install -U agno openai deepseek

export OPENAI_API_KEY=***
export DEEPSEEK_API_KEY=***

python deepseek_reasoning.py
```

## Reasoning with tools

You can also use tools with a reasoning agent. Lets create a finance agent that can reason.

```python finance_reasoning.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.yfinance import YFinanceTools

reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True, company_news=True)],
    instructions=["Use tables to show data"],
    show_tool_calls=True,
    markdown=True,
    reasoning=True,
)
reasoning_agent.print_response("Write a report comparing NVDA to TSLA", stream=True, show_full_reasoning=True)
```

Run the script to see the output.

```bash
pip install -U agno openai yfinance

export OPENAI_API_KEY=***

python finance_reasoning.py
```

## More reasoning examples

### Logical puzzles

```python logical_puzzle.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

task = (
    "Three missionaries and three cannibals need to cross a river. "
    "They have a boat that can carry up to two people at a time. "
    "If, at any time, the cannibals outnumber the missionaries on either side of the river, the cannibals will eat the missionaries. "
    "How can all six people get across the river safely? Provide a step-by-step solution and show the solutions as an ascii diagram"
)
reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-4o-2024-08-06"), reasoning=True, markdown=True, structured_outputs=True
)
reasoning_agent.print_response(task, stream=True, show_full_reasoning=True)
```

Run the script to see the output.

```bash
pip install -U agno openai

export OPENAI_API_KEY=***

python logical_puzzle.py
```

### Mathematical proofs

```python mathematical_proof.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

task = "Prove that for any positive integer n, the sum of the first n odd numbers is equal to n squared. Provide a detailed proof."
reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-4o-2024-08-06"), reasoning=True, markdown=True, structured_outputs=True
)
reasoning_agent.print_response(task, stream=True, show_full_reasoning=True)
```

Run the script to see the output.

```bash
pip install -U agno openai

export OPENAI_API_KEY=***

python mathematical_proof.py
```

### Scientific research

```python scientific_research.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

task = (
    "Read the following abstract of a scientific paper and provide a critical evaluation of its methodology,"
    "results, conclusions, and any potential biases or flaws:\n\n"
    "Abstract: This study examines the effect of a new teaching method on student performance in mathematics. "
    "A sample of 30 students was selected from a single school and taught using the new method over one semester. "
    "The results showed a 15% increase in test scores compared to the previous semester. "
    "The study concludes that the new teaching method is effective in improving mathematical performance among high school students."
)
reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-4o-2024-08-06"), reasoning=True, markdown=True, structured_outputs=True
)
reasoning_agent.print_response(task, stream=True, show_full_reasoning=True)
```

Run the script to see the output.

```bash
pip install -U agno openai

export OPENAI_API_KEY=***

python scientific_research.py
```

### Ethical dilemma

```python ethical_dilemma.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

task = (
    "You are a train conductor faced with an emergency: the brakes have failed, and the train is heading towards "
    "five people tied on the track. You can divert the train onto another track, but there is one person tied there. "
    "Do you divert the train, sacrificing one to save five? Provide a well-reasoned answer considering utilitarian "
    "and deontological ethical frameworks. "
    "Provide your answer also as an ascii art diagram."
)
reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-4o-2024-08-06"), reasoning=True, markdown=True, structured_outputs=True
)
reasoning_agent.print_response(task, stream=True, show_full_reasoning=True)
```

Run the script to see the output.

```bash
pip install -U agno openai

export OPENAI_API_KEY=***

python ethical_dilemma.py
```

### Planning an itinerary

```python planning_itinerary.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

task = "Plan an itinerary from Los Angeles to Las Vegas"
reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-4o-2024-08-06"), reasoning=True, markdown=True, structured_outputs=True
)
reasoning_agent.print_response(task, stream=True, show_full_reasoning=True)
```

Run the script to see the output.

```bash
pip install -U agno openai

export OPENAI_API_KEY=***

python planning_itinerary.py
```

### Creative writing

```python creative_writing.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

task = "Write a short story about life in 5000000 years"
reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-4o-2024-08-06"), reasoning=True, markdown=True, structured_outputs=True
)
reasoning_agent.print_response(task, stream=True, show_full_reasoning=True)
```

Run the script to see the output.

```bash
pip install -U agno openai

export OPENAI_API_KEY=***

python creative_writing.py
```

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/agent_concepts/reasoning)


# Agent.run()



Use the `Agent.run()` function to run the agent and return the response as a `RunResponse` object or a stream of `RunResponse` objects.

```python
from typing import Iterator
from agno.agent import Agent, RunResponse
from agno.models.openai import OpenAIChat
from agno.utils.pprint import pprint_run_response

agent = Agent(model=OpenAIChat(id="gpt-4o-mini"))

# Run agent and return the response as a variable
response: RunResponse = agent.run("Tell me a 5 second short story about a robot")
# Run agent and return the response as a stream
response_stream: Iterator[RunResponse] = agent.run("Tell me a 5 second short story about a lion", stream=True)

# Print the response in markdown format
pprint_run_response(response, markdown=True)
# Print the response stream in markdown format
pprint_run_response(response_stream, markdown=True)
```

<Note>
  Set `stream=True` to return a stream of `RunResponse` objects.
</Note>

## RunResponse

The `Agent.run()` function returns either a `RunResponse` object or an `Iterator[RunResponse]` when `stream=True`. It has the following attributes:

### RunResponse Attributes

| Attribute        | Type                   | Default                       | Description                                  |
| ---------------- | ---------------------- | ----------------------------- | -------------------------------------------- |
| `content`        | `Any`                  | `None`                        | Content of the response.                     |
| `content_type`   | `str`                  | `"str"`                       | Specifies the data type of the content.      |
| `context`        | `List[MessageContext]` | `None`                        | The context added to the response for RAG.   |
| `event`          | `str`                  | `RunEvent.run_response.value` | Event type of the response.                  |
| `event_data`     | `Dict[str, Any]`       | `None`                        | Data associated with the event.              |
| `messages`       | `List[Message]`        | `None`                        | A list of messages included in the response. |
| `metrics`        | `Dict[str, Any]`       | `None`                        | Usage metrics of the run.                    |
| `model`          | `str`                  | `None`                        | The model used in the run.                   |
| `run_id`         | `str`                  | `None`                        | Run Id.                                      |
| `agent_id`       | `str`                  | `None`                        | Agent Id for the run.                        |
| `session_id`     | `str`                  | `None`                        | Session Id for the run.                      |
| `tools`          | `List[Dict[str, Any]]` | `None`                        | List of tools provided to the model.         |
| `images`         | `List[Image]`          | `None`                        | List of images the model produced.           |
| `videos`         | `List[Video]`          | `None`                        | List of videos the model produced.           |
| `audio`          | `List[Audio]`          | `None`                        | List of audio snippets the model produced.   |
| `response_audio` | `ModelResponseAudio`   | `None`                        | The model's raw response in audio.           |
| `created_at`     | `int`                  | -                             | Unix timestamp of the response creation.     |


# Storage



**Agents use storage to persist sessions by storing them in a database.**

Agents come with built-in memory, but it only lasts while the session is active. To continue conversations across sessions, we store agent sessions in a database like Sqllite or PostgreSQL.

The general syntax for adding storage to an Agent looks like:

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.storage.agent.postgres import PostgresAgentStorage

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    storage=PostgresAgentStorage(table_name="agent_sessions", db_url="postgresql+psycopg://ai:ai@localhost:5532/ai"),
    tools=[DuckDuckGoTools()],
    show_tool_calls=True,
    add_history_to_messages=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
agent.print_response("Which country are we speaking about?")
```

## Example

<Steps>
  <Step title="Run Postgres">
    Install [docker desktop](https://docs.docker.com/desktop/install/mac-install/) and run **Postgres** on port **5532** using:

    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agno/pgvector:16
    ```
  </Step>

  <Step title="Create an Agent with Storage">
    Create a file `agent_with_storage.py` with the following contents

    ```python
    import typer
    from typing import Optional, List
    from agno.agent import Agent
    from agno.storage.agent.postgres import PostgresAgentStorage
    from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
    from agno.vectordb.pgvector import PgVector, SearchType

    db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
    knowledge_base = PDFUrlKnowledgeBase(
        urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
        vector_db=PgVector(table_name="recipes", db_url=db_url, search_type=SearchType.hybrid),
    )
    # Load the knowledge base: Comment after first run
    knowledge_base.load(upsert=True)
    storage = PostgresAgentStorage(table_name="pdf_agent", db_url=db_url)

    def pdf_agent(new: bool = False, user: str = "user"):
        session_id: Optional[str] = None

        if not new:
            existing_sessions: List[str] = storage.get_all_session_ids(user)
            if len(existing_sessions) > 0:
                session_id = existing_sessions[0]

        agent = Agent(
            session_id=session_id,
            user_id=user,
            knowledge=knowledge_base,
            storage=storage,
            # Show tool calls in the response
            show_tool_calls=True,
            # Enable the agent to read the chat history
            read_chat_history=True,
            # We can also automatically add the chat history to the messages sent to the model
            # But giving the model the chat history is not always useful, so we give it a tool instead
            # to only use when needed.
            # add_history_to_messages=True,
            # Number of historical responses to add to the messages.
            # num_history_responses=3,
        )
        if session_id is None:
            session_id = agent.session_id
            print(f"Started Session: {session_id}\n")
        else:
            print(f"Continuing Session: {session_id}\n")

        # Runs the agent as a cli app
        agent.cli_app(markdown=True)


    if __name__ == "__main__":
        typer.run(pdf_agent)
    ```
  </Step>

  <Step title="Run the agent">
    Install libraries

    <CodeGroup>
      ```bash Mac
      pip install -U agno openai pgvector pypdf "psycopg[binary]" sqlalchemy
      ```

      ```bash Windows
      pip install -U agno openai pgvector pypdf "psycopg[binary]" sqlalchemy
      ```
    </CodeGroup>

    Run the agent

    ```bash
    python agent_with_storage.py
    ```

    Now the agent continues across sessions. Ask a question:

    ```
    How do I make pad thai?
    ```

    Then message `bye` to exit, start the app again and ask:

    ```
    What was my last message?
    ```
  </Step>

  <Step title="Start a new run">
    Run the `agent_with_storage.py` file with the `--new` flag to start a new run.

    ```bash
    python agent_with_storage.py --new
    ```
  </Step>
</Steps>

## Params

| Parameter | Type                     | Default | Description                                     |
| --------- | ------------------------ | ------- | ----------------------------------------------- |
| `storage` | `Optional[AgentStorage]` | `None`  | Storage mechanism for the agent, if applicable. |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/agent_concepts/storage)


# Structured Output



One of our favorite features is using Agents to generate structured data (i.e. a pydantic model). Use this feature to extract features, classify data, produce fake data etc. The best part is that they work with function calls, knowledge bases and all other features.

## Example

Let's create an Movie Agent to write a `MovieScript` for us.

```python movie_agent.py
from typing import List
from rich.pretty import pprint
from pydantic import BaseModel, Field
from agno.agent import Agent, RunResponse
from agno.models.openai import OpenAIChat

class MovieScript(BaseModel):
    setting: str = Field(..., description="Provide a nice setting for a blockbuster movie.")
    ending: str = Field(..., description="Ending of the movie. If not available, provide a happy ending.")
    genre: str = Field(
        ..., description="Genre of the movie. If not available, select action, thriller or romantic comedy."
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(..., description="3 sentence storyline for the movie. Make it exciting!")

# Agent that uses JSON mode
json_mode_agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    description="You write movie scripts.",
    response_model=MovieScript,
)
# Agent that uses structured outputs
structured_output_agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    description="You write movie scripts.",
    response_model=MovieScript,
    structured_outputs=True,
)

# Get the response in a variable
# json_mode_response: RunResponse = json_mode_agent.run("New York")
# pprint(json_mode_response.content)
# structured_output_response: RunResponse = structured_output_agent.run("New York")
# pprint(structured_output_response.content)

json_mode_agent.print_response("New York")
structured_output_agent.print_response("New York")
```

Run the script to see the output.

```bash
pip install -U agno openai

python movie_agent.py
```

The output is an object of the `MovieScript` class, here's how it looks:

```python
# Using JSON mode
MovieScript(
│   setting='The bustling streets of New York City, filled with skyscrapers, secret alleyways, and hidden underground passages.',
│   ending='The protagonist manages to thwart an international conspiracy, clearing his name and winning the love of his life back.',
│   genre='Thriller',
│   name='Shadows in the City',
│   characters=['Alex Monroe', 'Eva Parker', 'Detective Rodriguez', 'Mysterious Mr. Black'],
│   storyline="When Alex Monroe, an ex-CIA operative, is framed for a crime he didn't commit, he must navigate the dangerous streets of New York to clear his name. As he uncovers a labyrinth of deceit involving the city's most notorious crime syndicate, he enlists the help of an old flame, Eva Parker. Together, they race against time to expose the true villain before it's too late."
)

# Use the structured output
MovieScript(
│   setting='In the bustling streets and iconic skyline of New York City.',
│   ending='Isabella and Alex, having narrowly escaped the clutches of the Syndicate, find themselves standing at the top of the Empire State Building. As the glow of the setting sun bathes the city, they share a victorious kiss. Newly emboldened and as an unstoppable duo, they vow to keep NYC safe from any future threats.',
│   genre='Action Thriller',
│   name='The NYC Chronicles',
│   characters=['Isabella Grant', 'Alex Chen', 'Marcus Kane', 'Detective Ellie Monroe', 'Victor Sinclair'],
│   storyline='Isabella Grant, a fearless investigative journalist, uncovers a massive conspiracy involving a powerful syndicate plotting to control New York City. Teaming up with renegade cop Alex Chen, they must race against time to expose the culprits before the city descends into chaos. Dodging danger at every turn, they fight to protect the city they love from imminent destruction.'
)
```

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/async/structured_output.py)


# Teams



We can combine multiple Agents to form a team and tackle tasks as a cohesive unit. Here's a simple example that uses a team of agents to write an article about the top stories on hackernews.

```python hackernews_team.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.hackernews import HackerNewsTools
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.newspaper4k import Newspaper4kTools

hn_researcher = Agent(
    name="HackerNews Researcher",
    model=OpenAIChat("gpt-4o"),
    role="Gets top stories from hackernews.",
    tools=[HackerNewsTools()],
)

web_searcher = Agent(
    name="Web Searcher",
    model=OpenAIChat("gpt-4o"),
    role="Searches the web for information on a topic",
    tools=[DuckDuckGoTools()],
    add_datetime_to_instructions=True,
)

article_reader = Agent(
    name="Article Reader",
    model=OpenAIChat("gpt-4o"),
    role="Reads articles from URLs.",
    tools=[Newspaper4kTools()],
)

hn_team = Agent(
    name="Hackernews Team",
    model=OpenAIChat("gpt-4o"),
    team=[hn_researcher, web_searcher, article_reader],
    instructions=[
        "First, search hackernews for what the user is asking about.",
        "Then, ask the article reader to read the links for the stories to get more information.",
        "Important: you must provide the article reader with the links to read.",
        "Then, ask the web searcher to search for each story to get more information.",
        "Finally, provide a thoughtful and engaging summary.",
    ],
    show_tool_calls=True,
    markdown=True,
)
hn_team.print_response("Write an article about the top 2 stories on hackernews", stream=True)
```

Run the script to see the output.

```bash
pip install -U openai duckduckgo-search newspaper4k lxml_html_clean agno

python hackernews_team.py
```

## How to build Agent Teams

1. Add a `name` and `role` parameter to the member Agents.
2. Create a Team Leader that can delegate tasks to team-members.
3. Use your Agent team just like you would use a regular Agent.

## Developer Resources

* View [Examples](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/teams/)


# Tools



**Agents use tools to take actions and interact with external systems**.

Tools are functions that an Agent can run to achieve tasks. For example: searching the web, running SQL, sending an email or calling APIs. You can use any python function as a tool or use a pre-built **toolkit**. The general syntax is:

```python
from agno.agent import Agent

agent = Agent(
    # Add functions or Toolkits
    tools=[...],
    # Show tool calls in the Agent response
    show_tool_calls=True
)
```

## Using a Toolkit

Agno provides many pre-built **toolkits** that you can add to your Agents. For example, let's use the DuckDuckGo toolkit to search the web.

<Tip>You can find more toolkits in the [Toolkits](/tools/toolkits) guide.</Tip>

<Steps>
  <Step title="Create Web Search Agent">
    Create a file `web_search.py`

    ```python web_search.py
    from agno.agent import Agent
    from agno.tools.duckduckgo import DuckDuckGoTools

    agent = Agent(tools=[DuckDuckGoTools()], show_tool_calls=True, markdown=True)
    agent.print_response("Whats happening in France?", stream=True)
    ```
  </Step>

  <Step title="Run the agent">
    Install libraries

    ```shell
    pip install openai duckduckgo-search agno
    ```

    Run the agent

    ```shell
    python web_search.py
    ```
  </Step>
</Steps>

## Writing your own Tools

For more control, write your own python functions and add them as tools to an Agent. For example, here's how to add a `get_top_hackernews_stories` tool to an Agent.

```python hn_agent.py
import json
import httpx

from agno.agent import Agent

def get_top_hackernews_stories(num_stories: int = 10) -> str:
    """Use this function to get top stories from Hacker News.

    Args:
        num_stories (int): Number of stories to return. Defaults to 10.

    Returns:
        str: JSON string of top stories.
    """

    # Fetch top story IDs
    response = httpx.get('https://hacker-news.firebaseio.com/v0/topstories.json')
    story_ids = response.json()

    # Fetch story details
    stories = []
    for story_id in story_ids[:num_stories]:
        story_response = httpx.get(f'https://hacker-news.firebaseio.com/v0/item/{story_id}.json')
        story = story_response.json()
        if "text" in story:
            story.pop("text", None)
        stories.append(story)
    return json.dumps(stories)

agent = Agent(tools=[get_top_hackernews_stories], show_tool_calls=True, markdown=True)
agent.print_response("Summarize the top 5 stories on hackernews?", stream=True)
```

Read more about:

* [Available toolkits](/tools/toolkits)
* [Using functions as tools](/tools/functions)

## Attributes

The following attributes allow an `Agent` to use tools

| Parameter                | Type                                                   | Default | Description                                                                                                                                                                                                                                                                                                                                                                                                                                         |
| ------------------------ | ------------------------------------------------------ | ------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `tools`                  | `List[Union[Tool, Toolkit, Callable, Dict, Function]]` | -       | A list of tools provided to the Model. Tools are functions the model may generate JSON inputs for.                                                                                                                                                                                                                                                                                                                                                  |
| `show_tool_calls`        | `bool`                                                 | `False` | Print the signature of the tool calls in the Model response.                                                                                                                                                                                                                                                                                                                                                                                        |
| `tool_call_limit`        | `int`                                                  | -       | Maximum number of tool calls allowed.                                                                                                                                                                                                                                                                                                                                                                                                               |
| `tool_choice`            | `Union[str, Dict[str, Any]]`                           | -       | Controls which (if any) tool is called by the model. "none" means the model will not call a tool and instead generates a message. "auto" means the model can pick between generating a message or calling a tool. Specifying a particular function via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool. "none" is the default when no tools are present. "auto" is the default if tools are present. |
| `read_chat_history`      | `bool`                                                 | `False` | Add a tool that allows the Model to read the chat history.                                                                                                                                                                                                                                                                                                                                                                                          |
| `search_knowledge`       | `bool`                                                 | `False` | Add a tool that allows the Model to search the knowledge base (aka Agentic RAG).                                                                                                                                                                                                                                                                                                                                                                    |
| `update_knowledge`       | `bool`                                                 | `False` | Add a tool that allows the Model to update the knowledge base.                                                                                                                                                                                                                                                                                                                                                                                      |
| `read_tool_call_history` | `bool`                                                 | `False` | Add a tool that allows the Model to get the tool call history.                                                                                                                                                                                                                                                                                                                                                                                      |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools)


# Product updates



<Update label="2025-02-05" description="v1.0.7">
  ## 1.0.7

  ## New Features:

  * **Google Sheets Toolkit**: Added a basic toolkit for reading, creating and updating Google sheets.
  * **Weviate Vector Store**: Added support for Weviate as a vector store.

  ## Improvements:

  * **Mistral Async**: Mistral now supports async execution via `agent.arun()` and `agent.aprint_response()`.
  * **Cohere Async**: Cohere now supports async execution via `agent.arun()` and `agent.aprint_response()`.

  ## Bug Fixes:

  * **Retriever as knowledge source**: Added small fix and examples for using the custom `retriever` parameter with an agent.
</Update>

<Update label="2025-02-05" description="v1.0.6">
  ## 1.0.6

  ## New Features:

  * **Google Maps Toolkit**: Added a rich toolkit for Google Maps that includes business discovery, directions, navigation, geocode locations, nearby places, etc.
  * **URL reader and knowledge base**: Added reader and knowledge base that can process any URL and store the text contents in the document store.

  ## Bug Fixes:

  * **Zoom tools fix:** Zoom tools updated to include the auth step and other misc fixes.
  * **Github search\_repositories pagination**: Pagination did not work correctly and this was fixed.
</Update>

<Update label="2025-02-03" description="v1.0.5">
  ## 1.0.5

  ## New Features:

  * **Gmail Tools:** Add tools for Gmail, including mail search, sending mails, etc.

  ## Improvements:

  * **Exa Toolkit Upgrade:** Added `find_similar` to `ExaTools`
  * **Claude Async:** Claude models can now be used with `await agent.aprint_response()` and `await agent.arun()`.
  * **Mistral Vision:** Mistral vision models are now supported. Various examples were added to illustrate [example](https://github.com/agno-agi/agno/blob/main/cookbook/models/mistral/image_file_input_agent.py).
</Update>

<Update label="2025-02-02" description="v1.0.4">
  ## 1.0.4

  ## Bug Fixes:

  * **Claude Tool Invocation:** Fixed issue where Claude was not working with tools that have no parameters.
</Update>

<Update label="2025-01-31" description="v1.0.3">
  ## 1.0.3

  ## Improvements:

  * **OpenAI Reasoning Parameter:** Added a reasoning parameter to OpenAI models.
</Update>

<Update label="2025-01-31" description="v1.0.2">
  ## 1.0.2

  ## Improvements:

  * **Model Client Caching:** Made all models cache the client instantiation, improving Agno agent instantiation time
  * **XTools:** Renamed `TwitterTools` to `XTools` and updated capabilities to be compatible with Twitter API v2.

  ## Bug Fixes:

  * **Agent Dataclass Compatibility:** Removed `slots=True` from the agent dataclass decorator, which was not compatible with Python \< 3.10.
  * **AzureOpenAIEmbedder:** Made `AzureOpenAIEmbedder` a dataclass to match other embedders.
</Update>

<Update label="2025-01-31" description="v1.0.1">
  ## 1.0.1

  ## Improvement:

  * **Mistral Model Caching:** Enabled caching for Mistral models.
</Update>

<Update label="2025-01-30" description="v1.0.0">
  ## 1.0.0 - Agno

  This is the major refactor from `phidata` to `agno`, released with the official launch of Agno AI.

  See the [migration guide](../how-to/phidata-to-agno) for additional guidance.

  ## Interface Changes:

  * `phi.model.x` → `agno.models.x`

  * `phi.knowledge_base.x` → `agno.knowledge.x` (applies to all knowledge bases)

  * `phi.document.reader.xxx` → `agno.document.reader.xxx_reader` (applies to all document readers)

  * All Agno toolkits are now suffixed with `Tools`. E.g. `DuckDuckGo` → `DuckDuckGoTools`

  * Multi-modal interface updates:

    * `agent.run(images=[])` and `agent.print_response(images=[])` is now of type `Image`

      ```python
      class Image(BaseModel):
          url: Optional[str] = None  # Remote location for image
          filepath: Optional[Union[Path, str]] = None  # Absolute local location for image
          content: Optional[Any] = None  # Actual image bytes content
          detail: Optional[str] = None # low, medium, high or auto (per OpenAI spec https://platform.openai.com/docs/guides/vision?lang=node#low-or-high-fidelity-image-understanding)
          id: Optional[str] = None
      ```

    * `agent.run(audio=[])` and `agent.print_response(audio=[])` is now of type `Audio`

      ```python
      class Audio(BaseModel):
          filepath: Optional[Union[Path, str]] = None  # Absolute local location for audio
          content: Optional[Any] = None  # Actual audio bytes content
          format: Optional[str] = None
      ```

    * `agent.run(video=[])` and `agent.print_response(video=[])` is now of type `Video`

      ```python
      class Video(BaseModel):
          filepath: Optional[Union[Path, str]] = None  # Absolute local location for video
          content: Optional[Any] = None  # Actual video bytes content
      ```

    * `RunResponse.images` is now a list of type `ImageArtifact`

      ```python
      class ImageArtifact(Media):
          id: str
          url: str  # Remote location for file
          alt_text: Optional[str] = None
      ```

    * `RunResponse.audio` is now a list of type `AudioArtifact`

      ```python
      class AudioArtifact(Media):
          id: str
          url: Optional[str] = None  # Remote location for file
          base64_audio: Optional[str] = None  # Base64-encoded audio data
          length: Optional[str] = None
          mime_type: Optional[str] = None
      ```

    * `RunResponse.videos` is now a list of type `VideoArtifact`

      ```python
      class VideoArtifact(Media):
          id: str
          url: str  # Remote location for file
          eta: Optional[str] = None
          length: Optional[str] = None
      ```

    * `RunResponse.response_audio` is now of type `AudioOutput`

      ```python
      class AudioOutput(BaseModel):
          id: str
          content: str  # Base64 encoded
          expires_at: int
          transcript: str
      ```

  * Models:
    * `Hermes` → `OllamaHermes`
    * `AzureOpenAIChat` → `AzureOpenAI`
    * `CohereChat` → `Cohere`
    * `DeepSeekChat` → `DeepSeek`
    * `GeminiOpenAIChat` → `GeminiOpenAI`
    * `HuggingFaceChat` → `HuggingFace`

  * Embedders now all take `id` instead of `model` as a parameter. For example

    ```python
    db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

    knowledge_base = PDFUrlKnowledgeBase(
        urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
        vector_db=PgVector(
            table_name="recipes",
            db_url=db_url,
            embedder=OllamaEmbedder(id="llama3.2", dimensions=3072),
        ),
    )
    knowledge_base.load(recreate=True)
    ```

  * Agent Storage class
    * `PgAgentStorage` → `PostgresDbAgentStorage`
    * `SqlAgentStorage` → `SqliteDbAgentStorage`
    * `MongoAgentStorage` → `MongoDbAgentStorage`
    * `S2AgentStorage` → `SingleStoreDbAgentStorage`

  * Workflow Storage class
    * `SqlWorkflowStorage` → `SqliteDbWorkflowStorage`
    * `PgWorkflowStorage` → `PostgresDbWorkflowStorage`
    * `MongoWorkflowStorage` → `MongoDbWorkflowStorage`

  * Knowledge Base
    * `phi.knowledge.pdf.PDFUrlKnowledgeBase` → `agno.knowledge.pdf_url.PDFUrlKnowledgeBase`
    * `phi.knowledge.csv.CSVUrlKnowledgeBase` → `agno.knowledge.csv_url.CSVUrlKnowledgeBase`

  * Readers
    * `phi.document.reader.arxiv` → `agno.document.reader.arxiv_reader`
    * `phi.document.reader.docx` → `agno.document.reader.docx_reader`
    * `phi.document.reader.json` → `agno.document.reader.json_reader`
    * `phi.document.reader.pdf` → `agno.document.reader.pdf_reader`
    * `phi.document.reader.s3.pdf` → `agno.document.reader.s3.pdf_reader`
    * `phi.document.reader.s3.text` → `agno.document.reader.s3.text_reader`
    * `phi.document.reader.text` → `agno.document.reader.text_reader`
    * `phi.document.reader.website` → `agno.document.reader.website_reader`

  ## Improvements:

  * **Dataclasses:** Changed various instances of Pydantic models to dataclasses to improve the speed.
  * Moved `Embedder` class from pydantic to data class

  ## Removals

  * Removed all references to `Assistant`
  * Removed all references to `llm`
  * Removed the `PhiTools` tool

  ## Bug Fixes:

  * **Semantic Chunking:** Fixed semantic chunking by replacing `similarity_threshold` param with `threshold` param.

  ## New Features:

  * **Evals for Agents:** Introducing Evals to measure the performance, accuracy, and reliability of your Agents.
</Update>


# Agentic Chunking



Agentic chunking is an intelligent method of splitting documents into smaller chunks by using a model to determine natural breakpoints in the text. Rather than splitting text at fixed character counts, it analyzes the content to find semantically meaningful boundaries like paragraph breaks and topic transitions.

## Usage

```python
from agno.agent import Agent
from agno.document.chunking.agentic import AgenticChunking
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=PgVector(table_name="recipes_agentic_chunking", db_url=db_url),
    chunking_strategy=AgenticChunking(),
)
knowledge_base.load(recreate=False)  # Comment out after first run

agent = Agent(
    knowledge_base=knowledge_base,
    search_knowledge=True,
)

agent.print_response("How to make Thai curry?", markdown=True)
```

## Agentic Chunking Params

<Snippet file="chunking-agentic.mdx" />


# Document Chunking



Document chunking is a method of splitting documents into smaller chunks based on document structure like paragraphs and sections. It analyzes natural document boundaries rather than splitting at fixed character counts. This is useful when you want to process large documents while preserving semantic meaning and context.

## Usage

```python
from agno.agent import Agent
from agno.document.chunking.document import DocumentChunking
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=PgVector(table_name="recipes_document_chunking", db_url=db_url),
    chunking_strategy=DocumentChunking(),
)
knowledge_base.load(recreate=False)  # Comment out after first run

agent = Agent(
    knowledge_base=knowledge_base,
    search_knowledge=True,
)

agent.print_response("How to make Thai curry?", markdown=True)

```

## Document Chunking Params

<Snippet file="chunking-document.mdx" />


# Fixed Size Chunking



Fixed size chunking is a method of splitting documents into smaller chunks of a specified size, with optional overlap between chunks. This is useful when you want to process large documents in smaller, manageable pieces.

## Usage

```python
from agno.agent import Agent
from agno.document.chunking.fixed import FixedSizeChunking
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=PgVector(table_name="recipes_fixed_size_chunking", db_url=db_url),
    chunking_strategy=FixedSizeChunking(),
)
knowledge_base.load(recreate=False)  # Comment out after first run

agent = Agent(
    knowledge_base=knowledge_base,
    search_knowledge=True,
)

agent.print_response("How to make Thai curry?", markdown=True)
```

## Fixed Size Chunking Params

<Snippet file="chunking-fixed-size.mdx" />


# Recursive Chunking



Recursive chunking is a method of splitting documents into smaller chunks by recursively applying a chunking strategy. This is useful when you want to process large documents in smaller, manageable pieces.

```python
from agno.agent import Agent
from agno.document.chunking.recursive import RecursiveChunking
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=PgVector(table_name="recipes_recursive_chunking", db_url=db_url),
    chunking_strategy=RecursiveChunking(),
)
knowledge_base.load(recreate=False)  # Comment out after first run

agent = Agent(
    knowledge_base=knowledge_base,
    search_knowledge=True,
)

agent.print_response("How to make Thai curry?", markdown=True)

```

## Recursive Chunking Params

<Snippet file="chunking-recursive.mdx" />


# Semantic Chunking



Semantic chunking is a method of splitting documents into smaller chunks by analyzing semantic similarity between text segments using embeddings. It uses the chonkie library to identify natural breakpoints where the semantic meaning changes significantly, based on a configurable similarity threshold. This helps preserve context and meaning better than fixed-size chunking by ensuring semantically related content stays together in the same chunk, while splitting occurs at meaningful topic transitions.

```python
from agno.agent import Agent
from agno.document.chunking.semantic import SemanticChunking
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=PgVector(table_name="recipes_semantic_chunking", db_url=db_url),
    chunking_strategy=SemanticChunking(),
)
knowledge_base.load(recreate=False)  # Comment out after first run

agent = Agent(
    knowledge_base=knowledge_base,
    search_knowledge=True,
)

agent.print_response("How to make Thai curry?", markdown=True)

```

## Semantic Chunking Params

<Snippet file="chunking-semantic.mdx" />


# Azure OpenAI Embedder



The `AzureOpenAIEmbedder` class is used to embed text data into vectors using the Azure OpenAI API. Get your key from [here](https://ai.azure.com/).

## Setup

### Set your API keys

```bash
export AZURE_EMBEDDER_OPENAI_API_KEY=xxx
export AZURE_EMBEDDER_OPENAI_ENDPOINT=xxx
export AZURE_EMBEDDER_DEPLOYMENT=xxx
```

### Run PgVector

```bash
docker run -d \
  -e POSTGRES_DB=ai \
  -e POSTGRES_USER=ai \
  -e POSTGRES_PASSWORD=ai \
  -e PGDATA=/var/lib/postgresql/data/pgdata \
  -v pgvolume:/var/lib/postgresql/data \
  -p 5532:5432 \
  --name pgvector \
  agnohq/pgvector:16
```

## Usage

```python cookbook/embedders/azure_embedder.py
from agno.agent import AgentKnowledge
from agno.vectordb.pgvector import PgVector
from agno.embedder.azure_openai import AzureOpenAIEmbedder

# Embed sentence in database
embeddings = AzureOpenAIEmbedder().get_embedding("The quick brown fox jumps over the lazy dog.")

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge_base = AgentKnowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="azure_openai_embeddings",
        embedder=AzureOpenAIEmbedder(),
    ),
    num_documents=2,
)
```

## Params

| Parameter                 | Type                          | Default                    | Description                                                                      |
| ------------------------- | ----------------------------- | -------------------------- | -------------------------------------------------------------------------------- |
| `model`                   | `str`                         | `"text-embedding-ada-002"` | The name of the model used for generating embeddings.                            |
| `dimensions`              | `int`                         | `1536`                     | The dimensionality of the embeddings generated by the model.                     |
| `encoding_format`         | `Literal['float', 'base64']`  | `"float"`                  | The format in which the embeddings are encoded. Options are "float" or "base64". |
| `user`                    | `str`                         | -                          | The user associated with the API request.                                        |
| `api_key`                 | `str`                         | -                          | The API key used for authenticating requests.                                    |
| `api_version`             | `str`                         | `"2024-02-01"`             | The version of the API to use for the requests.                                  |
| `azure_endpoint`          | `str`                         | -                          | The Azure endpoint for the API requests.                                         |
| `azure_deployment`        | `str`                         | -                          | The Azure deployment name for the API requests.                                  |
| `base_url`                | `str`                         | -                          | The base URL for the API endpoint.                                               |
| `azure_ad_token`          | `str`                         | -                          | The Azure Active Directory token for authentication.                             |
| `azure_ad_token_provider` | `Any`                         | -                          | The provider for obtaining the Azure AD token.                                   |
| `organization`            | `str`                         | -                          | The organization associated with the API request.                                |
| `request_params`          | `Optional[Dict[str, Any]]`    | -                          | Additional parameters to include in the API request. Optional.                   |
| `client_params`           | `Optional[Dict[str, Any]]`    | -                          | Additional parameters for configuring the API client. Optional.                  |
| `openai_client`           | `Optional[AzureOpenAIClient]` | -                          | An instance of the AzureOpenAIClient to use for making API requests. Optional.   |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/embedders/azure_embedder.py)


# Cohere Embedder



The `CohereEmbedder` class is used to embed text data into vectors using the Cohere API. You can get started with Cohere from [here](https://docs.cohere.com/reference/about)

Get your key from [here](https://dashboard.cohere.com/api-keys).

## Usage

```python cookbook/embedders/cohere_embedder.py
from agno.agent import AgentKnowledge
from agno.vectordb.pgvector import PgVector
from agno.embedder.cohere import CohereEmbedder

# Add embedding to database
embeddings = CohereEmbedder().get_embedding("The quick brown fox jumps over the lazy dog.")
# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge_base = AgentKnowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="cohere_embeddings",
        embedder=CohereEmbedder(),
    ),
    num_documents=2,
)
```

## Params

| Parameter         | Type                       | Default                | Description                                                                                                                    |
| ----------------- | -------------------------- | ---------------------- | ------------------------------------------------------------------------------------------------------------------------------ |
| `model`           | `str`                      | `"embed-english-v3.0"` | The name of the model used for generating embeddings.                                                                          |
| `input_type`      | `str`                      | `search_query`         | The type of input to embed. You can find more details [here](https://docs.cohere.com/docs/embeddings#the-input_type-parameter) |
| `embedding_types` | `Optional[List[str]]`      | -                      | The type of embeddings to generate. Optional.                                                                                  |
| `api_key`         | `str`                      | -                      | The Cohere API key used for authenticating requests.                                                                           |
| `request_params`  | `Optional[Dict[str, Any]]` | -                      | Additional parameters to include in the API request. Optional.                                                                 |
| `client_params`   | `Optional[Dict[str, Any]]` | -                      | Additional parameters for configuring the API client. Optional.                                                                |
| `cohere_client`   | `Optional[CohereClient]`   | -                      | An instance of the CohereClient to use for making API requests. Optional.                                                      |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/embedders/cohere_embedder.py)


# Fireworks Embedder



The `FireworksEmbedder` can be used to embed text data into vectors using the Fireworks API. Fireworks uses the OpenAI API specification, so the `FireworksEmbedder` class is similar to the `OpenAIEmbedder` class, incorporating adjustments to ensure compatibility with the Fireworks platform. Get your key from [here](https://fireworks.ai/account/api-keys).

## Usage

```python cookbook/embedders/fireworks_embedder.py
from agno.agent import AgentKnowledge
from agno.vectordb.pgvector import PgVector
from agno.embedder.fireworks import FireworksEmbedder

# Embed sentence in database
embeddings = FireworksEmbedder().get_embedding("The quick brown fox jumps over the lazy dog.")

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge_base = AgentKnowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="fireworks_embeddings",
        embedder=FireworksEmbedder(),
    ),
    num_documents=2,
)
```

## Params

| Parameter    | Type  | Default                                   | Description                                                  |
| ------------ | ----- | ----------------------------------------- | ------------------------------------------------------------ |
| `model`      | `str` | `"nomic-ai/nomic-embed-text-v1.5"`        | The name of the model used for generating embeddings.        |
| `dimensions` | `int` | `768`                                     | The dimensionality of the embeddings generated by the model. |
| `api_key`    | `str` | -                                         | The API key used for authenticating requests.                |
| `base_url`   | `str` | `"https://api.fireworks.ai/inference/v1"` | The base URL for the API endpoint.                           |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/embedders/fireworks_embedder.py)


# Gemini Embedder



The `GeminiEmbedder` class is used to embed text data into vectors using the Gemini API. You can get one from [here](https://ai.google.dev/aistudio).

## Usage

```python cookbook/embedders/gemini_embedder.py
from agno.agent import AgentKnowledge
from agno.vectordb.pgvector import PgVector
from agno.embedder.google import GeminiEmbedder

# Embed sentence in database
embeddings = GeminiEmbedder().get_embedding("The quick brown fox jumps over the lazy dog.")

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge_base = AgentKnowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="gemini_embeddings",
        embedder=GeminiEmbedder(),
    ),
    num_documents=2,
)
```

## Params

| Parameter        | Type                       | Default                     | Description                                                 |
| ---------------- | -------------------------- | --------------------------- | ----------------------------------------------------------- |
| `dimensions`     | `int`                      | `768`                       | The dimensionality of the generated embeddings              |
| `model`          | `str`                      | `models/text-embedding-004` | The name of the Gemini model to use                         |
| `task_type`      | `str`                      | -                           | The type of task for which embeddings are being generated   |
| `title`          | `str`                      | -                           | Optional title for the embedding task                       |
| `api_key`        | `str`                      | -                           | The API key used for authenticating requests.               |
| `request_params` | `Optional[Dict[str, Any]]` | -                           | Optional dictionary of parameters for the embedding request |
| `client_params`  | `Optional[Dict[str, Any]]` | -                           | Optional dictionary of parameters for the Gemini client     |
| `gemini_client`  | `Optional[Client]`         | -                           | Optional pre-configured Gemini client instance              |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/embedders/gemini_embedder.py)


# HuggingFace Embedder



The `HuggingfaceCustomEmbedder` class is used to embed text data into vectors using the Hugging Face API. You can get one from [here](https://huggingface.co/settings/tokens).

## Usage

```python cookbook/embedders/huggingface_embedder.py
from agno.agent import AgentKnowledge
from agno.vectordb.pgvector import PgVector
from agno.embedder.huggingface import HuggingfaceCustomEmbedder

# Embed sentence in database
embeddings = HuggingfaceCustomEmbedder().get_embedding("The quick brown fox jumps over the lazy dog.")

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge_base = AgentKnowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="huggingface_embeddings",
        embedder=HuggingfaceCustomEmbedder(),
    ),
    num_documents=2,
)
```

## Params

| Parameter            | Type                       | Default            | Description                                                  |
| -------------------- | -------------------------- | ------------------ | ------------------------------------------------------------ |
| `dimensions`         | `int`                      | -                  | The dimensionality of the generated embeddings               |
| `model`              | `str`                      | `all-MiniLM-L6-v2` | The name of the HuggingFace model to use                     |
| `api_key`            | `str`                      | -                  | The API key used for authenticating requests                 |
| `client_params`      | `Optional[Dict[str, Any]]` | -                  | Optional dictionary of parameters for the HuggingFace client |
| `huggingface_client` | `Any`                      | -                  | Optional pre-configured HuggingFace client instance          |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/embedders/huggingface_embedder.py)


# Introduction



An Embedder converts complex information into vector representations, allowing it to be stored in a vector database. By transforming data into embeddings, the embedder enables efficient searching and retrieval of contextually relevant information. This process enhances the responses of language models by providing them with the necessary business context, ensuring they are context-aware. Agno uses the `OpenAIEmbedder` as the default embedder, but other embedders are supported as well. Here is an example:

```python
from agno.agent import Agent, AgentKnowledge
from agno.vectordb.pgvector import PgVector
from agno.embedder.openai import OpenAIEmbedder

# Create knowledge base
knowledge_base=AgentKnowledge(
    vector_db=PgVector(
        db_url=db_url,
        table_name=embeddings_table,
        embedder=OpenAIEmbedder(),
    ),
    # 2 references are added to the prompt
    num_documents=2,
),

# Add information to the knowledge base
knowledge_base.load_text("The sky is blue")

# Add the knowledge base to the Agent
agent = Agent(knowledge_base=knowledge_base)
```

The following embedders are supported:

* [OpenAI](/embedder/openai)
* [Gemini](/embedder/gemini)
* [Ollama](/embedder/ollama)
* [Voyage AI](/embedder/voyageai)
* [Azure OpenAI](/embedder/azure_openai)
* [Mistral](/embedder/mistral)
* [Fireworks](/embedder/fireworks)
* [Together](/embedder/together)
* [HuggingFace](/embedder/huggingface)
* [Qdrant FastEmbed](/embedder/qdrant_fastembed)


# Mistral Embedder



The `MistralEmbedder` class is used to embed text data into vectors using the Mistral API. Get your key from [here](https://console.mistral.ai/api-keys/).

## Usage

```python cookbook/embedders/mistral_embedder.py
from agno.agent import AgentKnowledge
from agno.vectordb.pgvector import PgVector
from agno.embedder.mistral import MistralEmbedder

# Embed sentence in database
embeddings = MistralEmbedder().get_embedding("The quick brown fox jumps over the lazy dog.")

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge_base = AgentKnowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="mistral_embeddings",
        embedder=MistralEmbedder(),
    ),
    num_documents=2,
)
```

## Params

| Parameter        | Type                       | Default           | Description                                                                |
| ---------------- | -------------------------- | ----------------- | -------------------------------------------------------------------------- |
| `model`          | `str`                      | `"mistral-embed"` | The name of the model used for generating embeddings.                      |
| `dimensions`     | `int`                      | `1024`            | The dimensionality of the embeddings generated by the model.               |
| `request_params` | `Optional[Dict[str, Any]]` | -                 | Additional parameters to include in the API request. Optional.             |
| `api_key`        | `str`                      | -                 | The API key used for authenticating requests.                              |
| `endpoint`       | `str`                      | -                 | The endpoint URL for the API requests.                                     |
| `max_retries`    | `Optional[int]`            | -                 | The maximum number of retries for API requests. Optional.                  |
| `timeout`        | `Optional[int]`            | -                 | The timeout duration for API requests. Optional.                           |
| `client_params`  | `Optional[Dict[str, Any]]` | -                 | Additional parameters for configuring the API client. Optional.            |
| `mistral_client` | `Optional[MistralClient]`  | -                 | An instance of the MistralClient to use for making API requests. Optional. |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/embedders/mistral_embedder.py)


# Ollama Embedder



The `OllamaEmbedder` can be used to embed text data into vectors locally using Ollama.

<Note>The model used for generating embeddings needs to run locally. In this case it is `openhermes` so you have to [install `ollama`](https://ollama.com/download) and run `ollama pull openhermes` in your terminal.</Note>

## Usage

```python cookbook/embedders/ollama_embedder.py
from agno.agent import AgentKnowledge
from agno.vectordb.pgvector import PgVector
from agno.embedder.ollama import OllamaEmbedder

# Embed sentence in database
embeddings = OllamaEmbedder(id="openhermes").get_embedding("The quick brown fox jumps over the lazy dog.")

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge_base = AgentKnowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="ollama_embeddings",
        embedder=OllamaEmbedder(),
    ),
    num_documents=2,
)
```

## Params

| Parameter       | Type                       | Default        | Description                                                               |
| --------------- | -------------------------- | -------------- | ------------------------------------------------------------------------- |
| `model`         | `str`                      | `"openhermes"` | The name of the model used for generating embeddings.                     |
| `dimensions`    | `int`                      | `4096`         | The dimensionality of the embeddings generated by the model.              |
| `host`          | `str`                      | -              | The host address for the API endpoint.                                    |
| `timeout`       | `Any`                      | -              | The timeout duration for API requests.                                    |
| `options`       | `Any`                      | -              | Additional options for configuring the API request.                       |
| `client_kwargs` | `Optional[Dict[str, Any]]` | -              | Additional keyword arguments for configuring the API client. Optional.    |
| `ollama_client` | `Optional[OllamaClient]`   | -              | An instance of the OllamaClient to use for making API requests. Optional. |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/embedders/ollama_embedder.py)


# OpenAI Embedder



Agno uses the `OpenAIEmbedder` as the default embeder for the vector database. The `OpenAIEmbedder` class is used to embed text data into vectors using the OpenAI API. Get your key from [here](https://platform.openai.com/api-keys).

## Usage

```python cookbook/embedders/openai_embedder.py
from agno.agent import AgentKnowledge
from agno.vectordb.pgvector import PgVector
from agno.embedder.openai import OpenAIEmbedder

# Embed sentence in database
embeddings = OpenAIEmbedder().get_embedding("The quick brown fox jumps over the lazy dog.")

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge_base = AgentKnowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="openai_embeddings",
        embedder=OpenAIEmbedder(),
    ),
    num_documents=2,
)
```

## Params

| Parameter         | Type                         | Default                    | Description                                                                      |
| ----------------- | ---------------------------- | -------------------------- | -------------------------------------------------------------------------------- |
| `model`           | `str`                        | `"text-embedding-ada-002"` | The name of the model used for generating embeddings.                            |
| `dimensions`      | `int`                        | `1536`                     | The dimensionality of the embeddings generated by the model.                     |
| `encoding_format` | `Literal['float', 'base64']` | `"float"`                  | The format in which the embeddings are encoded. Options are "float" or "base64". |
| `user`            | `str`                        | -                          | The user associated with the API request.                                        |
| `api_key`         | `str`                        | -                          | The API key used for authenticating requests.                                    |
| `organization`    | `str`                        | -                          | The organization associated with the API request.                                |
| `base_url`        | `str`                        | -                          | The base URL for the API endpoint.                                               |
| `request_params`  | `Optional[Dict[str, Any]]`   | -                          | Additional parameters to include in the API request.                             |
| `client_params`   | `Optional[Dict[str, Any]]`   | -                          | Additional parameters for configuring the API client.                            |
| `openai_client`   | `Optional[OpenAIClient]`     | -                          | An instance of the OpenAIClient to use for making API requests.                  |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/embedders/openai_embedder.py)


# Qdrant FastEmbed Embedder



The `FastEmbedEmbedder` class is used to embed text data into vectors using the [FastEmbed](https://qdrant.github.io/fastembed/).

## Usage

```python cookbook/embedders/qdrant_fastembed.py
from agno.agent import AgentKnowledge
from agno.vectordb.pgvector import PgVector
from agno.embedder.fastembed import FastEmbedEmbedder

# Embed sentence in database
embeddings = FastEmbedEmbedder().get_embedding("The quick brown fox jumps over the lazy dog.")

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge_base = AgentKnowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="qdrant_embeddings",
        embedder=FastEmbedEmbedder(),
    ),
    num_documents=2,
)
```

## Params

| Parameter    | Type  | Default                  | Description                                    |
| ------------ | ----- | ------------------------ | ---------------------------------------------- |
| `dimensions` | `int` | -                        | The dimensionality of the generated embeddings |
| `model`      | `str` | `BAAI/bge-small-en-v1.5` | The name of the qdrant\_fastembed model to use |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/embedders/qdrant_fastembed.py)


# SentenceTransformers Embedder



The `SentenceTransformerEmbedder` class is used to embed text data into vectors using the [SentenceTransformers](https://www.sbert.net/) library.

## Usage

```python cookbook/embedders/sentence_transformer_embedder.py
from agno.agent import AgentKnowledge
from agno.vectordb.pgvector import PgVector
from agno.embedder.sentence_transformer import SentenceTransformerEmbedder

# Embed sentence in database
embeddings = SentenceTransformerEmbedder().get_embedding("The quick brown fox jumps over the lazy dog.")

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge_base = AgentKnowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="sentence_transformer_embeddings",
        embedder=SentenceTransformerEmbedder(),
    ),
    num_documents=2,
)
```

## Params

| Parameter                     | Type               | Default             | Description                                                  |
| ----------------------------- | ------------------ | ------------------- | ------------------------------------------------------------ |
| `dimensions`                  | `int`              | -                   | The dimensionality of the generated embeddings               |
| `model`                       | `str`              | `all-mpnet-base-v2` | The name of the SentenceTransformers model to use            |
| `sentence_transformer_client` | `Optional[Client]` | -                   | Optional pre-configured SentenceTransformers client instance |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/embedders/sentence_transformer_embedder.py)


# Together Embedder



The `TogetherEmbedder` can be used to embed text data into vectors using the Together API. Together uses the OpenAI API specification, so the `TogetherEmbedder` class is similar to the `OpenAIEmbedder` class, incorporating adjustments to ensure compatibility with the Together platform. Get your key from [here](https://api.together.xyz/settings/api-keys).

## Usage

```python cookbook/embedders/together_embedder.py
from agno.agent import AgentKnowledge
from agno.vectordb.pgvector import PgVector
from agno.embedder.together import TogetherEmbedder

# Embed sentence in database
embeddings = TogetherEmbedder().get_embedding("The quick brown fox jumps over the lazy dog.")

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge_base = AgentKnowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="together_embeddings",
        embedder=TogetherEmbedder(),
    ),
    num_documents=2,
)
```

## Params

| Parameter    | Type  | Default                                  | Description                                                  |
| ------------ | ----- | ---------------------------------------- | ------------------------------------------------------------ |
| `model`      | `str` | `"nomic-ai/nomic-embed-text-v1.5"`       | The name of the model used for generating embeddings.        |
| `dimensions` | `int` | `768`                                    | The dimensionality of the embeddings generated by the model. |
| `api_key`    | `str` |                                          | The API key used for authenticating requests.                |
| `base_url`   | `str` | `"https://api.Together.ai/inference/v1"` | The base URL for the API endpoint.                           |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/embedders/together_embedder.py)


# Voyage AI Embedder



The `VoyageAIEmbedder` class is used to embed text data into vectors using the Voyage AI API. Get your key from [here](https://dash.voyageai.com/api-keys).

## Usage

```python cookbook/embedders/voyageai_embedder.py
from agno.agent import AgentKnowledge
from agno.vectordb.pgvector import PgVector
from agno.embedder.voyageai import VoyageAIEmbedder

# Embed sentence in database
embeddings = VoyageAIEmbedder().get_embedding("The quick brown fox jumps over the lazy dog.")

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge_base = AgentKnowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="voyageai_embeddings",
        embedder=VoyageAIEmbedder(),
    ),
    num_documents=2,
)
```

## Params

| Parameter        | Type                       | Default                                    | Description                                                         |
| ---------------- | -------------------------- | ------------------------------------------ | ------------------------------------------------------------------- |
| `model`          | `str`                      | `"voyage-2"`                               | The name of the model used for generating embeddings.               |
| `dimensions`     | `int`                      | `1024`                                     | The dimensionality of the embeddings generated by the model.        |
| `request_params` | `Optional[Dict[str, Any]]` | -                                          | Additional parameters to include in the API request. Optional.      |
| `api_key`        | `str`                      | -                                          | The API key used for authenticating requests.                       |
| `base_url`       | `str`                      | `"https://api.voyageai.com/v1/embeddings"` | The base URL for the API endpoint.                                  |
| `max_retries`    | `Optional[int]`            | -                                          | The maximum number of retries for API requests. Optional.           |
| `timeout`        | `Optional[float]`          | -                                          | The timeout duration for API requests. Optional.                    |
| `client_params`  | `Optional[Dict[str, Any]]` | -                                          | Additional parameters for configuring the API client. Optional.     |
| `voyage_client`  | `Optional[Client]`         | -                                          | An instance of the Client to use for making API requests. Optional. |

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/embedders/voyageai_embedder.py)


# Books Recommender



This example shows how to create an intelligent book recommendation system that provides
comprehensive literary suggestions based on your preferences. The agent combines book databases,
ratings, reviews, and upcoming releases to deliver personalized reading recommendations.

Example prompts to try:

* "I loved 'The Seven Husbands of Evelyn Hugo' and 'Daisy Jones & The Six', what should I read next?"
* "Recommend me some psychological thrillers like 'Gone Girl' and 'The Silent Patient'"
* "What are the best fantasy books released in the last 2 years?"
* "I enjoy historical fiction with strong female leads, any suggestions?"
* "Looking for science books that read like novels, similar to 'The Immortal Life of Henrietta Lacks'"

## Code

```python books_recommender.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.exa import ExaTools

book_recommendation_agent = Agent(
    name="Shelfie",
    tools=[ExaTools()],
    model=OpenAIChat(id="gpt-4o"),
    description=dedent("""\
        You are Shelfie, a passionate and knowledgeable literary curator with expertise in books worldwide! 📚

        Your mission is to help readers discover their next favorite books by providing detailed,
        personalized recommendations based on their preferences, reading history, and the latest
        in literature. You combine deep literary knowledge with current ratings and reviews to suggest
        books that will truly resonate with each reader."""),
    instructions=dedent("""\
        Approach each recommendation with these steps:

        1. Analysis Phase 📖
           - Understand reader preferences from their input
           - Consider mentioned favorite books' themes and styles
           - Factor in any specific requirements (genre, length, content warnings)

        2. Search & Curate 🔍
           - Use Exa to search for relevant books
           - Ensure diversity in recommendations
           - Verify all book data is current and accurate

        3. Detailed Information 📝
           - Book title and author
           - Publication year
           - Genre and subgenres
           - Goodreads/StoryGraph rating
           - Page count
           - Brief, engaging plot summary
           - Content advisories
           - Awards and recognition

        4. Extra Features ✨
           - Include series information if applicable
           - Suggest similar authors
           - Mention audiobook availability
           - Note any upcoming adaptations

        Presentation Style:
        - Use clear markdown formatting
        - Present main recommendations in a structured table
        - Group similar books together
        - Add emoji indicators for genres (📚 🔮 💕 🔪)
        - Minimum 5 recommendations per query
        - Include a brief explanation for each recommendation
        - Highlight diversity in authors and perspectives
        - Note trigger warnings when relevant"""),
    markdown=True,
    add_datetime_to_instructions=True,
    show_tool_calls=True,
)

# Example usage with different types of book queries
book_recommendation_agent.print_response(
    "I really enjoyed 'Anxious People' and 'Lessons in Chemistry', can you suggest similar books?",
    stream=True,
)

# More example prompts to explore:
"""
Genre-specific queries:
1. "Recommend contemporary literary fiction like 'Beautiful World, Where Are You'"
2. "What are the best fantasy series completed in the last 5 years?"
3. "Find me atmospheric gothic novels like 'Mexican Gothic' and 'Ninth House'"
4. "What are the most acclaimed debut novels from this year?"

Contemporary Issues:
1. "Suggest books about climate change that aren't too depressing"
2. "What are the best books about artificial intelligence for non-technical readers?"
3. "Recommend memoirs about immigrant experiences"
4. "Find me books about mental health with hopeful endings"

Book Club Selections:
1. "What are good book club picks that spark discussion?"
2. "Suggest literary fiction under 350 pages"
3. "Find thought-provoking novels that tackle current social issues"
4. "Recommend books with multiple perspectives/narratives"

Upcoming Releases:
1. "What are the most anticipated literary releases next month?"
2. "Show me upcoming releases from my favorite authors"
3. "What debut novels are getting buzz this season?"
4. "List upcoming books being adapted for screen"
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install openai exa_py agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export EXA_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python books_recommender.py
    ```
  </Step>
</Steps>


# Finance Agent



This example shows how to create a sophisticated financial analyst that provides
comprehensive market insights using real-time data. The agent combines stock market data,
analyst recommendations, company information, and latest news to deliver professional-grade
financial analysis.

Example prompts to try:

* "What's the latest news and financial performance of Apple (AAPL)?"
* "Give me a detailed analysis of Tesla's (TSLA) current market position"
* "How are Microsoft's (MSFT) financials looking? Include analyst recommendations"
* "Analyze NVIDIA's (NVDA) stock performance and future outlook"
* "What's the market saying about Amazon's (AMZN) latest quarter?"

## Code

```python finance_agent.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.yfinance import YFinanceTools

finance_agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    tools=[
        YFinanceTools(
            stock_price=True,
            analyst_recommendations=True,
            stock_fundamentals=True,
            historical_prices=True,
            company_info=True,
            company_news=True,
        )
    ],
    instructions=dedent("""\
        You are a seasoned Wall Street analyst with deep expertise in market analysis! 📊

        Follow these steps for comprehensive financial analysis:
        1. Market Overview
           - Latest stock price
           - 52-week high and low
        2. Financial Deep Dive
           - Key metrics (P/E, Market Cap, EPS)
        3. Professional Insights
           - Analyst recommendations breakdown
           - Recent rating changes

        4. Market Context
           - Industry trends and positioning
           - Competitive analysis
           - Market sentiment indicators

        Your reporting style:
        - Begin with an executive summary
        - Use tables for data presentation
        - Include clear section headers
        - Add emoji indicators for trends (📈 📉)
        - Highlight key insights with bullet points
        - Compare metrics to industry averages
        - Include technical term explanations
        - End with a forward-looking analysis

        Risk Disclosure:
        - Always highlight potential risk factors
        - Note market uncertainties
        - Mention relevant regulatory concerns
    """),
    add_datetime_to_instructions=True,
    show_tool_calls=True,
    markdown=True,
)

# Example usage with detailed market analysis request
finance_agent.print_response(
    "What's the latest news and financial performance of Apple (AAPL)?", stream=True
)

# Semiconductor market analysis example
finance_agent.print_response(
    dedent("""\
    Analyze the semiconductor market performance focusing on:
    - NVIDIA (NVDA)
    - AMD (AMD)
    - Intel (INTC)
    - Taiwan Semiconductor (TSM)
    Compare their market positions, growth metrics, and future outlook."""),
    stream=True,
)

# Automotive market analysis example
finance_agent.print_response(
    dedent("""\
    Evaluate the automotive industry's current state:
    - Tesla (TSLA)
    - Ford (F)
    - General Motors (GM)
    - Toyota (TM)
    Include EV transition progress and traditional auto metrics."""),
    stream=True,
)

# More example prompts to explore:
"""
Advanced analysis queries:
1. "Compare Tesla's valuation metrics with traditional automakers"
2. "Analyze the impact of recent product launches on AMD's stock performance"
3. "How do Meta's financial metrics compare to its social media peers?"
4. "Evaluate Netflix's subscriber growth impact on financial metrics"
5. "Break down Amazon's revenue streams and segment performance"

Industry-specific analyses:
Semiconductor Market:
1. "How is the chip shortage affecting TSMC's market position?"
2. "Compare NVIDIA's AI chip revenue growth with competitors"
3. "Analyze Intel's foundry strategy impact on stock performance"
4. "Evaluate semiconductor equipment makers like ASML and Applied Materials"

Automotive Industry:
1. "Compare EV manufacturers' production metrics and margins"
2. "Analyze traditional automakers' EV transition progress"
3. "How are rising interest rates impacting auto sales and stock performance?"
4. "Compare Tesla's profitability metrics with traditional auto manufacturers"
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai yfinance agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python finance_agent.py
    ```
  </Step>
</Steps>


# Movie Recommender



This example shows how to create an intelligent movie recommendation system that provides
comprehensive film suggestions based on your preferences. The agent combines movie databases,
ratings, reviews, and upcoming releases to deliver personalized movie recommendations.

Example prompts to try:

* "Suggest thriller movies similar to Inception and Shutter Island"
* "What are the top-rated comedy movies from the last 2 years?"
* "Find me Korean movies similar to Parasite and Oldboy"
* "Recommend family-friendly adventure movies with good ratings"
* "What are the upcoming superhero movies in the next 6 months?"

## Code

```python movie_recommender.py
"""🎬 Movie Recommender - Your Personal Cinema Curator!

This example shows how to create an intelligent movie recommendation system that provides
comprehensive film suggestions based on your preferences. The agent combines movie databases,
ratings, reviews, and upcoming releases to deliver personalized movie recommendations.

Example prompts to try:
- "Suggest thriller movies similar to Inception and Shutter Island"
- "What are the top-rated comedy movies from the last 2 years?"
- "Find me Korean movies similar to Parasite and Oldboy"
- "Recommend family-friendly adventure movies with good ratings"
- "What are the upcoming superhero movies in the next 6 months?"

Run: `pip install openai exa_py agno` to install the dependencies
"""

from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.exa import ExaTools

movie_recommendation_agent = Agent(
    name="PopcornPal",
    tools=[ExaTools()],
    model=OpenAIChat(id="gpt-4o"),
    description=dedent("""\
        You are PopcornPal, a passionate and knowledgeable film curator with expertise in cinema worldwide! 🎥

        Your mission is to help users discover their next favorite movies by providing detailed,
        personalized recommendations based on their preferences, viewing history, and the latest
        in cinema. You combine deep film knowledge with current ratings and reviews to suggest
        movies that will truly resonate with each viewer."""),
    instructions=dedent("""\
        Approach each recommendation with these steps:
        1. Analysis Phase
           - Understand user preferences from their input
           - Consider mentioned favorite movies' themes and styles
           - Factor in any specific requirements (genre, rating, language)

        2. Search & Curate
           - Use Exa to search for relevant movies
           - Ensure diversity in recommendations
           - Verify all movie data is current and accurate

        3. Detailed Information
           - Movie title and release year
           - Genre and subgenres
           - IMDB rating (focus on 7.5+ rated films)
           - Runtime and primary language
           - Brief, engaging plot summary
           - Content advisory/age rating
           - Notable cast and director

        4. Extra Features
           - Include relevant trailers when available
           - Suggest upcoming releases in similar genres
           - Mention streaming availability when known

        Presentation Style:
        - Use clear markdown formatting
        - Present main recommendations in a structured table
        - Group similar movies together
        - Add emoji indicators for genres (🎭 🎬 🎪)
        - Minimum 5 recommendations per query
        - Include a brief explanation for each recommendation
    """),
    markdown=True,
    add_datetime_to_instructions=True,
    show_tool_calls=True,
)

# Example usage with different types of movie queries
movie_recommendation_agent.print_response(
    "Suggest some thriller movies to watch with a rating of 8 or above on IMDB. "
    "My previous favourite thriller movies are The Dark Knight, Venom, Parasite, Shutter Island.",
    stream=True,
)

# More example prompts to explore:
"""
Genre-specific queries:
1. "Find me psychological thrillers similar to Black Swan and Gone Girl"
2. "What are the best animated movies from Studio Ghibli?"
3. "Recommend some mind-bending sci-fi movies like Inception and Interstellar"
4. "What are the highest-rated crime documentaries from the last 5 years?"

International Cinema:
1. "Suggest Korean movies similar to Parasite and Train to Busan"
2. "What are the must-watch French films from the last decade?"
3. "Recommend Japanese animated movies for adults"
4. "Find me award-winning European drama films"

Family & Group Watching:
1. "What are good family movies for kids aged 8-12?"
2. "Suggest comedy movies perfect for a group movie night"
3. "Find educational documentaries suitable for teenagers"
4. "Recommend adventure movies that both adults and children would enjoy"

Upcoming Releases:
1. "What are the most anticipated movies coming out next month?"
2. "Show me upcoming superhero movie releases"
3. "What horror movies are releasing this Halloween season?"
4. "List upcoming book-to-movie adaptations"
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai exa_py agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export EXA_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python movie_recommender.py
    ```
  </Step>
</Steps>


# Recipe Creator



This example shows how to create an intelligent recipe recommendation system that provides
detailed, personalized recipes based on your ingredients, dietary preferences, and time constraints.
The agent combines culinary knowledge, nutritional data, and cooking techniques to deliver
comprehensive cooking instructions.

Example prompts to try:

* "I have chicken, rice, and vegetables. What can I make in 30 minutes?"
* "Create a vegetarian pasta recipe with mushrooms and spinach"
* "Suggest healthy breakfast options with oats and fruits"
* "What can I make with leftover turkey and potatoes?"
* "Need a quick dessert recipe using chocolate and bananas"

## Code

```python recipe_creator.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.exa import ExaTools

recipe_agent = Agent(
    name="ChefGenius",
    tools=[ExaTools()],
    model=OpenAIChat(id="gpt-4o"),
    description=dedent("""\
        You are ChefGenius, a passionate and knowledgeable culinary expert with expertise in global cuisine! 🍳

        Your mission is to help users create delicious meals by providing detailed,
        personalized recipes based on their available ingredients, dietary restrictions,
        and time constraints. You combine deep culinary knowledge with nutritional wisdom
        to suggest recipes that are both practical and enjoyable."""),
    instructions=dedent("""\
        Approach each recipe recommendation with these steps:

        1. Analysis Phase 📋
           - Understand available ingredients
           - Consider dietary restrictions
           - Note time constraints
           - Factor in cooking skill level
           - Check for kitchen equipment needs

        2. Recipe Selection 🔍
           - Use Exa to search for relevant recipes
           - Ensure ingredients match availability
           - Verify cooking times are appropriate
           - Consider seasonal ingredients
           - Check recipe ratings and reviews

        3. Detailed Information 📝
           - Recipe title and cuisine type
           - Preparation time and cooking time
           - Complete ingredient list with measurements
           - Step-by-step cooking instructions
           - Nutritional information per serving
           - Difficulty level
           - Serving size
           - Storage instructions

        4. Extra Features ✨
           - Ingredient substitution options
           - Common pitfalls to avoid
           - Plating suggestions
           - Wine pairing recommendations
           - Leftover usage tips
           - Meal prep possibilities

        Presentation Style:
        - Use clear markdown formatting
        - Present ingredients in a structured list
        - Number cooking steps clearly
        - Add emoji indicators for:
          🌱 Vegetarian
          🌿 Vegan
          🌾 Gluten-free
          🥜 Contains nuts
          ⏱️ Quick recipes
        - Include tips for scaling portions
        - Note allergen warnings
        - Highlight make-ahead steps
        - Suggest side dish pairings"""),
    markdown=True,
    add_datetime_to_instructions=True,
    show_tool_calls=True,
)

# Example usage with different types of recipe queries
recipe_agent.print_response(
    "I have chicken breast, broccoli, garlic, and rice. Need a healthy dinner recipe that takes less than 45 minutes.",
    stream=True,
)

# More example prompts to explore:
"""
Quick Meals:
1. "15-minute dinner ideas with pasta and vegetables"
2. "Quick healthy lunch recipes for meal prep"
3. "Easy breakfast recipes with eggs and avocado"
4. "No-cook dinner ideas for hot summer days"

Dietary Restrictions:
1. "Keto-friendly dinner recipes with salmon"
2. "Gluten-free breakfast options without eggs"
3. "High-protein vegetarian meals for athletes"
4. "Low-carb alternatives to pasta dishes"

Special Occasions:
1. "Impressive dinner party main course for 6 people"
2. "Romantic dinner recipes for two"
3. "Kid-friendly birthday party snacks"
4. "Holiday desserts that can be made ahead"

International Cuisine:
1. "Authentic Thai curry with available ingredients"
2. "Simple Japanese recipes for beginners"
3. "Mediterranean diet dinner ideas"
4. "Traditional Mexican recipes with modern twists"

Seasonal Cooking:
1. "Summer salad recipes with seasonal produce"
2. "Warming winter soups and stews"
3. "Fall harvest vegetable recipes"
4. "Spring picnic recipe ideas"

Batch Cooking:
1. "Freezer-friendly meal prep recipes"
2. "One-pot meals for busy weeknights"
3. "Make-ahead breakfast ideas"
4. "Bulk cooking recipes for large families"
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install required libraries">
    ```bash
    pip install agno openai exa_py
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export EXA_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python recipe_creator.py
    ```
  </Step>
</Steps>


# Research Agent



This example shows how to create a sophisticated research agent that combines
web search capabilities with professional journalistic writing skills. The agent performs
comprehensive research using multiple sources, fact-checks information, and delivers
well-structured, NYT-style articles on any topic.

Key capabilities:

* Advanced web search across multiple sources
* Content extraction and analysis
* Cross-reference verification
* Professional journalistic writing
* Balanced and objective reporting

Example prompts to try:

* "Analyze the impact of AI on healthcare delivery and patient outcomes"
* "Report on the latest breakthroughs in quantum computing"
* "Investigate the global transition to renewable energy sources"
* "Explore the evolution of cybersecurity threats and defenses"
* "Research the development of autonomous vehicle technology"

## Code

```python research_agent.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.newspaper4k import Newspaper4kTools

# Initialize the research agent with advanced journalistic capabilities
research_agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    tools=[DuckDuckGoTools(), Newspaper4kTools()],
    description=dedent("""\
        You are an elite investigative journalist with decades of experience at the New York Times.
        Your expertise encompasses: 📰

        - Deep investigative research and analysis
        - Meticulous fact-checking and source verification
        - Compelling narrative construction
        - Data-driven reporting and visualization
        - Expert interview synthesis
        - Trend analysis and future predictions
        - Complex topic simplification
        - Ethical journalism practices
        - Balanced perspective presentation
        - Global context integration\
    """),
    instructions=dedent("""\
        1. Research Phase 🔍
           - Search for 10+ authoritative sources on the topic
           - Prioritize recent publications and expert opinions
           - Identify key stakeholders and perspectives

        2. Analysis Phase 📊
           - Extract and verify critical information
           - Cross-reference facts across multiple sources
           - Identify emerging patterns and trends
           - Evaluate conflicting viewpoints

        3. Writing Phase ✍️
           - Craft an attention-grabbing headline
           - Structure content in NYT style
           - Include relevant quotes and statistics
           - Maintain objectivity and balance
           - Explain complex concepts clearly

        4. Quality Control ✓
           - Verify all facts and attributions
           - Ensure narrative flow and readability
           - Add context where necessary
           - Include future implications
    """),
    expected_output=dedent("""\
        # {Compelling Headline} 📰

        ## Executive Summary
        {Concise overview of key findings and significance}

        ## Background & Context
        {Historical context and importance}
        {Current landscape overview}

        ## Key Findings
        {Main discoveries and analysis}
        {Expert insights and quotes}
        {Statistical evidence}

        ## Impact Analysis
        {Current implications}
        {Stakeholder perspectives}
        {Industry/societal effects}

        ## Future Outlook
        {Emerging trends}
        {Expert predictions}
        {Potential challenges and opportunities}

        ## Expert Insights
        {Notable quotes and analysis from industry leaders}
        {Contrasting viewpoints}

        ## Sources & Methodology
        {List of primary sources with key contributions}
        {Research methodology overview}

        ---
        Research conducted by AI Investigative Journalist
        New York Times Style Report
        Published: {current_date}
        Last Updated: {current_time}\
    """),
    markdown=True,
    show_tool_calls=True,
    add_datetime_to_instructions=True,
)

# Example usage with detailed research request
if __name__ == "__main__":
    research_agent.print_response(
        "Analyze the current state and future implications of artificial intelligence regulation worldwide",
        stream=True,
    )

# Advanced research topics to explore:
"""
Technology & Innovation:
1. "Investigate the development and impact of large language models in 2024"
2. "Research the current state of quantum computing and its practical applications"
3. "Analyze the evolution and future of edge computing technologies"
4. "Explore the latest advances in brain-computer interface technology"

Environmental & Sustainability:
1. "Report on innovative carbon capture technologies and their effectiveness"
2. "Investigate the global progress in renewable energy adoption"
3. "Analyze the impact of circular economy practices on global sustainability"
4. "Research the development of sustainable aviation technologies"

Healthcare & Biotechnology:
1. "Explore the latest developments in CRISPR gene editing technology"
2. "Analyze the impact of AI on drug discovery and development"
3. "Investigate the evolution of personalized medicine approaches"
4. "Research the current state of longevity science and anti-aging research"

Societal Impact:
1. "Examine the effects of social media on democratic processes"
2. "Analyze the impact of remote work on urban development"
3. "Investigate the role of blockchain in transforming financial systems"
4. "Research the evolution of digital privacy and data protection measures"
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai duckduckgo-search newspaper4k lxml_html_clean agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python research_agent.py
    ```
  </Step>
</Steps>


# Research Agent using Exa



This example shows how to create a sophisticated research agent that combines
academic search capabilities with scholarly writing expertise. The agent performs
thorough research using Exa's academic search, analyzes recent publications, and delivers
well-structured, academic-style reports on any topic.

Key capabilities:

* Advanced academic literature search
* Recent publication analysis
* Cross-disciplinary synthesis
* Academic writing expertise
* Citation management

Example prompts to try:

* "Explore recent advances in quantum machine learning"
* "Analyze the current state of fusion energy research"
* "Investigate the latest developments in CRISPR gene editing"
* "Research the intersection of blockchain and sustainable energy"
* "Examine recent breakthroughs in brain-computer interfaces"

## Code

```python research_agent_exa.py
from datetime import datetime
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.exa import ExaTools

# Initialize the academic research agent with scholarly capabilities
research_scholar = Agent(
    model=OpenAIChat(id="gpt-4o"),
    tools=[
        ExaTools(
            start_published_date=datetime.now().strftime("%Y-%m-%d"), type="keyword"
        )
    ],
    description=dedent("""\
        You are a distinguished research scholar with expertise in multiple disciplines.
        Your academic credentials include: 📚

        - Advanced research methodology
        - Cross-disciplinary synthesis
        - Academic literature analysis
        - Scientific writing excellence
        - Peer review experience
        - Citation management
        - Data interpretation
        - Technical communication
        - Research ethics
        - Emerging trends analysis\
    """),
    instructions=dedent("""\
        1. Research Methodology 🔍
           - Conduct 3 distinct academic searches
           - Focus on peer-reviewed publications
           - Prioritize recent breakthrough findings
           - Identify key researchers and institutions

        2. Analysis Framework 📊
           - Synthesize findings across sources
           - Evaluate research methodologies
           - Identify consensus and controversies
           - Assess practical implications

        3. Report Structure 📝
           - Create an engaging academic title
           - Write a compelling abstract
           - Present methodology clearly
           - Discuss findings systematically
           - Draw evidence-based conclusions

        4. Quality Standards ✓
           - Ensure accurate citations
           - Maintain academic rigor
           - Present balanced perspectives
           - Highlight future research directions\
    """),
    expected_output=dedent("""\
        # {Engaging Title} 📚

        ## Abstract
        {Concise overview of the research and key findings}

        ## Introduction
        {Context and significance}
        {Research objectives}

        ## Methodology
        {Search strategy}
        {Selection criteria}

        ## Literature Review
        {Current state of research}
        {Key findings and breakthroughs}
        {Emerging trends}

        ## Analysis
        {Critical evaluation}
        {Cross-study comparisons}
        {Research gaps}

        ## Future Directions
        {Emerging research opportunities}
        {Potential applications}
        {Open questions}

        ## Conclusions
        {Summary of key findings}
        {Implications for the field}

        ## References
        {Properly formatted academic citations}

        ---
        Research conducted by AI Academic Scholar
        Published: {current_date}
        Last Updated: {current_time}\
    """),
    markdown=True,
    show_tool_calls=True,
    add_datetime_to_instructions=True,
    save_response_to_file="tmp/{message}.md",
)

# Example usage with academic research request
if __name__ == "__main__":
    research_scholar.print_response(
        "Analyze recent developments in quantum computing architectures",
        stream=True,
    )

# Advanced research topics to explore:
"""
Quantum Science & Computing:
1. "Investigate recent breakthroughs in quantum error correction"
2. "Analyze the development of topological quantum computing"
3. "Research quantum machine learning algorithms and applications"
4. "Explore advances in quantum sensing technologies"

Biotechnology & Medicine:
1. "Examine recent developments in mRNA vaccine technology"
2. "Analyze breakthroughs in organoid research"
3. "Investigate advances in precision medicine"
4. "Research developments in neurotechnology"

Materials Science:
1. "Explore recent advances in metamaterials"
2. "Analyze developments in 2D materials beyond graphene"
3. "Research progress in self-healing materials"
4. "Investigate new battery technologies"

Artificial Intelligence:
1. "Examine recent advances in foundation models"
2. "Analyze developments in AI safety research"
3. "Research progress in neuromorphic computing"
4. "Investigate advances in explainable AI"
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai exa_py agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python research_agent_exa.py
    ```
  </Step>
</Steps>


# Teaching Assistant



Coming soon...


# Travel Agent



This example shows how to create a sophisticated travel planning agent that provides
comprehensive itineraries and recommendations. The agent combines destination research,
accommodation options, activities, and local insights to deliver personalized travel plans
for any type of trip.

Example prompts to try:

* "Plan a 5-day cultural exploration trip to Kyoto for a family of 4"
* "Create a romantic weekend getaway in Paris with a \$2000 budget"
* "Organize a 7-day adventure trip to New Zealand for solo travel"
* "Design a tech company offsite in Barcelona for 20 people"
* "Plan a luxury honeymoon in Maldives for 10 days"

```python travel_planner.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.exa import ExaTools

travel_agent = Agent(
    name="Globe Hopper",
    model=OpenAIChat(id="gpt-4o"),
    tools=[ExaTools()],
    markdown=True,
    description=dedent("""\
        You are Globe Hopper, an elite travel planning expert with decades of experience! 🌍

        Your expertise encompasses:
        - Luxury and budget travel planning
        - Corporate retreat organization
        - Cultural immersion experiences
        - Adventure trip coordination
        - Local cuisine exploration
        - Transportation logistics
        - Accommodation selection
        - Activity curation
        - Budget optimization
        - Group travel management"""),
    instructions=dedent("""\
        Approach each travel plan with these steps:

        1. Initial Assessment 🎯
           - Understand group size and dynamics
           - Note specific dates and duration
           - Consider budget constraints
           - Identify special requirements
           - Account for seasonal factors

        2. Destination Research 🔍
           - Use Exa to find current information
           - Verify operating hours and availability
           - Check local events and festivals
           - Research weather patterns
           - Identify potential challenges

        3. Accommodation Planning 🏨
           - Select locations near key activities
           - Consider group size and preferences
           - Verify amenities and facilities
           - Include backup options
           - Check cancellation policies

        4. Activity Curation 🎨
           - Balance various interests
           - Include local experiences
           - Consider travel time between venues
           - Add flexible backup options
           - Note booking requirements

        5. Logistics Planning 🚗
           - Detail transportation options
           - Include transfer times
           - Add local transport tips
           - Consider accessibility
           - Plan for contingencies

        6. Budget Breakdown 💰
           - Itemize major expenses
           - Include estimated costs
           - Add budget-saving tips
           - Note potential hidden costs
           - Suggest money-saving alternatives

        Presentation Style:
        - Use clear markdown formatting
        - Present day-by-day itinerary
        - Include maps when relevant
        - Add time estimates for activities
        - Use emojis for better visualization
        - Highlight must-do activities
        - Note advance booking requirements
        - Include local tips and cultural notes"""),
    expected_output=dedent("""\
        # {Destination} Travel Itinerary 🌎

        ## Overview
        - **Dates**: {dates}
        - **Group Size**: {size}
        - **Budget**: {budget}
        - **Trip Style**: {style}

        ## Accommodation 🏨
        {Detailed accommodation options with pros and cons}

        ## Daily Itinerary

        ### Day 1
        {Detailed schedule with times and activities}

        ### Day 2
        {Detailed schedule with times and activities}

        [Continue for each day...]

        ## Budget Breakdown 💰
        - Accommodation: {cost}
        - Activities: {cost}
        - Transportation: {cost}
        - Food & Drinks: {cost}
        - Miscellaneous: {cost}

        ## Important Notes ℹ️
        {Key information and tips}

        ## Booking Requirements 📋
        {What needs to be booked in advance}

        ## Local Tips 🗺️
        {Insider advice and cultural notes}

        ---
        Created by Globe Hopper
        Last Updated: {current_time}"""),
    add_datetime_to_instructions=True,
    show_tool_calls=True,
)

# Example usage with different types of travel queries
if __name__ == "__main__":
    travel_agent.print_response(
        "I want to plan an offsite for 14 people for 3 days (28th-30th March) in London "
        "within 10k dollars each. Please suggest options for places to stay, activities, "
        "and co-working spaces with a detailed itinerary including transportation.",
        stream=True,
    )

# More example prompts to explore:
"""
Corporate Events:
1. "Plan a team-building retreat in Costa Rica for 25 people"
2. "Organize a tech conference after-party in San Francisco"
3. "Design a wellness retreat in Bali for 15 employees"
4. "Create an innovation workshop weekend in Stockholm"

Cultural Experiences:
1. "Plan a traditional arts and crafts tour in Kyoto"
2. "Design a food and wine exploration in Tuscany"
3. "Create a historical journey through Ancient Rome"
4. "Organize a festival-focused trip to India"

Adventure Travel:
1. "Plan a hiking expedition in Patagonia"
2. "Design a safari experience in Tanzania"
3. "Create a diving trip in the Great Barrier Reef"
4. "Organize a winter sports adventure in the Swiss Alps"

Luxury Experiences:
1. "Plan a luxury wellness retreat in the Maldives"
2. "Design a private yacht tour of the Greek Islands"
3. "Create a gourmet food tour in Paris"
4. "Organize a luxury train journey through Europe"
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai exa_py agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export OPENAI_API_KEY=****
    export EXA_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python travel_planner.py
    ```
  </Step>
</Steps>


# Youtube Agent



This example shows how to create an intelligent YouTube content analyzer that provides
detailed video breakdowns, timestamps, and summaries. Perfect for content creators,
researchers, and viewers who want to efficiently navigate video content.

Example prompts to try:

* "Analyze this tech review: \[video\_url]"
* "Get timestamps for this coding tutorial: \[video\_url]"
* "Break down the key points of this lecture: \[video\_url]"
* "Summarize the main topics in this documentary: \[video\_url]"
* "Create a study guide from this educational video: \[video\_url]"

## Code

```python youtube_agent.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.youtube import YouTubeTools

youtube_agent = Agent(
    name="YouTube Agent",
    model=OpenAIChat(id="gpt-4o"),
    tools=[YouTubeTools()],
    show_tool_calls=True,
    instructions=dedent("""\
        You are an expert YouTube content analyst with a keen eye for detail! 🎓
        Follow these steps for comprehensive video analysis:
        1. Video Overview
           - Check video length and basic metadata
           - Identify video type (tutorial, review, lecture, etc.)
           - Note the content structure
        2. Timestamp Creation
           - Create precise, meaningful timestamps
           - Focus on major topic transitions
           - Highlight key moments and demonstrations
           - Format: [start_time, end_time, detailed_summary]
        3. Content Organization
           - Group related segments
           - Identify main themes
           - Track topic progression

        Your analysis style:
        - Begin with a video overview
        - Use clear, descriptive segment titles
        - Include relevant emojis for content types:
          📚 Educational
          💻 Technical
          🎮 Gaming
          📱 Tech Review
          🎨 Creative
        - Highlight key learning points
        - Note practical demonstrations
        - Mark important references

        Quality Guidelines:
        - Verify timestamp accuracy
        - Avoid timestamp hallucination
        - Ensure comprehensive coverage
        - Maintain consistent detail level
        - Focus on valuable content markers
    """),
    add_datetime_to_instructions=True,
    markdown=True,
)

# Example usage with different types of videos
youtube_agent.print_response(
    "Analyze this video: https://www.youtube.com/watch?v=zjkBMFhNj_g",
    stream=True,
)

# More example prompts to explore:
"""
Tutorial Analysis:
1. "Break down this Python tutorial with focus on code examples"
2. "Create a learning path from this web development course"
3. "Extract all practical exercises from this programming guide"
4. "Identify key concepts and implementation examples"

Educational Content:
1. "Create a study guide with timestamps for this math lecture"
2. "Extract main theories and examples from this science video"
3. "Break down this historical documentary into key events"
4. "Summarize the main arguments in this academic presentation"

Tech Reviews:
1. "List all product features mentioned with timestamps"
2. "Compare pros and cons discussed in this review"
3. "Extract technical specifications and benchmarks"
4. "Identify key comparison points and conclusions"

Creative Content:
1. "Break down the techniques shown in this art tutorial"
2. "Create a timeline of project steps in this DIY video"
3. "List all tools and materials mentioned with timestamps"
4. "Extract tips and tricks with their demonstrations"
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai youtube_transcript_api agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python youtube_agent.py
    ```
  </Step>
</Steps>


# Agentic RAG



This example application shows how to build a sophisticated RAG (Retrieval Augmented Generation) system that leverages search of a knowledge base with LLMs to provide deep insights into the data.

## The agent can:

* Process and understand documents from multiple sources (PDFs, websites, text files)
* Build a searchable knowledge base using vector embeddings
* Maintain conversation context and memory across sessions
* Provide relevant citations and sources for its responses
* Generate summaries and extract key insights
* Answer follow-up questions and clarifications

## The agent uses:

* Vector similarity search for relevant document retrieval
* Conversation memory for contextual responses
* Citation tracking for source attribution
* Dynamic knowledge base updates

<video autoPlay muted controls className="w-full aspect-video" src="https://mintlify.s3.us-west-1.amazonaws.com/agno/videos/agentic_rag.mp4" />

## Example queries to try:

* "What are the key points from this document?"
* "Can you summarize the main arguments and supporting evidence?"
* "What are the important statistics and findings?"
* "How does this relate to \[topic X]?"
* "What are the limitations or gaps in this analysis?"
* "Can you explain \[concept X] in more detail?"
* "What other sources support or contradict these claims?"

## Code

The complete code is available in the [Agno repository](https://github.com/agno-agi/agno).

## Usage

<Steps>
  <Step title="Clone the repository">
    ```bash
    git clone https://github.com/agno-agi/agno.git
    cd agno
    ```
  </Step>

  <Step title="Create virtual environment">
    ```bash
    python3 -m venv .venv
    source .venv/bin/activate
    ```
  </Step>

  <Step title="Install dependencies">
    ```bash
    pip install -r cookbook/examples/apps/agentic_rag/requirements.txt
    ```
  </Step>

  <Step title="Run PgVector">
    First, install [Docker Desktop](https://docs.docker.com/desktop/install/mac-install/).

    Then run either using the helper script:

    ```bash
    ./cookbook/scripts/run_pgvector.sh
    ```

    Or directly with Docker:

    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Set up API keys">
    ```bash
    # Required
    export OPENAI_API_KEY=***
    # Optional
    export ANTHROPIC_API_KEY=***
    export GOOGLE_API_KEY=***

    ```

    We recommend using gpt-4o for optimal performance.
  </Step>

  <Step title="Launch the app">
    ```bash
    streamlit run cookbook/examples/apps/agentic_rag/app.py
    ```

    Open [localhost:8501](http://localhost:8501) to start using the Agentic RAG.
  </Step>
</Steps>

Need help? Join our [Discourse community](https://community.agno.com) for support!


# Chess Battle



Chess Battle is a chess application where multiple AI agents collaborate to play chess against each other, demonstrating the power of multi-agent systems in complex game environments.

### Key Capabilities

* Multi-Agent System: Features White and Black Piece Agents for move selection
* Move Validation: Dedicated Legal Move Agent ensures game rule compliance
* Game Coordination: Master Agent oversees the game flow and end conditions
* Interactive UI: Built with Streamlit for real-time game visualization

<video autoPlay muted controls className="w-full aspect-video" src="https://mintlify.s3.us-west-1.amazonaws.com/agno/videos/chess-team.mp4" />

### System Components

* White Piece Agent: Strategizes and selects moves for white pieces
* Black Piece Agent: Controls and determines moves for black pieces
* Legal Move Agent: Validates all proposed moves against chess rules
* Master Agent: Coordinates the game flow and monitors game status

### Advanced Features

The system demonstrates complex agent interactions where each AI component has a specific role. The agents communicate and coordinate to create a complete chess-playing experience, showcasing how multiple specialized AIs can work together effectively.

### Code

The complete code is available in the [Agno repository](https://github.com/agno-agi/agno/tree/main/cookbook/examples/apps/chess_team).

### Usage

<Steps>
  <Step title="Clone the repository">
    ```bash
    git clone https://github.com/agno-agi/agno.git
    cd agno
    ```
  </Step>

  <Step title="Create a Virtual Environment">
    ```bash
    python3 -m venv .venv
    source .venv/bin/activate  # On Windows use: .venv\Scripts\activate
    ```
  </Step>

  <Step title="Install Dependencies">
    ```bash
    pip install -r cookbook/examples/apps/chess_team/requirements.txt
    ```
  </Step>

  <Step title="Set up API Key">
    The Chess Team Agent uses the Anthropic API for agent reasoning:

    ```bash
    export ANTHROPIC_API_KEY=your_api_key_here
    ```
  </Step>

  <Step title="Launch the App">
    ```bash
    streamlit run cookbook/examples/apps/chess_team/app.py
    ```
  </Step>

  <Step title="Open the App">
    Then, open [http://localhost:8501](http://localhost:8501) in your browser to start watching the AI agents play chess.
  </Step>
</Steps>

### Pro Tips

* Watch Complete Games: Observe full matches to understand agent decision-making
* Monitor Agent Interactions: Pay attention to how agents communicate and coordinate

Need help? Join our [Discourse community](https://agno.link/community) for support!


# Game Generator



**GameGenerator** generates HTML5 games based on user descriptions.

Create a file `game_generator.py` with the following code:

```python game_generator.py
import json
from pathlib import Path
from typing import Iterator

from agno.agent import Agent, RunResponse
from agno.models.openai import OpenAIChat
from agno.run.response import RunEvent
from agno.storage.workflow.sqlite import SqliteWorkflowStorage
from agno.utils.log import logger
from agno.utils.pprint import pprint_run_response
from agno.utils.string import hash_string_sha256
from agno.utils.web import open_html_file
from agno.workflow import Workflow
from pydantic import BaseModel, Field

games_dir = Path(__file__).parent.joinpath("games")
games_dir.mkdir(parents=True, exist_ok=True)
game_output_path = games_dir / "game_output_file.html"
game_output_path.unlink(missing_ok=True)


class GameOutput(BaseModel):
    reasoning: str = Field(..., description="Explain your reasoning")
    code: str = Field(..., description="The html5 code for the game")
    instructions: str = Field(..., description="Instructions how to play the game")


class QAOutput(BaseModel):
    reasoning: str = Field(..., description="Explain your reasoning")
    correct: bool = Field(False, description="Does the game pass your criteria?")


class GameGenerator(Workflow):
    # This description is only used in the workflow UI
    description: str = "Generator for single-page HTML5 games"

    game_developer: Agent = Agent(
        name="Game Developer Agent",
        description="You are a game developer that produces working HTML5 code.",
        model=OpenAIChat(id="gpt-4o"),
        instructions=[
            "Create a game based on the user's prompt. "
            "The game should be HTML5, completely self-contained and must be runnable simply by opening on a browser",
            "Ensure the game has a alert that pops up if the user dies and then allows the user to restart or exit the game.",
            "Ensure instructions for the game are displayed on the HTML page."
            "Use user-friendly colours and make the game canvas large enough for the game to be playable on a larger screen.",
        ],
        response_model=GameOutput,
    )

    qa_agent: Agent = Agent(
        name="QA Agent",
        model=OpenAIChat(id="gpt-4o"),
        description="You are a game QA and you evaluate html5 code for correctness.",
        instructions=[
            "You will be given some HTML5 code."
            "Your task is to read the code and evaluate it for correctness, but also that it matches the original task description.",
        ],
        response_model=QAOutput,
    )

    def run(self, game_description: str) -> Iterator[RunResponse]:
        logger.info(f"Game description: {game_description}")

        game_output = self.game_developer.run(game_description)

        if (
            game_output
            and game_output.content
            and isinstance(game_output.content, GameOutput)
        ):
            game_code = game_output.content.code
            logger.info(f"Game code: {game_code}")
        else:
            yield RunResponse(
                run_id=self.run_id,
                event=RunEvent.workflow_completed,
                content="Sorry, could not generate a game.",
            )
            return

        logger.info("QA'ing the game code")
        qa_input = {
            "game_description": game_description,
            "game_code": game_code,
        }
        qa_output = self.qa_agent.run(json.dumps(qa_input, indent=2))

        if qa_output and qa_output.content and isinstance(qa_output.content, QAOutput):
            logger.info(qa_output.content)
            if not qa_output.content.correct:
                raise Exception(f"QA failed for code: {game_code}")

            # Store the resulting code
            game_output_path.write_text(game_code)

            yield RunResponse(
                run_id=self.run_id,
                event=RunEvent.workflow_completed,
                content=game_output.content.instructions,
            )
        else:
            yield RunResponse(
                run_id=self.run_id,
                event=RunEvent.workflow_completed,
                content="Sorry, could not QA the game.",
            )
            return


# Run the workflow if the script is executed directly
if __name__ == "__main__":
    from rich.prompt import Prompt

    game_description = Prompt.ask(
        "[bold]Describe the game you want to make (keep it simple)[/bold]\n✨",
        # default="An asteroids game."
        default="An asteroids game. Make sure the asteroids move randomly and are random sizes. They should continually spawn more and become more difficult over time. Keep score. Make my spaceship's movement realistic.",
    )

    hash_of_description = hash_string_sha256(game_description)

    # Initialize the investment analyst workflow
    game_generator = GameGenerator(
        session_id=f"game-gen-{hash_of_description}",
        storage=SqliteWorkflowStorage(
            table_name="game_generator_workflows",
            db_file="tmp/workflows.db",
        ),
    )

    # Execute the workflow
    result: Iterator[RunResponse] = game_generator.run(
        game_description=game_description
    )

    # Print the report
    pprint_run_response(result)

    if game_output_path.exists():
        open_html_file(game_output_path)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python game_generator.py.py
    ```
  </Step>
</Steps>


# GeoBuddy



GeoBuddy is a geography agent that analyzes images to predict locations based on visible cues such as landmarks, architecture, and cultural symbols.

### Key Capabilities

* Location Identification: Predicts location details from uploaded images
* Detailed Reasoning: Explains predictions based on visual cues
* User-Friendly Ul: Built with Streamlit for an intuitive experience

<video autoPlay muted controls className="w-full aspect-video" src="https://mintlify.s3.us-west-1.amazonaws.com/agno/videos/geobuddy.mp4" />

### Simple Examples to Try

* Landscape: A city skyline, a mountain panorama, or a famous landmark
* Architecture: Distinct buildings, bridges, or unique cityscapes
* Cultural Clues: Text on signboards, language hints, flags, or unique clothing

### Advanced Usage

Try providing images with subtle details, like store signs in different languages or iconic but less globally famous landmarks. GeoBuddy will attempt to reason more deeply about architectural style, environment (e.g. desert vs. tropical), and cultural references.

### Code

The complete code is available in the [Agno repository](https://github.com/agno-agi/agno).

### Usage

<Steps>
  <Step title="Clone the repository">
    ```bash
    git clone https://github.com/agno-agi/agno.git
    cd agno
    ```
  </Step>

  <Step title="Create a Virtual Environment">
    ```bash
    python3 -m venv .venv
    source .venv/bin/activate
    ```
  </Step>

  <Step title="Install Dependencies">
    ```bash
    pip install -r cookbook/examples/apps/geobuddy/requirements.txt
    ```
  </Step>

  <Step title="Set up API Key">
    GeoBuddy uses the Google PaLM API for advanced image reasoning:

    ```bash
    export GOOGLE_API_KEY=***
    ```
  </Step>

  <Step title="Launch the App">
    ```bash
    streamlit run cookbook/examples/apps/geobuddy/app.py
    ```
  </Step>

  <Step title="Open the App">
    Then, open [http://localhost:8501](http://localhost:8501) in your browser to start using GeoBuddy.
  </Step>
</Steps>

### Pro Tips

* High-Resolution Images: Clearer images with visible signboards or landmarks improve accuracy.
* Variety of Angles: Different angles (e.g. street-level vs. aerial views) can showcase unique clues.
* Contextual Clues: Sometimes minor details like license plates, local architectural elements or even vegetation can significantly influence the location guess.

Need help? Join our [Discourse community](https://community.agno.com) for support!


# SQL Agent



This example shows how to build a text-to-SQL system that:

1. Uses Agentic RAG to search for table metadata, sample queries and rules for writing better SQL queries.
2. Uses dynamic few-shot examples and rules to improve query construction.
3. Provides an interactive Streamlit UI for users to query the database.

We'll use the F1 dataset as an example, but you can easily extend it to other datasets.

### Key capabilities

* Natural language to SQL conversion
* Retrieve table metadata, sample queries and rules using Agentic RAG
* Better query construction with the help of dynamic few-shot examples and rules
* Interactive Streamlit UI

<video autoPlay muted controls className="w-full aspect-video" src="https://mintlify.s3.us-west-1.amazonaws.com/agno/videos/sql_agent.mp4" />

### Simple queries to try

* "Who are the top 5 drivers with the most race wins?"
* "Compare Mercedes vs Ferrari performance in constructors championships"
* "Show me the progression of fastest lap times at Monza"
* "Which drivers have won championships with multiple teams?"
* "What tracks have hosted the most races?"
* "Show me Lewis Hamilton's win percentage by season"

### Advanced queries with table joins

* "How many races did the championship winners win each year?"
* "Compare the number of race wins vs championship positions for constructors in 2019"
* "Show me Lewis Hamilton's race wins and championship positions by year"
* "Which drivers have both won races and set fastest laps at Monaco?"
* "Show me Ferrari's race wins and constructor championship positions from 2015-2020"

## Code

The complete code is available in the [Agno repository](https://github.com/agno-agi/agno).

## Usage

<Steps>
  <Step title="Clone the repository">
    ```bash
    git clone https://github.com/agno-agi/agno.git
    cd agno
    ```
  </Step>

  <Step title="Create virtual environment">
    ```bash
    python3 -m venv .venv
    source .venv/bin/activate
    ```
  </Step>

  <Step title="Install dependencies">
    ```bash
    pip install -r cookbook/examples/apps/sql_agent/requirements.txt
    ```
  </Step>

  <Step title="Run PgVector">
    First, install [Docker Desktop](https://docs.docker.com/desktop/install/mac-install/).

    Then run either using the helper script:

    ```bash
    ./cookbook/scripts/run_pgvector.sh
    ```

    Or directly with Docker:

    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Load F1 data">
    ```bash
    python cookbook/examples/apps/sql_agent/load_f1_data.py
    ```
  </Step>

  <Step title="Load knowledge base">
    The knowledge base contains table metadata, rules and sample queries that help the Agent generate better responses.

    ```bash
    python cookbook/examples/apps/sql_agent/load_knowledge.py
    ```

    Pro tips for enhancing the knowledge base:

    * Add `table_rules` and `column_rules` to guide the Agent on query formats
    * Add sample queries to `cookbook/examples/apps/sql_agent/knowledge_base/sample_queries.sql`
  </Step>

  <Step title="Set up API keys">
    ```bash
    # Required
    export OPENAI_API_KEY=***

    # Optional
    export ANTHROPIC_API_KEY=***
    export GOOGLE_API_KEY=***
    export GROQ_API_KEY=***
    ```

    We recommend using gpt-4o for optimal performance.
  </Step>

  <Step title="Launch the app">
    ```bash
    streamlit run cookbook/examples/apps/sql_agent/app.py
    ```

    Open [localhost:8501](http://localhost:8501) to start using the SQL Agent.
  </Step>
</Steps>

Need help? Join our [Discourse community](https://community.agno.com) for support!


# Basic Async



## Code

```python cookbook/agent_concepts/async/basic.py
import asyncio

from agno.agent import Agent
from agno.models.openai import OpenAIChat

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    description="You help people with their health and fitness goals.",
    instructions=["Recipes should be under 5 ingredients"],
    markdown=True,
)
# -*- Print a response to the cli
asyncio.run(agent.aprint_response("Share a breakfast recipe.", stream=True))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/async/basic.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/async/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Data Analyst



## Code

```python cookbook/agent_concepts/async/data_analyst.py
import asyncio
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckdb import DuckDbTools

duckdb_tools = DuckDbTools(
    create_tables=False, export_tables=False, summarize_tables=False
)
duckdb_tools.create_table_from_path(
    path="https://agno-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv",
    table="movies",
)

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    tools=[duckdb_tools],
    markdown=True,
    show_tool_calls=True,
    additional_context=dedent("""\
    You have access to the following tables:
    - movies: contains information about movies from IMDB.
    """),
)
asyncio.run(
    agent.aprint_response("What is the average rating of movies?", stream=False)
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno duckdb
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/async/data_analyst.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/async/data_analyst.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Gather Multiple Agents



## Code

```python cookbook/agent_concepts/async/gather_agents.py
import asyncio

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from rich.pretty import pprint

providers = ["openai", "anthropic", "ollama", "cohere", "google"]
instructions = [
    "Your task is to write a well researched report on AI providers.",
    "The report should be unbiased and factual.",
]


async def get_reports():
    tasks = []
    for provider in providers:
        agent = Agent(
            model=OpenAIChat(id="gpt-4"),
            instructions=instructions,
            tools=[DuckDuckGoTools()],
        )
        tasks.append(
            agent.arun(f"Write a report on the following AI provider: {provider}")
        )

    results = await asyncio.gather(*tasks)
    return results


async def main():
    results = await get_reports()
    for result in results:
        print("************")
        pprint(result.content)
        print("************")
        print("\n")


if __name__ == "__main__":
    asyncio.run(main())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno rich duckduckgo-search
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/async/gather_agents.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/async/gather_agents.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Reasoning Agent



## Code

```python cookbook/agent_concepts/async/reasoning.py
import asyncio

from agno.agent import Agent
from agno.cli.console import console
from agno.models.openai import OpenAIChat

task = "9.11 and 9.9 -- which is bigger?"

regular_agent = Agent(model=OpenAIChat(id="gpt-4o"), markdown=True)
reasoning_agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    reasoning=True,
    markdown=True,
    structured_outputs=True,
)

console.rule("[bold green]Regular Agent[/bold green]")
asyncio.run(regular_agent.aprint_response(task, stream=True))
console.rule("[bold yellow]Reasoning Agent[/bold yellow]")
asyncio.run(
    reasoning_agent.aprint_response(task, stream=True, show_full_reasoning=True)
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/async/reasoning.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/async/reasoning.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Structured Outputs



## Code

```python cookbook/agent_concepts/async/structured_output.py
import asyncio
from typing import List

from agno.agent import Agent, RunResponse  # noqa
from agno.models.openai import OpenAIChat
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


# Agent that uses JSON mode
json_mode_agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    description="You write movie scripts.",
    response_model=MovieScript,
)

# Agent that uses structured outputs
structured_output_agent = Agent(
    model=OpenAIChat(id="gpt-4o-2024-08-06"),
    description="You write movie scripts.",
    response_model=MovieScript,
    structured_outputs=True,
)


asyncio.run(json_mode_agent.aprint_response("New York"))
asyncio.run(structured_output_agent.aprint_response("New York"))
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/async/structured_output.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/async/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Azure OpenAI Embedder



## Code

```python
from agno.agent import AgentKnowledge
from agno.embedder.azure_openai import AzureOpenAIEmbedder
from agno.vectordb.pgvector import PgVector

embeddings = AzureOpenAIEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge_base = AgentKnowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="azure_openai_embeddings",
        embedder=AzureOpenAIEmbedder(),
    ),
    num_documents=2,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export AZURE_EMBEDDER_OPENAI_API_KEY=xxx
    export AZURE_EMBEDDER_OPENAI_ENDPOINT=xxx
    export AZURE_EMBEDDER_DEPLOYMENT=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy 'psycopg[binary]' pgvector openai agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/knowledge/embedders/azure_embedder.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/knowledge/embedders/azure_embedder.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Cohere Embedder



## Code

```python
from agno.agent import AgentKnowledge
from agno.embedder.cohere import CohereEmbedder
from agno.vectordb.pgvector import PgVector

embeddings = CohereEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)
# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge_base = AgentKnowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="cohere_embeddings",
        embedder=CohereEmbedder(),
    ),
    num_documents=2,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export COHERE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy 'psycopg[binary]' pgvector cohere agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/knowledge/embedders/cohere_embedder.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/knowledge/embedders/cohere_embedder.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Fireworks Embedder



## Code

```python
from agno.agent import AgentKnowledge
from agno.embedder.fireworks import FireworksEmbedder
from agno.vectordb.pgvector import PgVector

embeddings = FireworksEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge_base = AgentKnowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="fireworks_embeddings",
        embedder=FireworksEmbedder(),
    ),
    num_documents=2,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export FIREWORKS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy 'psycopg[binary]' pgvector fireworks-ai agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/knowledge/embedders/fireworks_embedder.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/knowledge/embedders/fireworks_embedder.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Gemini Embedder



## Code

```python
from agno.agent import AgentKnowledge
from agno.embedder.google import GeminiEmbedder
from agno.vectordb.pgvector import PgVector

embeddings = GeminiEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge_base = AgentKnowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="gemini_embeddings",
        embedder=GeminiEmbedder(dimensions=1536),
    ),
    num_documents=2,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy 'psycopg[binary]' pgvector google-generativeai agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/knowledge/embedders/gemini_embedder.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/knowledge/embedders/gemini_embedder.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Huggingface Embedder



## Code

```python
from agno.agent import AgentKnowledge
from agno.embedder.huggingface import HuggingfaceCustomEmbedder
from agno.vectordb.pgvector import PgVector

embeddings = HuggingfaceCustomEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge_base = AgentKnowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="huggingface_embeddings",
        embedder=HuggingfaceCustomEmbedder(),
    ),
    num_documents=2,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export HUGGINGFACE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy 'psycopg[binary]' pgvector huggingface-hub agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/knowledge/embedders/huggingface_embedder.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/knowledge/embedders/huggingface_embedder.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Mistral Embedder



## Code

```python
from agno.agent import AgentKnowledge
from agno.embedder.mistral import MistralEmbedder
from agno.vectordb.pgvector import PgVector

embeddings = MistralEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge_base = AgentKnowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="mistral_embeddings",
        embedder=MistralEmbedder(),
    ),
    num_documents=2,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export MISTRAL_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy 'psycopg[binary]' pgvector mistralai agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/knowledge/embedders/mistral_embedder.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/knowledge/embedders/mistral_embedder.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Ollama Embedder



## Code

```python
from agno.agent import AgentKnowledge
from agno.embedder.ollama import OllamaEmbedder
from agno.vectordb.pgvector import PgVector

embeddings = OllamaEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge_base = AgentKnowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="ollama_embeddings",
        embedder=OllamaEmbedder(),
    ),
    num_documents=2,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the installation instructions at [Ollama's website](https://ollama.ai)
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy 'psycopg[binary]' pgvector agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/knowledge/embedders/ollama_embedder.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/knowledge/embedders/ollama_embedder.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# OpenAI Embedder



## Code

```python
from agno.agent import AgentKnowledge
from agno.embedder.openai import OpenAIEmbedder
from agno.vectordb.pgvector import PgVector

embeddings = OpenAIEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge_base = AgentKnowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="openai_embeddings",
        embedder=OpenAIEmbedder(),
    ),
    num_documents=2,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy 'psycopg[binary]' pgvector openai agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/knowledge/embedders/openai_embedder.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/knowledge/embedders/openai_embedder.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Qdrant FastEmbed Embedder



## Code

```python
from agno.agent import AgentKnowledge
from agno.embedder.fastembed import FastEmbedEmbedder
from agno.vectordb.pgvector import PgVector

embeddings = FastEmbedEmbedder().get_embedding(
    "The quick brown fox jumps over the lazy dog."
)

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Example usage:
knowledge_base = AgentKnowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="qdrant_embeddings",
        embedder=FastEmbedEmbedder(),
    ),
    num_documents=2,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy 'psycopg[binary]' pgvector fastembed agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/knowledge/embedders/qdrant_fastembed.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/knowledge/embedders/qdrant_fastembed.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# LanceDB Hybrid Search



## Code

```python cookbook/agent_concepts/hybrid_search/lancedb/agent.py
from typing import Optional

import typer
from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.lancedb import LanceDb
from agno.vectordb.search import SearchType
from rich.prompt import Prompt

vector_db = LanceDb(
    table_name="recipes",
    uri="tmp/lancedb",
    search_type=SearchType.hybrid,
)

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=vector_db,
)

def lancedb_agent(user: str = "user"):
    agent = Agent(
        user_id=user,
        knowledge=knowledge_base,
        search_knowledge=True,
        show_tool_calls=True,
        debug_mode=True,
    )

    while True:
        message = Prompt.ask(f"[bold] :sunglasses: {user} [/bold]")
        if message in ("exit", "bye"):
            break
        agent.print_response(message)

if __name__ == "__main__":
    # Comment out after first run
    knowledge_base.load(recreate=False)

    typer.run(lancedb_agent)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U lancedb tantivy pypdf openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/hybrid_search/lancedb/agent.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/hybrid_search/lancedb/agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# PgVector Hybrid Search



## Code

```python
from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.models.openai import OpenAIChat
from agno.vectordb.pgvector import PgVector, SearchType

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=PgVector(
        table_name="recipes", db_url=db_url, search_type=SearchType.hybrid
    ),
)
# Load the knowledge base: Comment out after first run
knowledge_base.load(recreate=False)

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    knowledge=knowledge_base,
    search_knowledge=True,
    read_chat_history=True,
    show_tool_calls=True,
    markdown=True,
)
agent.print_response(
    "How do I make chicken and galangal in coconut milk soup", stream=True
)
agent.print_response("What was my last question?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U pgvector pypdf "psycopg[binary]" sqlalchemy openai agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    ./cookbook/scripts/run_pgvector.sh
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/hybrid_search/pgvector/agent.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/hybrid_search/pgvector/agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Pinecone Hybrid Search



## Code

```python
import os
from typing import Optional

import nltk  # type: ignore
import typer
from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.pineconedb import PineconeDb
from rich.prompt import Prompt

nltk.download("punkt")
nltk.download("punkt_tab")

api_key = os.getenv("PINECONE_API_KEY")
index_name = "thai-recipe-hybrid-search"

vector_db = PineconeDb(
    name=index_name,
    dimension=1536,
    metric="cosine",
    spec={"serverless": {"cloud": "aws", "region": "us-east-1"}},
    api_key=api_key,
    use_hybrid_search=True,
    hybrid_alpha=0.5,
)

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=vector_db,
)


def pinecone_agent(user: str = "user"):
    agent = Agent(
        user_id=user,
        knowledge=knowledge_base,
        search_knowledge=True,
        show_tool_calls=True,
    )

    while True:
        message = Prompt.ask(f"[bold] :sunglasses: {user} [/bold]")
        if message in ("exit", "bye"):
            break
        agent.print_response(message)


if __name__ == "__main__":
    # Comment out after first run
    knowledge_base.load(recreate=False, upsert=True)

    typer.run(pinecone_agent)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export OPENAI_API_KEY=xxx
    export PINECONE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U pinecone pinecone-text pypdf openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/hybrid_search/pinecone/agent.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/hybrid_search/pinecone/agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# ArXiv Knowledge Base



## Code

```python
from agno.agent import Agent
from agno.knowledge.arxiv import ArxivKnowledgeBase
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

# Create a knowledge base with the ArXiv documents
knowledge_base = ArxivKnowledgeBase(
    queries=["Generative AI", "Machine Learning"],
    # Table name: ai.arxiv_documents
    vector_db=PgVector(
        table_name="arxiv_documents",
        db_url=db_url,
    ),
)
# Load the knowledge base
knowledge_base.load(recreate=False)

# Create an agent with the knowledge base
agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
)

# Ask the agent about the knowledge base
agent.print_response(
    "Ask me about generative ai from the knowledge base", markdown=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy 'psycopg[binary]' pgvector agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/knowledge/arxiv_kb.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/knowledge/arxiv_kb.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Combined Knowledge Base



## Code

```python
from pathlib import Path

from agno.agent import Agent
from agno.knowledge.combined import CombinedKnowledgeBase
from agno.knowledge.csv import CSVKnowledgeBase
from agno.knowledge.pdf import PDFKnowledgeBase
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.knowledge.website import WebsiteKnowledgeBase
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

# Create CSV knowledge base
csv_kb = CSVKnowledgeBase(
    path=Path("data/csvs"),
    vector_db=PgVector(
        table_name="csv_documents",
        db_url=db_url,
    ),
)

# Create PDF URL knowledge base
pdf_url_kb = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=PgVector(
        table_name="pdf_documents",
        db_url=db_url,
    ),
)

# Create Website knowledge base
website_kb = WebsiteKnowledgeBase(
    urls=["https://docs.agno.com/introduction"],
    max_links=10,
    vector_db=PgVector(
        table_name="website_documents",
        db_url=db_url,
    ),
)

# Create Local PDF knowledge base
local_pdf_kb = PDFKnowledgeBase(
    path="data/pdfs",
    vector_db=PgVector(
        table_name="pdf_documents",
        db_url=db_url,
    ),
)

# Combine knowledge bases
knowledge_base = CombinedKnowledgeBase(
    sources=[
        csv_kb,
        pdf_url_kb,
        website_kb,
        local_pdf_kb,
    ],
    vector_db=PgVector(
        table_name="combined_documents",
        db_url=db_url,
    ),
)

# Initialize the Agent with the combined knowledge base
agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
)

knowledge_base.load(recreate=False)

# Use the agent
agent.print_response("Ask me about something from the knowledge base", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy 'psycopg[binary]' pgvector pypdf agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/knowledge/combined_kb.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/knowledge/combined_kb.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# CSV Knowledge Base



## Code

```python
from pathlib import Path

from agno.agent import Agent
from agno.knowledge.csv import CSVKnowledgeBase
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = CSVKnowledgeBase(
    path=Path("data/csvs"),
    vector_db=PgVector(
        table_name="csv_documents",
        db_url=db_url,
    ),
    num_documents=5,  # Number of documents to return on search
)
# Load the knowledge base
knowledge_base.load(recreate=False)

# Initialize the Agent with the knowledge_base
agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
)

# Use the agent
agent.print_response("Ask me about something from the knowledge base", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy 'psycopg[binary]' pgvector agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/knowledge/csv_kb.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/knowledge/csv_kb.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# CSV URL Knowledge Base



## Code

```python
from agno.agent import Agent
from agno.knowledge.csv_url import CSVUrlKnowledgeBase
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = CSVUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/csvs/employees.csv"],
    vector_db=PgVector(table_name="csv_documents", db_url=db_url),
)
knowledge_base.load(recreate=False)  # Comment out after first run

agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
)

agent.print_response(
    "What is the average salary of employees in the Marketing department?",
    markdown=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy 'psycopg[binary]' pgvector agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/knowledge/csv_url_kb.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/knowledge/csv_url_kb.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Document Knowledge Base



## Code

```python
from agno.agent import Agent
from agno.document.base import Document
from agno.knowledge.document import DocumentKnowledgeBase
from agno.vectordb.pgvector import PgVector

fun_facts = """
- Earth is the third planet from the Sun and the only known astronomical object to support life.
- Approximately 71% of Earth's surface is covered by water, with the Pacific Ocean being the largest.
- The Earth's atmosphere is composed mainly of nitrogen (78%) and oxygen (21%), with traces of other gases.
- Earth rotates on its axis once every 24 hours, leading to the cycle of day and night.
- The planet has one natural satellite, the Moon, which influences tides and stabilizes Earth's axial tilt.
- Earth's tectonic plates are constantly shifting, leading to geological activities like earthquakes and volcanic eruptions.
- The highest point on Earth is Mount Everest, standing at 8,848 meters (29,029 feet) above sea level.
- The deepest part of the ocean is the Mariana Trench, reaching depths of over 11,000 meters (36,000 feet).
- Earth has a diverse range of ecosystems, from rainforests and deserts to coral reefs and tundras.
- The planet's magnetic field protects life by deflecting harmful solar radiation and cosmic rays.
"""

# Load documents from the data/docs directory
documents = [Document(content=fun_facts)]

# Database connection URL
db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

# Create a knowledge base with the loaded documents
knowledge_base = DocumentKnowledgeBase(
    documents=documents,
    vector_db=PgVector(
        table_name="documents",
        db_url=db_url,
    ),
)

# Load the knowledge base
knowledge_base.load(recreate=False)

# Create an agent with the knowledge base
agent = Agent(
    knowledge=knowledge_base,
)

# Ask the agent about the knowledge base
agent.print_response(
    "Ask me about something from the knowledge base about earth", markdown=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy 'psycopg[binary]' pgvector agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/knowledge/doc_kb.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/knowledge/doc_kb.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# DOCX Knowledge Base



## Code

```python
from pathlib import Path

from agno.agent import Agent
from agno.knowledge.docx import DocxKnowledgeBase
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

# Create a knowledge base with the DOCX files from the data/docs directory
knowledge_base = DocxKnowledgeBase(
    path=Path("data/docs"),
    vector_db=PgVector(
        table_name="docx_documents",
        db_url=db_url,
    ),
)
# Load the knowledge base
knowledge_base.load(recreate=False)

# Create an agent with the knowledge base
agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
)

# Ask the agent about the knowledge base
agent.print_response("Ask me about something from the knowledge base", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy 'psycopg[binary]' pgvector python-docx agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/knowledge/docx_kb.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/knowledge/docx_kb.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Built-in Memory



## Code

```python cookbook/agent_concepts/memory/01_builtin_memory.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from rich.pretty import pprint

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    # Set add_history_to_messages=true to add the previous chat history to the messages sent to the Model.
    add_history_to_messages=True,
    # Number of historical responses to add to the messages.
    num_history_responses=3,
    description="You are a helpful assistant that always responds in a polite, upbeat and positive manner.",
)

# -*- Create a run
agent.print_response("Share a 2 sentence horror story", stream=True)
# -*- Print the messages in the memory
pprint([m.model_dump(include={"role", "content"}) for m in agent.memory.messages])

# -*- Ask a follow up question that continues the conversation
agent.print_response("What was my first message?", stream=True)
# -*- Print the messages in the memory
pprint([m.model_dump(include={"role", "content"}) for m in agent.memory.messages])
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai sqlalchemy agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/memory/01_builtin_memory.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/memory/01_builtin_memory.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Mem0 Memory



## Code

```python cookbook/agent_concepts/memory/08_mem0_memory.py
from agno.agent import Agent, RunResponse
from agno.models.openai import OpenAIChat
from agno.utils.pprint import pprint_run_response
from mem0 import MemoryClient

client = MemoryClient()

user_id = "agno"
messages = [
    {"role": "user", "content": "My name is John Billings."},
    {"role": "user", "content": "I live in NYC."},
    {"role": "user", "content": "I'm going to a concert tomorrow."},
]
# Comment out the following line after running the script once
client.add(messages, user_id=user_id)

agent = Agent(
    model=OpenAIChat(),
    context={"memory": client.get_all(user_id=user_id)},
    add_context=True,
)
run: RunResponse = agent.run("What do you know about me?")

pprint_run_response(run)

messages = [{"role": i.role, "content": str(i.content)} for i in (run.messages or [])]
client.add(messages, user_id=user_id)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai mem0 agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/memory/08_mem0_memory.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/memory/08_mem0_memory.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Memories and Summaries



## Code

```python cookbook/agent_concepts/memory/03_memories_and_summaries.py
import json

from agno.agent import Agent, AgentMemory
from agno.memory.db.sqlite import SqliteMemoryDb
from agno.models.openai import OpenAIChat
from agno.storage.agent.sqlite import SqliteAgentStorage
from rich.console import Console
from rich.json import JSON
from rich.panel import Panel

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    # The memories are personalized for this user
    user_id="john_billings",
    # Store the memories and summary in a table: agent_memory
    memory=AgentMemory(
        db=SqliteMemoryDb(
            table_name="agent_memory",
            db_file="tmp/agent_memory.db",
        ),
        # Create and store personalized memories for this user
        create_user_memories=True,
        # Update memories for the user after each run
        update_user_memories_after_run=True,
        # Create and store session summaries
        create_session_summary=True,
        # Update session summaries after each run
        update_session_summary_after_run=True,
    ),
    # Store agent sessions in a database, that persists between runs
    storage=SqliteAgentStorage(
        table_name="agent_sessions", db_file="tmp/agent_storage.db"
    ),
    # add_history_to_messages=true adds the chat history to the messages sent to the Model.
    add_history_to_messages=True,
    # Number of historical responses to add to the messages.
    num_history_responses=3,
    # Description creates a system prompt for the agent
    description="You are a helpful assistant that always responds in a polite, upbeat and positive manner.",
)

console = Console()


def render_panel(title: str, content: str) -> Panel:
    return Panel(JSON(content, indent=4), title=title, expand=True)


def print_agent_memory(agent):
    # -*- Print history
    console.print(
        render_panel(
            f"Chat History for session_id: {agent.session_id}",
            json.dumps(
                [
                    m.model_dump(include={"role", "content"})
                    for m in agent.memory.messages
                ],
                indent=4,
            ),
        )
    )
    # -*- Print memories
    console.print(
        render_panel(
            f"Memories for user_id: {agent.user_id}",
            json.dumps(
                [
                    m.model_dump(include={"memory", "input"})
                    for m in agent.memory.memories
                ],
                indent=4,
            ),
        )
    )
    # -*- Print summary
    console.print(
        render_panel(
            f"Summary for session_id: {agent.session_id}",
            json.dumps(agent.memory.summary.model_dump(), indent=4),
        )
    )


# -*- Share personal information
agent.print_response("My name is john billings and I live in nyc.", stream=True)
# -*- Print agent memory
print_agent_memory(agent)

# -*- Share personal information
agent.print_response("I'm going to a concert tomorrow?", stream=True)
# -*- Print agent memory
print_agent_memory(agent)

# Ask about the conversation
agent.print_response(
    "What have we been talking about, do you know my name?", stream=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai sqlalchemy agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/memory/03_memories_and_summaries.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/memory/03_memories_and_summaries.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Memories and Summaries with Postgres



## Code

```python cookbook/agent_concepts/memory/05_memories_and_summaries_postgres.py
from agno.agent import Agent, AgentMemory
from agno.memory.db.postgres import PgMemoryDb
from agno.models.openai import OpenAIChat
from agno.storage.agent.postgres import PostgresAgentStorage
from rich.pretty import pprint

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    # Store the memories and summary in a database
    memory=AgentMemory(
        db=PgMemoryDb(table_name="agent_memory", db_url=db_url),
        create_user_memories=True,
        create_session_summary=True,
    ),
    # Store agent sessions in a database
    storage=PostgresAgentStorage(
        table_name="personalized_agent_sessions", db_url=db_url
    ),
    # Show debug logs so, you can see the memory being created
    # debug_mode=True,
)

# -*- Share personal information
agent.print_response("My name is john billings?", stream=True)
# -*- Print memories
pprint(agent.memory.memories)
# -*- Print summary
pprint(agent.memory.summary)

# -*- Share personal information
agent.print_response("I live in nyc?", stream=True)
# -*- Print memories
pprint(agent.memory.memories)
# -*- Print summary
pprint(agent.memory.summary)

# -*- Share personal information
agent.print_response("I'm going to a concert tomorrow?", stream=True)
# -*- Print memories
pprint(agent.memory.memories)
# -*- Print summary
pprint(agent.memory.summary)

# Ask about the conversation
agent.print_response(
    "What have we been talking about, do you know my name?", stream=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai sqlalchemy "psycopg[binary]" pgvector agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    ./cookbook/scripts/run_pgvector.sh
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/memory/05_memories_and_summaries_postgres.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/memory/05_memories_and_summaries_postgres.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Memories and Summaries with SQLite (Async)



## Code

```python cookbook/agent_concepts/memory/06_memories_and_summaries_sqlite_async.py
import asyncio
import json

from agno.agent import Agent, AgentMemory
from agno.memory.db.sqlite import SqliteMemoryDb
from agno.models.openai import OpenAIChat
from agno.storage.agent.sqlite import SqliteAgentStorage
from rich.console import Console
from rich.json import JSON
from rich.panel import Panel

agent_memory_file: str = "tmp/agent_memory.db"
agent_storage_file: str = "tmp/agent_storage.db"

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    # The memories are personalized for this user
    user_id="john_billings",
    # Store the memories and summary in a table: agent_memory
    memory=AgentMemory(
        db=SqliteMemoryDb(
            table_name="agent_memory",
            db_file=agent_memory_file,
        ),
        # Create and store personalized memories for this user
        create_user_memories=True,
        # Update memories for the user after each run
        update_user_memories_after_run=True,
        # Create and store session summaries
        create_session_summary=True,
        # Update session summaries after each run
        update_session_summary_after_run=True,
    ),
    # Store agent sessions in a database
    storage=SqliteAgentStorage(table_name="agent_sessions", db_file=agent_storage_file),
    description="You are a helpful assistant that always responds in a polite, upbeat and positive manner.",
    # Show debug logs to see the memory being created
    # debug_mode=True,
)

console = Console()


def render_panel(title: str, content: str) -> Panel:
    return Panel(JSON(content, indent=4), title=title, expand=True)


def print_agent_memory(agent):
    # -*- Print history
    console.print(
        render_panel(
            "Chat History",
            json.dumps(
                [
                    m.model_dump(include={"role", "content"})
                    for m in agent.memory.messages
                ],
                indent=4,
            ),
        )
    )
    # -*- Print memories
    console.print(
        render_panel(
            "Memories",
            json.dumps(
                [
                    m.model_dump(include={"memory", "input"})
                    for m in agent.memory.memories
                ],
                indent=4,
            ),
        )
    )
    # -*- Print summary
    console.print(
        render_panel("Summary", json.dumps(agent.memory.summary.model_dump(), indent=4))
    )


async def main():
    # -*- Share personal information
    await agent.aprint_response("My name is john billings?", stream=True)
    # -*- Print agent memory
    print_agent_memory(agent)

    # -*- Share personal information
    await agent.aprint_response("I live in nyc?", stream=True)
    # -*- Print agent memory
    print_agent_memory(agent)

    # -*- Share personal information
    await agent.aprint_response("I'm going to a concert tomorrow?", stream=True)
    # -*- Print agent memory
    print_agent_memory(agent)

    # Ask about the conversation
    await agent.aprint_response(
        "What have we been talking about, do you know my name?", stream=True
    )


# Run the async main function
if __name__ == "__main__":
    asyncio.run(main())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai sqlalchemy agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/memory/06_memories_and_summaries_sqlite_async.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/memory/06_memories_and_summaries_sqlite_async.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Persistent Memory



## Code

```python cookbook/agent_concepts/memory/02_persistent_memory.py
import json

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.storage.agent.sqlite import SqliteAgentStorage
from rich.console import Console
from rich.json import JSON
from rich.panel import Panel

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    # Store agent sessions in a database
    storage=SqliteAgentStorage(
        table_name="agent_sessions", db_file="tmp/agent_storage.db"
    ),
    # Set add_history_to_messages=true to add the previous chat history to the messages sent to the Model.
    add_history_to_messages=True,
    # Number of historical responses to add to the messages.
    num_history_responses=3,
    # The session_id is used to identify the session in the database
    # You can resume any session by providing a session_id
    # session_id="xxxx-xxxx-xxxx-xxxx",
    # Description creates a system prompt for the agent
    description="You are a helpful assistant that always responds in a polite, upbeat and positive manner.",
)

console = Console()


def print_chat_history(agent):
    # -*- Print history
    console.print(
        Panel(
            JSON(
                json.dumps(
                    [
                        m.model_dump(include={"role", "content"})
                        for m in agent.memory.messages
                    ]
                ),
                indent=4,
            ),
            title=f"Chat History for session_id: {agent.session_id}",
            expand=True,
        )
    )


# -*- Create a run
agent.print_response("Share a 2 sentence horror story", stream=True)
# -*- Print the chat history
print_chat_history(agent)

# -*- Ask a follow up question that continues the conversation
agent.print_response("What was my first message?", stream=True)
# -*- Print the chat history
print_chat_history(agent)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai sqlalchemy agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/memory/02_persistent_memory.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/memory/02_persistent_memory.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Persistent Memory with MongoDB



## Code

```python cookbook/agent_concepts/memory/07_persistent_memory_mongodb.py
import json

from agno.agent import Agent
from agno.memory.agent import AgentMemory
from agno.memory.db.mongodb import MongoMemoryDb
from agno.models.openai import OpenAIChat
from agno.storage.agent.mongodb import MongoDbAgentStorage
from rich.console import Console
from rich.json import JSON
from rich.panel import Panel

# MongoDB connection settings
db_url = "mongodb://localhost:27017"

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    # Store agent sessions in MongoDB
    storage=MongoDbAgentStorage(
        collection_name="agent_sessions", db_url=db_url, db_name="agno"
    ),
    # Store memories in MongoDB
    memory=AgentMemory(
        db=MongoMemoryDb(
            collection_name="agent_sessions", db_url=db_url, db_name="agno"
        ),
        create_user_memories=True,
        create_session_summary=True,
    ),
    # Set add_history_to_messages=true to add the previous chat history to the messages sent to the Model.
    add_history_to_messages=True,
    # Number of historical responses to add to the messages.
    num_history_responses=3,
    # The session_id is used to identify the session in the database
    # You can resume any session by providing a session_id
    # session_id="xxxx-xxxx-xxxx-xxxx",
    # Description creates a system prompt for the agent
    description="You are a helpful assistant that always responds in a polite, upbeat and positive manner.",
)

console = Console()


def print_chat_history(agent):
    # -*- Print history
    console.print(
        Panel(
            JSON(
                json.dumps(
                    [
                        m.model_dump(include={"role", "content"})
                        for m in agent.memory.messages
                    ]
                ),
                indent=4,
            ),
            title=f"Chat History for session_id: {agent.session_id}",
            expand=True,
        )
    )


# -*- Create a run
agent.print_response("Share a 2 sentence horror story", stream=True)
# -*- Print the chat history
print_chat_history(agent)

# -*- Ask a follow up question that continues the conversation
agent.print_response("What was my first message?", stream=True)
# -*- Print the chat history
print_chat_history(agent)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai pymongo agno
    ```
  </Step>

  <Step title="Run MongoDB">
    Make sure you have MongoDB running locally on port 27017
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/memory/07_persistent_memory_mongodb.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/memory/07_persistent_memory_mongodb.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Persistent Memory with Postgres



## Code

```python cookbook/agent_concepts/memory/04_persistent_memory_postgres.py
from typing import List, Optional

import typer
from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.storage.agent.postgres import PostgresAgentStorage
from agno.vectordb.pgvector import PgVector, SearchType

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=PgVector(
        table_name="recipes", db_url=db_url, search_type=SearchType.hybrid
    ),
)
# Load the knowledge base: Comment after first run
knowledge_base.load(upsert=True)

storage = PostgresAgentStorage(table_name="pdf_agent", db_url=db_url)


def pdf_agent(new: bool = False, user: str = "user"):
    session_id: Optional[str] = None

    if not new:
        existing_sessions: List[str] = storage.get_all_session_ids(user)
        if len(existing_sessions) > 0:
            session_id = existing_sessions[0]

    agent = Agent(
        session_id=session_id,
        user_id=user,
        knowledge=knowledge_base,
        storage=storage,
        # Show tool calls in the response
        show_tool_calls=True,
        # Enable the agent to read the chat history
        read_chat_history=True,
        # We can also automatically add the chat history to the messages sent to the model
        # But giving the model the chat history is not always useful, so we give it a tool instead
        # to only use when needed.
        # add_history_to_messages=True,
        # Number of historical responses to add to the messages.
        # num_history_responses=3,
    )
    if session_id is None:
        session_id = agent.session_id
        print(f"Started Session: {session_id}\n")
    else:
        print(f"Continuing Session: {session_id}\n")

    # Runs the agent as a cli app
    agent.cli_app(markdown=True)


if __name__ == "__main__":
    typer.run(pdf_agent)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai sqlalchemy pgvector "psycopg[binary]" agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    ./cookbook/scripts/run_pgvector.sh
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/memory/04_persistent_memory_postgres.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/memory/04_persistent_memory_postgres.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Audio Input Output



## Code

```python
import requests
from agno.agent import Agent
from agno.media import Audio
from agno.models.openai import OpenAIChat
from agno.utils.audio import write_audio_to_file

# Fetch the audio file and convert it to a base64 encoded string
url = "https://openaiassets.blob.core.windows.net/$web/API/docs/audio/alloy.wav"
response = requests.get(url)
response.raise_for_status()
wav_data = response.content

agent = Agent(
    model=OpenAIChat(
        id="gpt-4o-audio-preview",
        modalities=["text", "audio"],
        audio={"voice": "alloy", "format": "wav"},
    ),
    markdown=True,
)

agent.run(
    "What's in these recording?",
    audio=[Audio(content=wav_data, format="wav")],
)

if agent.run_response.response_audio is not None:
    write_audio_to_file(
        audio=agent.run_response.response_audio.content, filename="tmp/result.wav"
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/multimodal/audio_input_output.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/multimodal/audio_input_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Multi-turn Audio Agent



## Code

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.utils.audio import write_audio_to_file

agent = Agent(
    model=OpenAIChat(
        id="gpt-4o-audio-preview",
        modalities=["text", "audio"],
        audio={"voice": "alloy", "format": "wav"},
    ),
    debug_mode=True,
    add_history_to_messages=True,
)

agent.run("Is a golden retriever a good family dog?")
if agent.run_response.response_audio is not None:
    write_audio_to_file(
        audio=agent.run_response.response_audio.content, filename="tmp/answer_1.wav"
    )

agent.run("Why do you say they are loyal?")
if agent.run_response.response_audio is not None:
    write_audio_to_file(
        audio=agent.run_response.response_audio.content, filename="tmp/answer_2.wav"
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/multimodal/audio_multi_turn.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/multimodal/audio_multi_turn.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Generate Images with Intermediate Steps



## Code

```python
from typing import Iterator

from agno.agent import Agent, RunResponse
from agno.models.openai import OpenAIChat
from agno.tools.dalle import DalleTools
from agno.utils.common import dataclass_to_dict
from rich.pretty import pprint

image_agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    tools=[DalleTools()],
    description="You are an AI agent that can create images using DALL-E.",
    instructions=[
        "When the user asks you to create an image, use the DALL-E tool to create an image.",
        "The DALL-E tool will return an image URL.",
        "Return the image URL in your response in the following format: `![image description](image URL)`",
    ],
    markdown=True,
)

run_stream: Iterator[RunResponse] = image_agent.run(
    "Create an image of a yellow siamese cat",
    stream=True,
    stream_intermediate_steps=True,
)
for chunk in run_stream:
    pprint(dataclass_to_dict(chunk, exclude={"messages"}))
    print("---" * 20)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai rich agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/multimodal/generate_image_with_intermediate_steps.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/multimodal/generate_image_with_intermediate_steps.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Generate Video using Models Lab



## Code

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.models_labs import ModelsLabTools

video_agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    tools=[ModelsLabTools()],
    description="You are an AI agent that can generate videos using the ModelsLabs API.",
    instructions=[
        "When the user asks you to create a video, use the `generate_media` tool to create the video.",
        "The video will be displayed in the UI automatically below your response, so you don't need to show the video URL in your response.",
        "Politely and courteously let the user know that the video has been generated and will be displayed below as soon as its ready.",
    ],
    markdown=True,
    debug_mode=True,
    show_tool_calls=True,
)

video_agent.print_response("Generate a video of a cat playing with a ball")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    export MODELS_LAB_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/multimodal/generate_video_using_models_lab.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/multimodal/generate_video_using_models_lab.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Generate Video using Replicate



## Code

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.replicate import ReplicateTools

video_agent = Agent(
    name="Video Generator Agent",
    model=OpenAIChat(id="gpt-4o"),
    tools=[
        ReplicateTools(
            model="tencent/hunyuan-video:847dfa8b01e739637fc76f480ede0c1d76408e1d694b830b5dfb8e547bf98405"
        )
    ],
    description="You are an AI agent that can generate videos using the Replicate API.",
    instructions=[
        "When the user asks you to create a video, use the `generate_media` tool to create the video.",
        "Return the URL as raw to the user.",
        "Don't convert video URL to markdown or anything else.",
    ],
    markdown=True,
    debug_mode=True,
    show_tool_calls=True,
)

video_agent.print_response("Generate a video of a horse in the dessert.")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    export REPLICATE_API_TOKEN=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai replicate agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/multimodal/generate_video_using_replicate.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/multimodal/generate_video_using_replicate.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image to Audio Agent



## Code

```python
from pathlib import Path

from agno.agent import Agent, RunResponse
from agno.media import Image
from agno.models.openai import OpenAIChat
from agno.utils.audio import write_audio_to_file
from rich import print
from rich.text import Text

image_agent = Agent(model=OpenAIChat(id="gpt-4o"))

image_path = Path(__file__).parent.joinpath("sample.jpg")
image_story: RunResponse = image_agent.run(
    "Write a 3 sentence fiction story about the image",
    images=[Image(filepath=image_path)],
)
formatted_text = Text.from_markup(
    f":sparkles: [bold magenta]Story:[/bold magenta] {image_story.content} :sparkles:"
)
print(formatted_text)

audio_agent = Agent(
    model=OpenAIChat(
        id="gpt-4o-audio-preview",
        modalities=["text", "audio"],
        audio={"voice": "alloy", "format": "wav"},
    ),
)

audio_story: RunResponse = audio_agent.run(
    f"Narrate the story with flair: {image_story.content}"
)
if audio_story.response_audio is not None:
    write_audio_to_file(
        audio=audio_story.response_audio.content, filename="tmp/sample_story.wav"
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai rich agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/multimodal/image_to_audio.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/multimodal/image_to_audio.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image to Image Agent



## Code

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.fal import FalTools

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    agent_id="image-to-image",
    name="Image to Image Agent",
    tools=[FalTools()],
    markdown=True,
    debug_mode=True,
    show_tool_calls=True,
    instructions=[
        "You have to use the `image_to_image` tool to generate the image.",
        "You are an AI agent that can generate images using the Fal AI API.",
        "You will be given a prompt and an image URL.",
        "You have to return the image URL as provided, don't convert it to markdown or anything else.",
    ],
)

agent.print_response(
    "a cat dressed as a wizard with a background of a mystic forest. Make it look like 'https://fal.media/files/koala/Chls9L2ZnvuipUTEwlnJC.png'",
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    export FAL_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai fal agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/multimodal/image_to_image_agent.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/multimodal/image_to_image_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Video Caption Agent



## Code

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.moviepy_video import MoviePyVideoTools
from agno.tools.openai import OpenAITools

video_tools = MoviePyVideoTools(
    process_video=True, generate_captions=True, embed_captions=True
)

openai_tools = OpenAITools()

video_caption_agent = Agent(
    name="Video Caption Generator Agent",
    model=OpenAIChat(
        id="gpt-4o",
    ),
    tools=[video_tools, openai_tools],
    description="You are an AI agent that can generate and embed captions for videos.",
    instructions=[
        "When a user provides a video, process it to generate captions.",
        "Use the video processing tools in this sequence:",
        "1. Extract audio from the video using extract_audio",
        "2. Transcribe the audio using transcribe_audio",
        "3. Generate SRT captions using create_srt",
        "4. Embed captions into the video using embed_captions",
    ],
    markdown=True,
)

video_caption_agent.print_response(
    "Generate captions for {video with location} and embed them in the video"
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai moviepy ffmpeg agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/multimodal/video_caption_agent.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/multimodal/video_caption_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Video to Shorts Agent



## Code

```python
import subprocess
import time
from pathlib import Path

from agno.agent import Agent
from agno.media import Video
from agno.models.google import Gemini
from agno.utils.log import logger
from google.generativeai import get_file, upload_file

video_path = Path(__file__).parent.joinpath("sample.mp4")
output_dir = Path("tmp/shorts")

agent = Agent(
    name="Video2Shorts",
    description="Process videos and generate engaging shorts.",
    model=Gemini(id="gemini-2.0-flash-exp"),
    markdown=True,
    debug_mode=True,
    structured_outputs=True,
    instructions=[
        "Analyze the provided video directly—do NOT reference or analyze any external sources or YouTube videos.",
        "Identify engaging moments that meet the specified criteria for short-form content.",
        """Provide your analysis in a **table format** with these columns:
   - Start Time | End Time | Description | Importance Score""",
        "Ensure all timestamps use MM:SS format and importance scores range from 1-10. ",
        "Focus only on segments between 15 and 60 seconds long.",
        "Base your analysis solely on the provided video content.",
        "Deliver actionable insights to improve the identified segments for short-form optimization.",
    ],
)

# Upload and process video
video_file = upload_file(video_path)
while video_file.state.name == "PROCESSING":
    time.sleep(2)
    video_file = get_file(video_file.name)

# Multimodal Query for Video Analysis
query = """
You are an expert in video content creation, specializing in crafting engaging short-form content for platforms like YouTube Shorts and Instagram Reels. Your task is to analyze the provided video and identify segments that maximize viewer engagement.

For each video, you'll:

1. Identify key moments that will capture viewers' attention, focusing on:
   - High-energy sequences
   - Emotional peaks
   - Surprising or unexpected moments
   - Strong visual and audio elements
   - Clear narrative segments with compelling storytelling

2. Extract segments that work best for short-form content, considering:
   - Optimal length (strictly 15–60 seconds)
   - Natural start and end points that ensure smooth transitions
   - Engaging pacing that maintains viewer attention
   - Audio-visual harmony for an immersive experience
   - Vertical format compatibility and adjustments if necessary

3. Provide a detailed analysis of each segment, including:
   - Precise timestamps (Start Time | End Time in MM:SS format)
   - A clear description of why the segment would be engaging
   - Suggestions on how to enhance the segment for short-form content
   - An importance score (1-10) based on engagement potential

Your goal is to identify moments that are visually compelling, emotionally engaging, and perfectly optimized for short-form platforms.
"""

# Generate Video Analysis
response = agent.run(query, videos=[Video(content=video_file)])

# Create output directory
output_dir = Path(output_dir)
output_dir.mkdir(parents=True, exist_ok=True)

# Extract and cut video segments
def extract_segments(response_text):
    import re

    segments_pattern = r"\|\s*(\d+:\d+)\s*\|\s*(\d+:\d+)\s*\|\s*(.*?)\s*\|\s*(\d+)\s*\|"
    segments: list[dict] = []

    for match in re.finditer(segments_pattern, str(response_text)):
        start_time = match.group(1)
        end_time = match.group(2)
        description = match.group(3)
        score = int(match.group(4))

        start_seconds = sum(x * int(t) for x, t in zip([60, 1], start_time.split(":")))
        end_seconds = sum(x * int(t) for x, t in zip([60, 1], end_time.split(":")))
        duration = end_seconds - start_seconds

        if 15 <= duration <= 60 and score > 7:
            output_path = output_dir / f"short_{len(segments) + 1}.mp4"

            command = [
                "ffmpeg",
                "-ss",
                str(start_seconds),
                "-i",
                video_path,
                "-t",
                str(duration),
                "-vf",
                "scale=1080:1920,setsar=1:1",
                "-c:v",
                "libx264",
                "-c:a",
                "aac",
                "-y",
                str(output_path),
            ]

            try:
                subprocess.run(command, check=True)
                segments.append(
                    {"path": output_path, "description": description, "score": score}
                )
            except subprocess.CalledProcessError:
                print(f"Failed to process segment: {start_time} - {end_time}")

    return segments

logger.debug(f"{response.content}")

# Process segments
shorts = extract_segments(response.content)

# Print results
print("\n--- Generated Shorts ---")
for short in shorts:
    print(f"Short at {short['path']}")
    print(f"Description: {short['description']}")
    print(f"Engagement Score: {short['score']}/10\n")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U opencv-python google-generativeai sqlalchemy ffmpeg-python agno
    ```
  </Step>

  <Step title="Install ffmpeg">
    <CodeGroup>
      ```bash Mac
      brew install ffmpeg
      ```

      ```bash Windows
      # Install ffmpeg using chocolatey or download from https://ffmpeg.org/download.html
      choco install ffmpeg
      ```
    </CodeGroup>
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/multimodal/video_to_shorts.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/multimodal/video_to_shorts.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agentic RAG with Agent UI



## Code

```python
from agno.agent import Agent
from agno.embedder.openai import OpenAIEmbedder
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.models.openai import OpenAIChat
from agno.playground import Playground, serve_playground_app
from agno.storage.agent.postgres import PostgresAgentStorage
from agno.vectordb.pgvector import PgVector, SearchType

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
# Create a knowledge base of PDFs from URLs
knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    # Use PgVector as the vector database and store embeddings in the `ai.recipes` table
    vector_db=PgVector(
        table_name="recipes",
        db_url=db_url,
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)

rag_agent = Agent(
    name="RAG Agent",
    agent_id="rag-agent",
    model=OpenAIChat(id="gpt-4o"),
    knowledge=knowledge_base,
    # Add a tool to search the knowledge base which enables agentic RAG.
    # This is enabled by default when `knowledge` is provided to the Agent.
    search_knowledge=True,
    # Add a tool to read chat history.
    read_chat_history=True,
    # Store the agent sessions in the `ai.rag_agent_sessions` table
    storage=PostgresAgentStorage(table_name="rag_agent_sessions", db_url=db_url),
    instructions=[
        "Always search your knowledge base first and use it if available.",
        "Share the page number or source URL of the information you used in your response.",
        "If health benefits are mentioned, include them in the response.",
        "Important: Use tables where possible.",
    ],
    markdown=True,
)

app = Playground(agents=[rag_agent]).get_app()

if __name__ == "__main__":
    # Load the knowledge base: Comment after first run as the knowledge base is already loaded
    knowledge_base.load(upsert=True)
    serve_playground_app("agentic_rag_agent_ui:app", reload=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai sqlalchemy 'psycopg[binary]' pgvector 'fastapi[standard]' agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/rag/agentic_rag_agent_ui.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/rag/agentic_rag_agent_ui.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agentic RAG with LanceDB



## Code

```python
from agno.agent import Agent
from agno.embedder.openai import OpenAIEmbedder
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.models.openai import OpenAIChat
from agno.vectordb.lancedb import LanceDb, SearchType

# Create a knowledge base of PDFs from URLs
knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    # Use LanceDB as the vector database and store embeddings in the `recipes` table
    vector_db=LanceDb(
        table_name="recipes",
        uri="tmp/lancedb",
        search_type=SearchType.vector,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)
# Load the knowledge base: Comment after first run as the knowledge base is already loaded
knowledge_base.load()

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    knowledge=knowledge_base,
    # Add a tool to search the knowledge base which enables agentic RAG.
    # This is enabled by default when `knowledge` is provided to the Agent.
    search_knowledge=True,
    show_tool_calls=True,
    markdown=True,
)
agent.print_response(
    "How do I make chicken and galangal in coconut milk soup", stream=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai lancedb tantivy pypdf sqlalchemy agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/rag/agentic_rag_lancedb.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/rag/agentic_rag_lancedb.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agentic RAG with PgVector



## Code

```python
from agno.agent import Agent
from agno.embedder.openai import OpenAIEmbedder
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.models.openai import OpenAIChat
from agno.vectordb.pgvector import PgVector, SearchType

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
# Create a knowledge base of PDFs from URLs
knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    # Use PgVector as the vector database and store embeddings in the `ai.recipes` table
    vector_db=PgVector(
        table_name="recipes",
        db_url=db_url,
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)
# Load the knowledge base: Comment after first run as the knowledge base is already loaded
knowledge_base.load(upsert=True)

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    knowledge=knowledge_base,
    # Add a tool to search the knowledge base which enables agentic RAG.
    # This is enabled by default when `knowledge` is provided to the Agent.
    search_knowledge=True,
    show_tool_calls=True,
    markdown=True,
)
agent.print_response(
    "How do I make chicken and galangal in coconut milk soup", stream=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai sqlalchemy 'psycopg[binary]' pgvector agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/rag/agentic_rag_pgvector.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/rag/agentic_rag_pgvector.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agentic RAG with Reranking



## Code

```python
from agno.agent import Agent
from agno.embedder.openai import OpenAIEmbedder
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.models.openai import OpenAIChat
from agno.reranker.cohere import CohereReranker
from agno.vectordb.lancedb import LanceDb, SearchType

# Create a knowledge base of PDFs from URLs
knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    # Use LanceDB as the vector database and store embeddings in the `recipes` table
    vector_db=LanceDb(
        table_name="recipes",
        uri="tmp/lancedb",
        search_type=SearchType.vector,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
        reranker=CohereReranker(model="rerank-multilingual-v3.0"),  # Add a reranker
    ),
)
# Load the knowledge base: Comment after first run as the knowledge base is already loaded
knowledge_base.load()

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    knowledge=knowledge_base,
    # Add a tool to search the knowledge base which enables agentic RAG.
    # This is enabled by default when `knowledge` is provided to the Agent.
    search_knowledge=True,
    show_tool_calls=True,
    markdown=True,
)
agent.print_response(
    "How do I make chicken and galangal in coconut milk soup", stream=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export OPENAI_API_KEY=xxx
    export COHERE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai lancedb tantivy pypdf sqlalchemy agno cohere
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/rag/agentic_rag_with_reranking.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/rag/agentic_rag_with_reranking.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# RAG with LanceDB and SQLite



## Code

```python
from agno.agent import Agent
from agno.embedder.ollama import OllamaEmbedder
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.models.ollama import Ollama
from agno.storage.agent.sqlite import SqliteAgentStorage
from agno.vectordb.lancedb import LanceDb

# Define the database URL where the vector database will be stored
db_url = "/tmp/lancedb"

# Configure the language model
model = Ollama(id="llama3.1:8b")

# Create Ollama embedder
embedder = OllamaEmbedder(id="nomic-embed-text", dimensions=768)

# Create the vector database
vector_db = LanceDb(
    table_name="recipes",  # Table name in the vector database
    uri=db_url,  # Location to initiate/create the vector database
    embedder=embedder,  # Without using this, it will use OpenAIChat embeddings by default
)

# Create a knowledge base from a PDF URL using LanceDb for vector storage and OllamaEmbedder for embedding
knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=vector_db,
)

# Load the knowledge base without recreating it if it already exists in Vector LanceDB
knowledge_base.load(recreate=False)

# Set up SQL storage for the agent's data
storage = SqliteAgentStorage(table_name="recipes", db_file="data.db")
storage.create()  # Create the storage if it doesn't exist

# Initialize the Agent with various configurations including the knowledge base and storage
agent = Agent(
    session_id="session_id",  # use any unique identifier to identify the run
    user_id="user",  # user identifier to identify the user
    model=model,
    knowledge=knowledge_base,
    storage=storage,
    show_tool_calls=True,
    debug_mode=True,  # Enable debug mode for additional information
)

# Use the agent to generate and print a response to a query, formatted in Markdown
agent.print_response(
    "What is the first step of making Gluai Buat Chi from the knowledge base?",
    markdown=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the installation instructions at [Ollama's website](https://ollama.ai)
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U lancedb sqlalchemy agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/rag/rag_with_lance_db_and_sqlite.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/rag/rag_with_lance_db_and_sqlite.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Traditional RAG with LanceDB



## Code

```python
from agno.agent import Agent
from agno.embedder.openai import OpenAIEmbedder
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.models.openai import OpenAIChat
from agno.vectordb.lancedb import LanceDb, SearchType

# Create a knowledge base of PDFs from URLs
knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    # Use LanceDB as the vector database and store embeddings in the `recipes` table
    vector_db=LanceDb(
        table_name="recipes",
        uri="tmp/lancedb",
        search_type=SearchType.vector,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)
# Load the knowledge base: Comment after first run as the knowledge base is already loaded
knowledge_base.load()

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    knowledge=knowledge_base,
    # Enable RAG by adding references from AgentKnowledge to the user prompt.
    add_references=True,
    # Set as False because Agents default to `search_knowledge=True`
    search_knowledge=False,
    show_tool_calls=True,
    markdown=True,
)
agent.print_response(
    "How do I make chicken and galangal in coconut milk soup", stream=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai lancedb tantivy pypdf sqlalchemy agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/rag/traditional_rag_lancedb.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/rag/traditional_rag_lancedb.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Traditional RAG with PgVector



## Code

```python
from agno.agent import Agent
from agno.embedder.openai import OpenAIEmbedder
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.models.openai import OpenAIChat
from agno.vectordb.pgvector import PgVector, SearchType

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
# Create a knowledge base of PDFs from URLs
knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    # Use PgVector as the vector database and store embeddings in the `ai.recipes` table
    vector_db=PgVector(
        table_name="recipes",
        db_url=db_url,
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)
# Load the knowledge base: Comment after first run as the knowledge base is already loaded
knowledge_base.load(upsert=True)

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    knowledge=knowledge_base,
    # Enable RAG by adding context from the `knowledge` to the user prompt.
    add_references=True,
    # Set as False because Agents default to `search_knowledge=True`
    search_knowledge=False,
    markdown=True,
)
agent.print_response(
    "How do I make chicken and galangal in coconut milk soup", stream=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai sqlalchemy 'psycopg[binary]' pgvector pypdf agno
    ```
  </Step>

  <Step title="Run PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/rag/traditional_rag_pgvector.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/rag/traditional_rag_pgvector.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# DynamoDB Storage



## Code

```python cookbook/agent_concepts/storage/dynamodb_storage.py
from agno.agent import Agent
from agno.storage.agent.dynamodb import DynamoDbAgentStorage
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    storage=DynamoDbAgentStorage(table_name="agent_sessions", region_name="us-east-1"),
    tools=[DuckDuckGoTools()],
    add_history_to_messages=True,
    debug_mode=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U duckduckgo-search boto3 openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/storage/dynamodb_storage.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/storage/dynamodb_storage.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# JSON Storage



## Code

```python cookbook/agent_concepts/storage/json_storage.py
from agno.agent import Agent
from agno.storage.agent.json import JsonAgentStorage
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    storage=JsonAgentStorage(dir_path="tmp/agent_sessions_json"),
    tools=[DuckDuckGoTools()],
    add_history_to_messages=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U duckduckgo-search openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/storage/json_storage.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/storage/json_storage.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# MongoDB Storage



## Code

```python cookbook/agent_concepts/storage/mongodb_storage.py
from agno.agent import Agent
from agno.storage.agent.mongodb import MongoDbAgentStorage
from agno.tools.duckduckgo import DuckDuckGoTools

# MongoDB connection settings
db_url = "mongodb://localhost:27017"

agent = Agent(
    storage=MongoDbAgentStorage(
        collection_name="agent_sessions", db_url=db_url, db_name="agno"
    ),
    tools=[DuckDuckGoTools()],
    add_history_to_messages=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai pymongo agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/storage/mongodb_storage.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/storage/mongodb_storage.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# PostgreSQL Storage



## Code

```python cookbook/agent_concepts/storage/postgres_storage.py
from agno.agent import Agent
from agno.storage.agent.postgres import PostgresAgentStorage
from agno.tools.duckduckgo import DuckDuckGoTools

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

agent = Agent(
    storage=PostgresAgentStorage(table_name="agent_sessions", db_url=db_url),
    tools=[DuckDuckGoTools()],
    add_history_to_messages=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U duckduckgo-search sqlalchemy psycopg openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/storage/postgres_storage.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/storage/postgres_storage.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# SingleStore Storage



## Code

```python cookbook/agent_concepts/storage/singlestore_storage.py
from os import getenv

from agno.agent import Agent
from agno.storage.agent.singlestore import SingleStoreAgentStorage
from agno.tools.duckduckgo import DuckDuckGoTools
from sqlalchemy.engine import create_engine

# Configure SingleStore DB connection
USERNAME = getenv("SINGLESTORE_USERNAME")
PASSWORD = getenv("SINGLESTORE_PASSWORD")
HOST = getenv("SINGLESTORE_HOST")
PORT = getenv("SINGLESTORE_PORT")
DATABASE = getenv("SINGLESTORE_DATABASE")
SSL_CERT = getenv("SINGLESTORE_SSL_CERT", None)

# SingleStore DB URL
db_url = (
    f"mysql+pymysql://{USERNAME}:{PASSWORD}@{HOST}:{PORT}/{DATABASE}?charset=utf8mb4"
)
if SSL_CERT:
    db_url += f"&ssl_ca={SSL_CERT}&ssl_verify_cert=true"

# Create a DB engine
db_engine = create_engine(db_url)

# Create an agent with SingleStore storage
agent = Agent(
    storage=SingleStoreAgentStorage(
        table_name="agent_sessions", db_engine=db_engine, schema=DATABASE
    ),
    tools=[DuckDuckGoTools()],
    add_history_to_messages=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U duckduckgo-search sqlalchemy pymysql openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/storage/singlestore_storage.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/storage/singlestore_storage.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# SQLite Storage



## Code

```python cookbook/agent_concepts/storage/sqlite_storage.py
from agno.agent import Agent
from agno.storage.agent.sqlite import SqliteAgentStorage
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    storage=SqliteAgentStorage(table_name="agent_sessions", db_file="tmp/data.db"),
    tools=[DuckDuckGoTools()],
    add_history_to_messages=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U duckduckgo-search sqlalchemy openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/storage/sqlite_storage.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/storage/sqlite_storage.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# YAML Storage



## Code

```python cookbook/agent_concepts/storage/yaml_storage.py
from agno.agent import Agent
from agno.storage.agent.yaml import YamlAgentStorage
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    storage=YamlAgentStorage(dir_path="tmp/agent_sessions_yaml"),
    tools=[DuckDuckGoTools()],
    add_history_to_messages=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U duckduckgo-search pyyaml openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/storage/yaml_storage.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/storage/yaml_storage.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# News Agency Team



## Code

```python
from pathlib import Path

from agno.agent import Agent
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.file import FileTools
from agno.tools.newspaper4k import Newspaper4kTools

urls_file = Path(__file__).parent.joinpath("tmp", "urls__{session_id}.md")
urls_file.parent.mkdir(parents=True, exist_ok=True)


searcher = Agent(
    name="Searcher",
    role="Searches the top URLs for a topic",
    instructions=[
        "Given a topic, first generate a list of 3 search terms related to that topic.",
        "For each search term, search the web and analyze the results.Return the 10 most relevant URLs to the topic.",
        "You are writing for the New York Times, so the quality of the sources is important.",
    ],
    tools=[DuckDuckGoTools()],
    save_response_to_file=str(urls_file),
    add_datetime_to_instructions=True,
)
writer = Agent(
    name="Writer",
    role="Writes a high-quality article",
    description=(
        "You are a senior writer for the New York Times. Given a topic and a list of URLs, "
        "your goal is to write a high-quality NYT-worthy article on the topic."
    ),
    instructions=[
        f"First read all urls in {urls_file.name} using `get_article_text`."
        "Then write a high-quality NYT-worthy article on the topic."
        "The article should be well-structured, informative, engaging and catchy.",
        "Ensure the length is at least as long as a NYT cover story -- at a minimum, 15 paragraphs.",
        "Ensure you provide a nuanced and balanced opinion, quoting facts where possible.",
        "Focus on clarity, coherence, and overall quality.",
        "Never make up facts or plagiarize. Always provide proper attribution.",
        "Remember: you are writing for the New York Times, so the quality of the article is important.",
    ],
    tools=[Newspaper4kTools(), FileTools(base_dir=urls_file.parent)],
    add_datetime_to_instructions=True,
)

editor = Agent(
    name="Editor",
    team=[searcher, writer],
    description="You are a senior NYT editor. Given a topic, your goal is to write a NYT worthy article.",
    instructions=[
        "First ask the search journalist to search for the most relevant URLs for that topic.",
        "Then ask the writer to get an engaging draft of the article.",
        "Edit, proofread, and refine the article to ensure it meets the high standards of the New York Times.",
        "The article should be extremely articulate and well written. "
        "Focus on clarity, coherence, and overall quality.",
        "Remember: you are the final gatekeeper before the article is published, so make sure the article is perfect.",
    ],
    add_datetime_to_instructions=True,
    markdown=True,
    debug_mode=True
)
editor.print_response("Write an article about latest developments in AI.")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai duckduckgo-search newspaper4k lxml_html_clean agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/teams/news_agency_team.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/teams/news_agency_team.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Direct Response Team



## Code

```python
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.yfinance import YFinanceTools

web_agent = Agent(
    name="Web Agent",
    role="Search the web for information",
    model=OpenAIChat(id="gpt-4o"),
    tools=[DuckDuckGoTools()],
    instructions=["Always include sources"],
    expected_output=dedent("""\
    ## {title}

    {Answer to the user's question}
    """),
    # This will make the agent respond directly to the user, rather than through the team leader.
    respond_directly=True,
    markdown=True,
)


finance_agent = Agent(
    name="Finance Agent",
    role="Get financial data",
    model=OpenAIChat(id="gpt-4o"),
    tools=[
        YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True)
    ],
    instructions=["Use tables to display data"],
    expected_output=dedent("""\
    ## {title}

    {Answer to the user's question}
    """),
    # This will make the agent respond directly to the user, rather than through the team leader.
    respond_directly=True,
    markdown=True,
)

agent_team = Agent(
    team=[web_agent, finance_agent],
    instructions=["Always include sources", "Use tables to display data"],
    markdown=True,
    debug_mode=True
)

agent_team.print_response(
    "Summarize analyst recommendations and share the latest news for NVDA", stream=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai duckduckgo-search yfinance agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/teams/respond_directly.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/teams/respond_directly.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Airflow Tools



## Code

```python cookbook/tools/airflow_tools.py
from agno.agent import Agent
from agno.tools.airflow import AirflowTools

agent = Agent(
    tools=[AirflowTools(dags_dir="tmp/dags", save_dag=True, read_dag=True)],
    show_tool_calls=True,
    markdown=True,
)

dag_content = """
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta

default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

# Using 'schedule' instead of deprecated 'schedule_interval'
with DAG(
    'example_dag',
    default_args=default_args,
    description='A simple example DAG',
    schedule='@daily',  # Changed from schedule_interval
    catchup=False
) as dag:

    def print_hello():
        print("Hello from Airflow!")
        return "Hello task completed"

    task = PythonOperator(
        task_id='hello_task',
        python_callable=print_hello,
        dag=dag,
    )
"""

agent.run(f"Save this DAG file as 'example_dag.py': {dag_content}")
agent.print_response("Read the contents of 'example_dag.py'")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U apache-airflow openai agno
    ```
  </Step>

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/airflow_tools.py
      ```

      ```bash Windows
      python cookbook/tools/airflow_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Apify Tools



## Code

```python cookbook/tools/apify_tools.py
from agno.agent import Agent
from agno.tools.apify import ApifyTools

agent = Agent(tools=[ApifyTools()], show_tool_calls=True)
agent.print_response("Tell me about https://docs.agno.com/introduction", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export APIFY_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U apify-client openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/apify_tools.py
      ```

      ```bash Windows
      python cookbook/tools/apify_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# ArXiv Tools



## Code

```python cookbook/tools/arxiv_tools.py
from agno.agent import Agent
from agno.tools.arxiv_toolkit import ArxivTools

agent = Agent(tools=[ArxivTools()], show_tool_calls=True)
agent.print_response("Search arxiv for 'language models'", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U arxiv openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/arxiv_tools.py
      ```

      ```bash Windows
      python cookbook/tools/arxiv_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# AWS Lambda Tools



## Code

```python cookbook/tools/aws_lambda_tools.py
from agno.agent import Agent
from agno.tools.aws_lambda import AWSLambdaTools

agent = Agent(
    tools=[AWSLambdaTools(region_name="us-east-1")],
    name="AWS Lambda Agent",
    show_tool_calls=True,
)

agent.print_response("List all Lambda functions in our AWS account", markdown=True)
agent.print_response(
    "Invoke the 'hello-world' Lambda function with an empty payload", markdown=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your AWS credentials">
    ```bash
    export AWS_ACCESS_KEY_ID=xxx
    export AWS_SECRET_ACCESS_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U boto3 openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/aws_lambda_tools.py
      ```

      ```bash Windows
      python cookbook/tools/aws_lambda_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Baidu Search Tools



## Code

```python cookbook/tools/baidusearch_tools.py
from agno.agent import Agent
from agno.tools.baidusearch import BaiduSearchTools

agent = Agent(
    tools=[BaiduSearchTools()],
    description="You are a search agent that helps users find the most relevant information using Baidu.",
    instructions=[
        "Given a topic by the user, respond with the 3 most relevant search results about that topic.",
        "Search for 5 results and select the top 3 unique items.",
        "Search in both English and Chinese.",
    ],
    show_tool_calls=True,
)
agent.print_response("What are the latest advancements in AI?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/baidusearch_tools.py
      ```

      ```bash Windows
      python cookbook/tools/baidusearch_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Cal.com Tools



## Code

```python cookbook/tools/calcom_tools.py
from datetime import datetime

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.calcom import CalComTools

agent = Agent(
    name="Calendar Assistant",
    instructions=[
        f"You're scheduing assistant. Today is {datetime.now()}.",
        "You can help users by:",
        "    - Finding available time slots",
        "    - Creating new bookings",
        "    - Managing existing bookings (view, reschedule, cancel)",
        "    - Getting booking details",
        "    - IMPORTANT: In case of rescheduling or cancelling booking, call the get_upcoming_bookings function to get the booking uid. check available slots before making a booking for given time",
        "Always confirm important details before making bookings or changes.",
    ],
    model=OpenAIChat(id="gpt-4"),
    tools=[CalComTools(user_timezone="America/New_York")],
    show_tool_calls=True,
    markdown=True,
)

agent.print_response("What are my bookings for tomorrow?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export CALCOM_API_KEY=xxx
    export CALCOM_EVENT_TYPE_ID=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U requests pytz openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/calcom_tools.py
      ```

      ```bash Windows
      python cookbook/tools/calcom_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Calculator



## Code

```python cookbook/tools/calculator_tools.py
from agno.agent import Agent
from agno.tools.calculator import CalculatorTools

agent = Agent(
    tools=[
        CalculatorTools(
            add=True,
            subtract=True,
            multiply=True,
            divide=True,
            exponentiate=True,
            factorial=True,
            is_prime=True,
            square_root=True,
        )
    ],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("What is 10*5 then to the power of 2, do it step by step")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/calculator_tools.py
      ```

      ```bash Windows
      python cookbook/tools/calculator_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Composio Tools



## Code

```python cookbook/tools/composio_tools.py
from agno.agent import Agent
from composio_agno import Action, ComposioToolSet

toolset = ComposioToolSet()
composio_tools = toolset.get_tools(
    actions=[Action.GITHUB_STAR_A_REPOSITORY_FOR_THE_AUTHENTICATED_USER]
)

agent = Agent(tools=composio_tools, show_tool_calls=True)
agent.print_response("Can you star agno-agi/agno repo?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export COMPOSIO_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U composio-agno openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/composio_tools.py
      ```

      ```bash Windows
      python cookbook/tools/composio_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Confluence Tools



## Code

```python cookbook/tools/confluence_tools.py
from agno.agent import Agent
from agno.tools.confluence import ConfluenceTools

agent = Agent(
    name="Confluence agent",
    tools=[ConfluenceTools()],
    show_tool_calls=True,
    markdown=True,
)

agent.print_response("How many spaces are there and what are their names?")
agent.print_response(
    "What is the content present in page 'Large language model in LLM space'"
)
agent.print_response("Can you extract all the page names from 'LLM' space")
agent.print_response("Can you create a new page named 'TESTING' in 'LLM' space")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API credentials">
    ```bash
    export CONFLUENCE_API_TOKEN=xxx
    export CONFLUENCE_SITE_URL=xxx
    export CONFLUENCE_USERNAME=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U atlassian-python-api openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/confluence_tools.py
      ```

      ```bash Windows
      python cookbook/tools/confluence_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Crawl4ai Tools



## Code

```python cookbook/tools/crawl4ai_tools.py
from agno.agent import Agent
from agno.tools.crawl4ai import Crawl4aiTools

agent = Agent(tools=[Crawl4aiTools(max_length=None)], show_tool_calls=True)
agent.print_response("Tell me about https://github.com/agno-agi/agno.")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U crawl4ai openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/crawl4ai_tools.py
      ```

      ```bash Windows
      python cookbook/tools/crawl4ai_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# CSV Tools



## Code

```python cookbook/tools/csv_tools.py
from pathlib import Path

import httpx
from agno.agent import Agent
from agno.tools.csv_toolkit import CsvTools

url = "https://agno-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv"
response = httpx.get(url)

imdb_csv = Path(__file__).parent.joinpath("imdb.csv")
imdb_csv.parent.mkdir(parents=True, exist_ok=True)
imdb_csv.write_bytes(response.content)

agent = Agent(
    tools=[CsvTools(csvs=[imdb_csv])],
    markdown=True,
    show_tool_calls=True,
    instructions=[
        "First always get the list of files",
        "Then check the columns in the file",
        "Then run the query to answer the question",
    ],
)
agent.cli_app(stream=False)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U httpx openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/csv_tools.py
      ```

      ```bash Windows
      python cookbook/tools/csv_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# DALL-E Tools



## Code

```python cookbook/tools/dalle_tools.py
from pathlib import Path

from agno.agent import Agent
from agno.tools.dalle import DalleTools
from agno.utils.media import download_image

agent = Agent(tools=[DalleTools()], name="DALL-E Image Generator")

agent.print_response(
    "Generate an image of a futuristic city with flying cars and tall skyscrapers",
    markdown=True,
)

custom_dalle = DalleTools(
    model="dall-e-3", size="1792x1024", quality="hd", style="natural"
)

agent_custom = Agent(
    tools=[custom_dalle],
    name="Custom DALL-E Generator",
    show_tool_calls=True,
)

response = agent_custom.run(
    "Create a panoramic nature scene showing a peaceful mountain lake at sunset",
    markdown=True,
)
if response.images:
    download_image(
        url=response.images[0].url,
        save_path=Path(__file__).parent.joinpath("tmp/nature.jpg"),
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx  # Required for DALL-E image generation
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/dalle_tools.py
      ```

      ```bash Windows
      python cookbook/tools/dalle_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Desi Vocal Tools



## Code

```python cookbook/tools/desi_vocal_tools.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.desi_vocal import DesiVocalTools

audio_agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    tools=[DesiVocalTools()],
    description="You are an AI agent that can generate audio using the DesiVocal API.",
    instructions=[
        "When the user asks you to generate audio, use the `text_to_speech` tool to generate the audio.",
        "You'll generate the appropriate prompt to send to the tool to generate audio.",
        "You don't need to find the appropriate voice first, I already specified the voice to user.",
        "Return the audio file name in your response. Don't convert it to markdown.",
        "Generate the text prompt we send in hindi language",
    ],
    markdown=True,
    debug_mode=True,
    show_tool_calls=True,
)

audio_agent.print_response(
    "Generate a very small audio of history of french revolution"
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export DESI_VOCAL_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U requests openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/desi_vocal_tools.py
      ```

      ```bash Windows
      python cookbook/tools/desi_vocal_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Discord Tools



## Code

```python cookbook/tools/discord_tools.py
from agno.agent import Agent
from agno.tools.discord import DiscordTools

discord_tools = DiscordTools(
    bot_token=discord_token,
    enable_messaging=True,
    enable_history=True,
    enable_channel_management=True,
    enable_message_management=True,
)

discord_agent = Agent(
    name="Discord Agent",
    instructions=[
        "You are a Discord bot that can perform various operations.",
        "You can send messages, read message history, manage channels, and delete messages.",
    ],
    tools=[discord_tools],
    show_tool_calls=True,
    markdown=True,
)

channel_id = "YOUR_CHANNEL_ID"
server_id = "YOUR_SERVER_ID"

discord_agent.print_response(
    f"Send a message 'Hello from Agno!' to channel {channel_id}", stream=True
)

discord_agent.print_response(f"Get information about channel {channel_id}", stream=True)

discord_agent.print_response(f"List all channels in server {server_id}", stream=True)

discord_agent.print_response(
    f"Get the last 5 messages from channel {channel_id}", stream=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your Discord token">
    ```bash
    export DISCORD_BOT_TOKEN=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U discord.py openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/discord_tools.py
      ```

      ```bash Windows
      python cookbook/tools/discord_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# DuckDB Tools



## Code

```python cookbook/tools/duckdb_tools.py
from agno.agent import Agent
from agno.tools.duckdb import DuckDbTools

agent = Agent(
    tools=[DuckDbTools()],
    show_tool_calls=True,
    instructions="Use this file for Movies data: https://agno-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv",
)
agent.print_response(
    "What is the average rating of movies?", markdown=True, stream=False
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U duckdb openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/duckdb_tools.py
      ```

      ```bash Windows
      python cookbook/tools/duckdb_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# DuckDuckGo Search



## Code

```python cookbook/tools/duckduckgo_tools.py
from agno.agent import Agent
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(tools=[DuckDuckGoTools()], show_tool_calls=True)
agent.print_response("Whats happening in France?", markdown=True)

# We will search DDG but limit the site to Politifact
agent = Agent(
    tools=[DuckDuckGoTools(modifier="site:politifact.com")], show_tool_calls=True
)
agent.print_response(
    "Is Taylor Swift promoting energy-saving devices with Elon Musk?", markdown=False
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U duckduckgo-search openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/duckduckgo_tools.py
      ```

      ```bash Windows
      python cookbook/tools/duckduckgo_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Email Tools



## Code

```python cookbook/tools/email_tools.py
from agno.agent import Agent
from agno.tools.email import EmailTools

receiver_email = "<receiver_email>"
sender_email = "<sender_email>"
sender_name = "<sender_name>"
sender_passkey = "<sender_passkey>"

agent = Agent(
    tools=[
        EmailTools(
            receiver_email=receiver_email,
            sender_email=sender_email,
            sender_name=sender_name,
            sender_passkey=sender_passkey,
        )
    ]
)
agent.print_response("Send an email to <receiver_email>.")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Set your email credentials">
    ```bash
    export SENDER_EMAIL=xxx
    export SENDER_PASSKEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/email_tools.py
      ```

      ```bash Windows
      python cookbook/tools/email_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Exa Tools



## Code

```python cookbook/tools/exa_tools.py
from agno.agent import Agent
from agno.tools.exa import ExaTools

agent = Agent(
    tools=[ExaTools(include_domains=["cnbc.com", "reuters.com", "bloomberg.com"])],
    show_tool_calls=True,
)
agent.print_response("Search for AAPL news", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export EXA_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U exa-py openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/exa_tools.py
      ```

      ```bash Windows
      python cookbook/tools/exa_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Fal Tools



## Code

```python cookbook/tools/fal_tools.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.fal import FalTools

fal_agent = Agent(
    name="Fal Video Generator Agent",
    model=OpenAIChat(id="gpt-4o"),
    tools=[FalTools("fal-ai/hunyuan-video")],
    description="You are an AI agent that can generate videos using the Fal API.",
    instructions=[
        "When the user asks you to create a video, use the `generate_media` tool to create the video.",
        "Return the URL as raw to the user.",
        "Don't convert video URL to markdown or anything else.",
    ],
    markdown=True,
    debug_mode=True,
    show_tool_calls=True,
)

fal_agent.print_response("Generate video of balloon in the ocean")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export FAL_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U fal openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/fal_tools.py
      ```

      ```bash Windows
      python cookbook/tools/fal_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# File Tools



## Code

```python cookbook/tools/file_tools.py
from pathlib import Path

from agno.agent import Agent
from agno.tools.file import FileTools

agent = Agent(tools=[FileTools(Path("tmp/file"))], show_tool_calls=True)
agent.print_response(
    "What is the most advanced LLM currently? Save the answer to a file.", markdown=True
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/file_tools.py
      ```

      ```bash Windows
      python cookbook/tools/file_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Firecrawl Tools



## Code

```python cookbook/tools/firecrawl_tools.py
from agno.agent import Agent
from agno.tools.firecrawl import FirecrawlTools

agent = Agent(
    tools=[FirecrawlTools(scrape=False, crawl=True)],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Summarize this https://finance.yahoo.com/")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export FIRECRAWL_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U firecrawl openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/firecrawl_tools.py
      ```

      ```bash Windows
      python cookbook/tools/firecrawl_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Giphy Tools



## Code

```python cookbook/tools/giphy_tools.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.giphy import GiphyTools

gif_agent = Agent(
    name="Gif Generator Agent",
    model=OpenAIChat(id="gpt-4o"),
    tools=[GiphyTools(limit=5)],
    description="You are an AI agent that can generate gifs using Giphy.",
    instructions=[
        "When the user asks you to create a gif, come up with the appropriate Giphy query and use the `search_gifs` tool to find the appropriate gif.",
    ],
    debug_mode=True,
    show_tool_calls=True,
)

gif_agent.print_response("I want a gif to send to a friend for their birthday.")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GIPHY_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U giphy_client openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/giphy_tools.py
      ```

      ```bash Windows
      python cookbook/tools/giphy_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# GitHub Tools



## Code

```python cookbook/tools/github_tools.py
from agno.agent import Agent
from agno.tools.github import GithubTools

agent = Agent(
    instructions=[
        "Use your tools to answer questions about the repo: agno-agi/agno",
        "Do not create any issues or pull requests unless explicitly asked to do so",
    ],
    tools=[GithubTools()],
    show_tool_calls=True,
)
agent.print_response("List open pull requests", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your GitHub token">
    ```bash
    export GITHUB_TOKEN=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U PyGithub openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/github_tools.py
      ```

      ```bash Windows
      python cookbook/tools/github_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Google Calendar Tools



## Code

```python cookbook/tools/google_calendar_tools.py
from agno.agent import Agent
from agno.tools.google_calendar import GoogleCalendarTools

agent = Agent(
    tools=[GoogleCalendarTools()],
    show_tool_calls=True,
    markdown=True,
)

agent.print_response("What events do I have today?")
agent.print_response("Schedule a meeting with John tomorrow at 2pm")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Set up Google Calendar credentials">
    ```bash
    export GOOGLE_CALENDAR_CREDENTIALS=path/to/credentials.json
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-auth-oauthlib google-auth-httplib2 google-api-python-client openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/google_calendar_tools.py
      ```

      ```bash Windows
      python cookbook/tools/google_calendar_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Google Maps Tools



## Code

```python cookbook/tools/google_maps_tools.py
from agno.agent import Agent
from agno.tools.google_maps import GoogleMapTools
from agno.tools.crawl4ai import Crawl4aiTools  # Optional: for enriching place data

agent = Agent(
    name="Maps API Demo Agent",
    tools=[
        GoogleMapTools(),
        Crawl4aiTools(max_length=5000),  # Optional: for scraping business websites
    ],
    description="Location and business information specialist for mapping and location-based queries.",
    markdown=True,
    show_tool_calls=True,
)

# Example 1: Business Search
print("\n=== Business Search Example ===")
agent.print_response(
    "Find me highly rated Indian restaurants in Phoenix, AZ with their contact details",
    markdown=True,
    stream=True,
)

# Example 2: Directions
print("\n=== Directions Example ===")
agent.print_response(
    """Get driving directions from 'Phoenix Sky Harbor Airport' to 'Desert Botanical Garden', 
    avoiding highways if possible""",
    markdown=True,
    stream=True,
)

# Example 3: Address Validation and Geocoding
print("\n=== Address Validation and Geocoding Example ===")
agent.print_response(
    """Please validate and geocode this address: 
    '1600 Amphitheatre Parkway, Mountain View, CA'""",
    markdown=True,
    stream=True,
)

# Example 4: Distance Matrix
print("\n=== Distance Matrix Example ===")
agent.print_response(
    """Calculate the travel time and distance between these locations in Phoenix:
    Origins: ['Phoenix Sky Harbor Airport', 'Downtown Phoenix']
    Destinations: ['Desert Botanical Garden', 'Phoenix Zoo']""",
    markdown=True,
    stream=True,
)

# Example 5: Location Analysis
print("\n=== Location Analysis Example ===")
agent.print_response(
    """Analyze this location in Phoenix:
    Address: '2301 N Central Ave, Phoenix, AZ 85004'
    Please provide:
    1. Exact coordinates
    2. Nearby landmarks
    3. Elevation data
    4. Local timezone""",
    markdown=True,
    stream=True,
)

# Example 6: Multi-mode Transit Comparison
print("\n=== Transit Options Example ===")
agent.print_response(
    """Compare different travel modes from 'Phoenix Convention Center' to 'Phoenix Art Museum':
    1. Driving
    2. Walking
    3. Transit (if available)
    Include estimated time and distance for each option.""",
    markdown=True,
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export GOOGLE_MAPS_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```

    Get your API key from the [Google Cloud Console](https://console.cloud.google.com/projectselector2/google/maps-apis/credentials)
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai googlemaps agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/google_maps_tools.py
      ```

      ```bash Windows
      python cookbook/tools/google_maps_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Google Search Tools



## Code

```python cookbook/tools/googlesearch_tools.py
from agno.agent import Agent
from agno.tools.googlesearch import GoogleSearchTools

agent = Agent(
    tools=[GoogleSearchTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("What are the latest developments in AI?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API credentials">
    ```bash
    export GOOGLE_CSE_ID=xxx
    export GOOGLE_API_KEY=xxx
    export OPENAI_API_KEY=xxx 
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-api-python-client openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/googlesearch_tools.py
      ```

      ```bash Windows
      python cookbook/tools/googlesearch_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Hacker News Tools



## Code

```python cookbook/tools/hackernews_tools.py
from agno.agent import Agent
from agno.tools.hackernews import HackerNewsTools

agent = Agent(
    tools=[HackerNewsTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("What are the top stories on Hacker News right now?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U requests openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/hackernews_tools.py
      ```

      ```bash Windows
      python cookbook/tools/hackernews_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Jina Reader Tools



## Code

```python cookbook/tools/jina_reader_tools.py
from agno.agent import Agent
from agno.tools.jina_reader import JinaReaderTools

agent = Agent(
    tools=[JinaReaderTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Read and summarize this PDF: https://example.com/sample.pdf")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U jina-reader openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/jina_reader_tools.py
      ```

      ```bash Windows
      python cookbook/tools/jina_reader_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Jira Tools



## Code

```python cookbook/tools/jira_tools.py
from agno.agent import Agent
from agno.tools.jira import JiraTools

agent = Agent(
    tools=[JiraTools()],
    show_tool_calls=True,
    markdown=True,
)

agent.print_response("List all open issues in project 'DEMO'")
agent.print_response("Create a new task in project 'DEMO' with high priority")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your Jira credentials">
    ```bash
    export JIRA_API_TOKEN=xxx
    export JIRA_SERVER_URL=xxx
    export JIRA_EMAIL=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U jira openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/jira_tools.py
      ```

      ```bash Windows
      python cookbook/tools/jira_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Linear Tools



## Code

```python cookbook/tools/linear_tools.py
from agno.agent import Agent
from agno.tools.linear import LinearTools

agent = Agent(
    tools=[LinearTools()],
    show_tool_calls=True,
    markdown=True,
)

agent.print_response("Show me all active issues")
agent.print_response("Create a new high priority task for the engineering team")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your Linear API key">
    ```bash
    export LINEAR_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U linear-sdk openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/linear_tools.py
      ```

      ```bash Windows
      python cookbook/tools/linear_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Luma Labs Tools



## Code

```python cookbook/tools/lumalabs_tools.py
from agno.agent import Agent
from agno.tools.lumalabs import LumaLabsTools

agent = Agent(
    tools=[LumaLabsTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Generate a 3D model of a futuristic city")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export LUMALABS_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/lumalabs_tools.py
      ```

      ```bash Windows
      python cookbook/tools/lumalabs_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# MLX Transcribe Tools



## Code

```python cookbook/tools/mlx_transcribe_tools.py
from agno.agent import Agent
from agno.tools.mlx_transcribe import MLXTranscribeTools

agent = Agent(
    tools=[MLXTranscribeTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Transcribe this audio file: path/to/audio.mp3")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U mlx-transcribe openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/mlx_transcribe_tools.py
      ```

      ```bash Windows
      python cookbook/tools/mlx_transcribe_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Models Labs Tools



## Code

```python cookbook/tools/models_labs_tools.py
from agno.agent import Agent
from agno.tools.models_labs import ModelsLabsTools

agent = Agent(
    tools=[ModelsLabsTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Generate an image of a sunset over mountains")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export MODELS_LABS_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/models_labs_tools.py
      ```

      ```bash Windows
      python cookbook/tools/models_labs_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Newspaper Tools



## Code

```python cookbook/tools/newspaper_tools.py
from agno.agent import Agent
from agno.tools.newspaper import NewspaperTools

agent = Agent(
    tools=[NewspaperTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Extract the main article content from https://example.com/article")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U newspaper3k openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/newspaper_tools.py
      ```

      ```bash Windows
      python cookbook/tools/newspaper_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Newspaper4k Tools



## Code

```python cookbook/tools/newspaper4k_tools.py
from agno.agent import Agent
from agno.tools.newspaper4k import Newspaper4kTools

agent = Agent(
    tools=[Newspaper4kTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Analyze and summarize this news article: https://example.com/news")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U newspaper4k openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/newspaper4k_tools.py
      ```

      ```bash Windows
      python cookbook/tools/newspaper4k_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# OpenBB Tools



## Code

```python cookbook/tools/openbb_tools.py
from agno.agent import Agent
from agno.tools.openbb import OpenBBTools

agent = Agent(
    tools=[OpenBBTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Get the latest stock price for AAPL")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENBB_PAT=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openbb openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/openbb_tools.py
      ```

      ```bash Windows
      python cookbook/tools/openbb_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Pandas Tools



## Code

```python cookbook/tools/pandas_tools.py
from agno.agent import Agent
from agno.tools.pandas import PandasTools

agent = Agent(
    tools=[PandasTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Load and analyze the dataset from data.csv")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U pandas openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/pandas_tools.py
      ```

      ```bash Windows
      python cookbook/tools/pandas_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Postgres Tools



## Code

```python cookbook/tools/postgres_tools.py
from agno.agent import Agent
from agno.tools.postgres import PostgresTools

agent = Agent(
    tools=[PostgresTools(db_url="postgresql://user:pass@localhost:5432/db")],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Show me all tables in the database")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Set your database URL">
    ```bash
    export DATABASE_URL=postgresql://user:pass@localhost:5432/db
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U psycopg2-binary sqlalchemy openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/postgres_tools.py
      ```

      ```bash Windows
      python cookbook/tools/postgres_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# PubMed Tools



## Code

```python cookbook/tools/pubmed_tools.py
from agno.agent import Agent
from agno.tools.pubmed import PubMedTools

agent = Agent(
    tools=[PubMedTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Find recent research papers about COVID-19 vaccines")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U biopython openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/pubmed_tools.py
      ```

      ```bash Windows
      python cookbook/tools/pubmed_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Python Tools



## Code

```python cookbook/tools/python_tools.py
from agno.agent import Agent
from agno.tools.python import PythonTools

agent = Agent(
    tools=[PythonTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Calculate the factorial of 5 using Python")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/python_tools.py
      ```

      ```bash Windows
      python cookbook/tools/python_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Replicate Tools



## Code

```python cookbook/tools/replicate_tools.py
from agno.agent import Agent
from agno.tools.replicate import ReplicateTools

agent = Agent(
    tools=[ReplicateTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Generate an image of a cyberpunk city")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API token">
    ```bash
    export REPLICATE_API_TOKEN=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U replicate openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/replicate_tools.py
      ```

      ```bash Windows
      python cookbook/tools/replicate_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Resend Tools



## Code

```python cookbook/tools/resend_tools.py
from agno.agent import Agent
from agno.tools.resend import ResendTools

agent = Agent(
    tools=[ResendTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Send an email to test@example.com with the subject 'Test Email'")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export RESEND_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U resend openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/resend_tools.py
      ```

      ```bash Windows
      python cookbook/tools/resend_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# SearxNG Tools



## Code

```python cookbook/tools/searxng_tools.py
from agno.agent import Agent
from agno.tools.searxng import SearxNGTools

agent = Agent(
    tools=[SearxNGTools(instance_url="https://your-searxng-instance.com")],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Search for recent news about artificial intelligence")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U searxng-client openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/searxng_tools.py
      ```

      ```bash Windows
      python cookbook/tools/searxng_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# SerpAPI Tools



## Code

```python cookbook/tools/serpapi_tools.py
from agno.agent import Agent
from agno.tools.serpapi import SerpAPITools

agent = Agent(
    tools=[SerpAPITools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("What are the top search results for 'machine learning'?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export SERPAPI_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-search-results openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/serpapi_tools.py
      ```

      ```bash Windows
      python cookbook/tools/serpapi_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Shell Tools



## Code

```python cookbook/tools/shell_tools.py
from agno.agent import Agent
from agno.tools.shell import ShellTools

agent = Agent(
    tools=[ShellTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("List all files in the current directory")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/shell_tools.py
      ```

      ```bash Windows
      python cookbook/tools/shell_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Slack Tools



## Code

```python cookbook/tools/slack_tools.py
from agno.agent import Agent
from agno.tools.slack import SlackTools

agent = Agent(
    tools=[SlackTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Send a message to #general channel saying 'Hello from Agno!'")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Set your Slack token">
    ```bash
    export SLACK_BOT_TOKEN=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U slack-sdk openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/slack_tools.py
      ```

      ```bash Windows
      python cookbook/tools/slack_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Sleep Tools



## Code

```python cookbook/tools/sleep_tools.py
from agno.agent import Agent
from agno.tools.sleep import SleepTools

agent = Agent(
    tools=[SleepTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Wait for 5 seconds before continuing")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/sleep_tools.py
      ```

      ```bash Windows
      python cookbook/tools/sleep_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Spider Tools



## Code

```python cookbook/tools/spider_tools.py
from agno.agent import Agent
from agno.tools.spider import SpiderTools

agent = Agent(
    tools=[SpiderTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Crawl https://example.com and extract all links")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U scrapy openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/spider_tools.py
      ```

      ```bash Windows
      python cookbook/tools/spider_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# SQL Tools



## Code

```python cookbook/tools/sql_tools.py
from agno.agent import Agent
from agno.tools.sql import SQLTools

agent = Agent(
    tools=[SQLTools(db_url="sqlite:///database.db")],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Show me all tables in the database and their schemas")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/sql_tools.py
      ```

      ```bash Windows
      python cookbook/tools/sql_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Tavily Tools



## Code

```python cookbook/tools/tavily_tools.py
from agno.agent import Agent
from agno.tools.tavily import TavilyTools

agent = Agent(
    tools=[TavilyTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Search for recent breakthroughs in quantum computing")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export TAVILY_API_KEY=xxx
    export OPENAI_API_KEY=xxx 
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai tavily-python agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/tavily_tools.py
      ```

      ```bash Windows
      python cookbook/tools/tavily_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Todoist Tools



## Code

```python cookbook/tools/todoist_tools.py
"""
Example showing how to use the Todoist Tools with Agno

Requirements:
- Sign up/login to Todoist and get a Todoist API Token (get from https://app.todoist.com/app/settings/integrations/developer)
- pip install todoist-api-python

Usage:
- Set the following environment variables:
    export TODOIST_API_TOKEN="your_api_token"

- Or provide them when creating the TodoistTools instance
"""

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.todoist import TodoistTools

todoist_agent = Agent(
    name="Todoist Agent",
    role="Manage your todoist tasks",
    instructions=[
        "When given a task, create a todoist task for it.",
        "When given a list of tasks, create a todoist task for each one.",
        "When given a task to update, update the todoist task.",
        "When given a task to delete, delete the todoist task.",
        "When given a task to get, get the todoist task.",
    ],
    agent_id="todoist-agent",
    model=OpenAIChat(id="gpt-4o"),
    tools=[TodoistTools()],
    markdown=True,
    debug_mode=True,
    show_tool_calls=True,
)

# Example 1: Create a task
print("\n=== Create a task ===")
todoist_agent.print_response("Create a todoist task to buy groceries tomorrow at 10am")


# Example 2: Delete a task
print("\n=== Delete a task ===")
todoist_agent.print_response(
    "Delete the todoist task to buy groceries tomorrow at 10am"
)


# Example 3: Get all tasks
print("\n=== Get all tasks ===")
todoist_agent.print_response("Get all the todoist tasks")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API Token">
    ```bash
    export TODOIST_API_TOKEN=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U todoist-api-python openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/todoist_tools.py
      ```

      ```bash Windows
      python cookbook/tools/todoist_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Twilio Tools



## Code

```python cookbook/tools/twilio_tools.py
from agno.agent import Agent
from agno.tools.twilio import TwilioTools

agent = Agent(
    tools=[TwilioTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Send an SMS to +1234567890 saying 'Hello from Agno!'")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Set your Twilio credentials">
    ```bash
    export TWILIO_ACCOUNT_SID=xxx
    export TWILIO_AUTH_TOKEN=xxx
    export TWILIO_FROM_NUMBER=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U twilio openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/twilio_tools.py
      ```

      ```bash Windows
      python cookbook/tools/twilio_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Website Tools



## Code

```python cookbook/tools/website_tools.py
from agno.agent import Agent
from agno.tools.website import WebsiteTools

agent = Agent(
    tools=[WebsiteTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Extract the main content from https://example.com")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U beautifulsoup4 requests openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/website_tools.py
      ```

      ```bash Windows
      python cookbook/tools/website_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Wikipedia Tools



## Code

```python cookbook/tools/wikipedia_tools.py
from agno.agent import Agent
from agno.tools.wikipedia import WikipediaTools

agent = Agent(
    tools=[WikipediaTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Search Wikipedia for information about artificial intelligence")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U wikipedia openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/wikipedia_tools.py
      ```

      ```bash Windows
      python cookbook/tools/wikipedia_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# X (Twitter) Tools



## Code

```python cookbook/tools/x_tools.py
from agno.agent import Agent
from agno.tools.x import XTools

agent = Agent(
    tools=[XTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Make a post saying 'Hello World from Agno!'")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Set your X credentials">
    ```bash
    export X_CONSUMER_KEY=xxx
    export X_CONSUMER_SECRET=xxx
    export X_ACCESS_TOKEN=xxx
    export X_ACCESS_TOKEN_SECRET=xxx
    export X_BEARER_TOKEN=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U tweepy openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/x_tools.py
      ```

      ```bash Windows
      python cookbook/tools/x_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# YFinance Tools



## Code

```python cookbook/tools/yfinance_tools.py
from agno.agent import Agent
from agno.tools.yfinance import YFinanceTools

agent = Agent(
    tools=[YFinanceTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Get the current stock price and recent history for AAPL")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U yfinance openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/yfinance_tools.py
      ```

      ```bash Windows
      python cookbook/tools/yfinance_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# YouTube Tools



## Code

```python cookbook/tools/youtube_tools.py
from agno.agent import Agent
from agno.tools.youtube import YouTubeTools

agent = Agent(
    tools=[YouTubeTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Search for recent videos about artificial intelligence")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export YOUTUBE_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-api-python-client openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/youtube_tools.py
      ```

      ```bash Windows
      python cookbook/tools/youtube_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Zendesk Tools



## Code

```python cookbook/tools/zendesk_tools.py
from agno.agent import Agent
from agno.tools.zendesk import ZendeskTools

agent = Agent(
    tools=[ZendeskTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Show me all open tickets")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Set your Zendesk credentials">
    ```bash
    export ZENDESK_EMAIL=xxx
    export ZENDESK_TOKEN=xxx
    export ZENDESK_SUBDOMAIN=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U zenpy openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/tools/zendesk_tools.py
      ```

      ```bash Windows
      python cookbook/tools/zendesk_tools.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Cassandra Integration



## Code

```python cookbook/agent_concepts/vector_dbs/cassandra_db.py
from agno.agent import Agent
from agno.embedder.mistral import MistralEmbedder
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.models.mistral import MistralChat
from agno.vectordb.cassandra import Cassandra

try:
    from cassandra.cluster import Cluster
except (ImportError, ModuleNotFoundError):
    raise ImportError(
        "Could not import cassandra-driver python package.Please install it with pip install cassandra-driver."
    )

cluster = Cluster()

session = cluster.connect()
session.execute(
    """
    CREATE KEYSPACE IF NOT EXISTS testkeyspace
    WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }
    """
)

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=Cassandra(
        table_name="recipes",
        keyspace="testkeyspace",
        session=session,
        embedder=MistralEmbedder(),
    ),
)

knowledge_base.load(recreate=True)  # Comment out after first run

agent = Agent(
    model=MistralChat(),
    knowledge=knowledge_base,
    show_tool_calls=True,
)

agent.print_response(
    "What are the health benefits of Khao Niew Dam Piek Maphrao Awn?",
    markdown=True,
    show_full_reasoning=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U cassandra-driver pypdf openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/vector_dbs/cassandra_db.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/vector_dbs/cassandra_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# ChromaDB Integration



## Code

```python cookbook/agent_concepts/vector_dbs/chroma_db.py
from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.chroma import ChromaDb

# Initialize ChromaDB
vector_db = ChromaDb(collection="recipes", path="tmp/chromadb", persistent_client=True)

# Create knowledge base
knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=vector_db,
)

knowledge_base.load(recreate=False)  # Comment out after first run

# Create and use the agent
agent = Agent(knowledge=knowledge_base, show_tool_calls=True)
agent.print_response("Show me how to make Tom Kha Gai", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U chromadb pypdf openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/vector_dbs/chroma_db.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/vector_dbs/chroma_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Clickhouse Integration



## Code

```python cookbook/agent_concepts/vector_dbs/clickhouse.py
from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.storage.agent.sqlite import SqliteAgentStorage
from agno.vectordb.clickhouse import Clickhouse

agent = Agent(
    storage=SqliteAgentStorage(table_name="recipe_agent"),
    knowledge=PDFUrlKnowledgeBase(
        urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
        vector_db=Clickhouse(
            table_name="recipe_documents",
            host="localhost",
            port=8123,
            username="ai",
            password="ai",
        ),
    ),
    show_tool_calls=True,
    search_knowledge=True,
    read_chat_history=True,
)
agent.knowledge.load(recreate=False)  # type: ignore

agent.print_response("How do I make pad thai?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Start Clickhouse">
    ```bash
    docker run -d \
      -e CLICKHOUSE_DB=ai \
      -e CLICKHOUSE_USER=ai \
      -e CLICKHOUSE_PASSWORD=ai \
      -e CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT=1 \
      -v clickhouse_data:/var/lib/clickhouse/ \
      -v clickhouse_log:/var/log/clickhouse-server/ \
      -p 8123:8123 \
      -p 9000:9000 \
      --ulimit nofile=262144:262144 \
      --name clickhouse-server \
      clickhouse/clickhouse-server
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U clickhouse-connect pypdf openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/vector_dbs/clickhouse.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/vector_dbs/clickhouse.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# LanceDB Integration



## Code

```python cookbook/agent_concepts/vector_dbs/lance_db.py
from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.lancedb import LanceDb

vector_db = LanceDb(
    table_name="recipes",
    uri="/tmp/lancedb",  # You can change this path to store data elsewhere
)

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=vector_db,
)

knowledge_base.load(recreate=False)  # Comment out after first run

agent = Agent(knowledge=knowledge_base, show_tool_calls=True)
agent.print_response("How to make Tom Kha Gai", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U lancedb pypdf openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/vector_dbs/lance_db.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/vector_dbs/lance_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Milvus Integration



## Code

```python cookbook/agent_concepts/vector_dbs/milvus.py
from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.milvus import Milvus

COLLECTION_NAME = "thai-recipes"

vector_db = Milvus(collection=COLLECTION_NAME, url="http://localhost:6333")

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=vector_db,
)

knowledge_base.load(recreate=False)  # Comment out after first run

agent = Agent(knowledge=knowledge_base, show_tool_calls=True)
agent.print_response("List down the ingredients to make Massaman Gai", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U pymilvus pypdf openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/vector_dbs/milvus.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/vector_dbs/milvus.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# MongoDB Integration



## Code

```python cookbook/agent_concepts/vector_dbs/mongodb.py
from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.mongodb import MongoDb

mdb_connection_string = "mongodb://ai:ai@localhost:27017/ai?authSource=admin"

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=MongoDb(
        collection_name="recipes",
        db_url=mdb_connection_string,
        wait_until_index_ready=60,
        wait_after_insert=300,
    ),
)
knowledge_base.load(recreate=True)

agent = Agent(knowledge=knowledge_base, show_tool_calls=True)
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install -U pymongo pypdf openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/vector_dbs/mongodb.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/vector_dbs/mongodb.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# PgVector Integration



## Code

```python cookbook/agent_concepts/vector_dbs/pg_vector.py
from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

vector_db = PgVector(table_name="recipes", db_url=db_url)

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=vector_db,
)
knowledge_base.load(recreate=False)  # Comment out after first run

agent = Agent(knowledge=knowledge_base, show_tool_calls=True)
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Start PgVector">
    ```bash
    docker run -d \
      -e POSTGRES_DB=ai \
      -e POSTGRES_USER=ai \
      -e POSTGRES_PASSWORD=ai \
      -e PGDATA=/var/lib/postgresql/data/pgdata \
      -v pgvolume:/var/lib/postgresql/data \
      -p 5532:5432 \
      --name pgvector \
      agnohq/pgvector:16
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy pgvector psycopg pypdf openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/vector_dbs/pg_vector.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/vector_dbs/pg_vector.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Pinecone Integration



## Code

```python cookbook/agent_concepts/vector_dbs/pinecone_db.py
from os import getenv

from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.pineconedb import PineconeDb

api_key = getenv("PINECONE_API_KEY")
index_name = "thai-recipe-index"

vector_db = PineconeDb(
    name=index_name,
    dimension=1536,
    metric="cosine",
    spec={"serverless": {"cloud": "aws", "region": "us-east-1"}},
    api_key=api_key,
)

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=vector_db,
)

knowledge_base.load(recreate=False, upsert=True)

agent = Agent(
    knowledge=knowledge_base,
    show_tool_calls=True,
    search_knowledge=True,
    read_chat_history=True,
)

agent.print_response("How do I make pad thai?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export PINECONE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U pinecone-client pypdf openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/vector_dbs/pinecone_db.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/vector_dbs/pinecone_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Qdrant Integration



## Code

```python cookbook/agent_concepts/vector_dbs/qdrant_db.py
from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.qdrant import Qdrant

COLLECTION_NAME = "thai-recipes"

vector_db = Qdrant(collection=COLLECTION_NAME, url="http://localhost:6333")

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=vector_db,
)

knowledge_base.load(recreate=False)  # Comment out after first run

agent = Agent(knowledge=knowledge_base, show_tool_calls=True)
agent.print_response("List down the ingredients to make Massaman Gai", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Start Qdrant">
    ```bash
    docker run -p 6333:6333 -p 6334:6334 \
      -v $(pwd)/qdrant_storage:/qdrant/storage:z \
      qdrant/qdrant
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U qdrant-client pypdf openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/vector_dbs/qdrant_db.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/vector_dbs/qdrant_db.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# SingleStore Integration



## Code

```python cookbook/agent_concepts/vector_dbs/singlestore.py
from os import getenv

from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.singlestore import SingleStore
from sqlalchemy.engine import create_engine

USERNAME = getenv("SINGLESTORE_USERNAME")
PASSWORD = getenv("SINGLESTORE_PASSWORD")
HOST = getenv("SINGLESTORE_HOST")
PORT = getenv("SINGLESTORE_PORT")
DATABASE = getenv("SINGLESTORE_DATABASE")
SSL_CERT = getenv("SINGLESTORE_SSL_CERT", None)

db_url = (
    f"mysql+pymysql://{USERNAME}:{PASSWORD}@{HOST}:{PORT}/{DATABASE}?charset=utf8mb4"
)
if SSL_CERT:
    db_url += f"&ssl_ca={SSL_CERT}&ssl_verify_cert=true"

db_engine = create_engine(db_url)

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=SingleStore(
        collection="recipes",
        db_engine=db_engine,
        schema=DATABASE,
    ),
)

knowledge_base.load(recreate=False)

agent = Agent(
    knowledge=knowledge_base,
    show_tool_calls=True,
    search_knowledge=True,
    read_chat_history=True,
)

agent.print_response("How do I make pad thai?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set environment variables">
    ```bash
    export SINGLESTORE_HOST="localhost"
    export SINGLESTORE_PORT="3306"
    export SINGLESTORE_USERNAME="root"
    export SINGLESTORE_PASSWORD="admin"
    export SINGLESTORE_DATABASE="AGNO"
    export SINGLESTORE_SSL_CA=".certs/singlestore_bundle.pem"
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U sqlalchemy pymysql pypdf openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/agent_concepts/vector_dbs/singlestore.py
      ```

      ```bash Windows
      python cookbook/agent_concepts/vector_dbs/singlestore.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent Context



This example shows how to inject external dependencies into an agent. The context is evaluated when the agent is run, acting like dependency injection for Agents.

Example prompts to try:

* "Summarize the top stories on HackerNews"
* "What are the trending tech discussions right now?"
* "Analyze the current top stories and identify trends"
* "What's the most upvoted story today?"

## Code

```python agent_context.py
import json
from textwrap import dedent

import httpx
from agno.agent import Agent
from agno.models.openai import OpenAIChat


def get_top_hackernews_stories(num_stories: int = 5) -> str:
    """Fetch and return the top stories from HackerNews.

    Args:
        num_stories: Number of top stories to retrieve (default: 5)
    Returns:
        JSON string containing story details (title, url, score, etc.)
    """
    # Get top stories
    stories = [
        {
            k: v
            for k, v in httpx.get(
                f"https://hacker-news.firebaseio.com/v0/item/{id}.json"
            )
            .json()
            .items()
            if k != "kids"  # Exclude discussion threads
        }
        for id in httpx.get(
            "https://hacker-news.firebaseio.com/v0/topstories.json"
        ).json()[:num_stories]
    ]
    return json.dumps(stories, indent=4)


# Create a Context-Aware Agent that can access real-time HackerNews data
agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    # Each function in the context is evaluated when the agent is run,
    # think of it as dependency injection for Agents
    context={"top_hackernews_stories": get_top_hackernews_stories},
    # add_context will automatically add the context to the user message
    # add_context=True,
    # Alternatively, you can manually add the context to the instructions
    instructions=dedent("""\
        You are an insightful tech trend observer! 📰

        Here are the top stories on HackerNews:
        {top_hackernews_stories}\
    """),
    markdown=True,
)

# Example usage
agent.print_response(
    "Summarize the top stories on HackerNews and identify any interesting trends.",
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai httpx agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python agent_context.py
    ```
  </Step>
</Steps>


# Agent Session



This example shows how to create an agent with persistent memory stored in a SQLite database. We set the session\_id on the agent when resuming the conversation, this way the previous chat history is preserved.

Key features:

* Stores conversation history in a SQLite database
* Continues conversations across multiple sessions
* References previous context in responses

## Code

```python agent_session.py
import json
from typing import Optional

import typer
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.storage.agent.sqlite import SqliteAgentStorage
from rich.console import Console
from rich.json import JSON
from rich.panel import Panel
from rich.prompt import Prompt
from rich import print

console = Console()


def create_agent(user: str = "user"):
    session_id: Optional[str] = None

    # Ask if user wants to start new session or continue existing one
    new = typer.confirm("Do you want to start a new session?")

    # Get existing session if user doesn't want a new one
    agent_storage = SqliteAgentStorage(
        table_name="agent_sessions", db_file="tmp/agents.db"
    )

    if not new:
        existing_sessions = agent_storage.get_all_session_ids(user)
        if len(existing_sessions) > 0:
            session_id = existing_sessions[0]

    agent = Agent(
        user_id=user,
        # Set the session_id on the agent to resume the conversation
        session_id=session_id,
        model=OpenAIChat(id="gpt-4o"),
        storage=agent_storage,
        # Add chat history to messages
        add_history_to_messages=True,
        num_history_responses=3,
        markdown=True,
    )

    if session_id is None:
        session_id = agent.session_id
        if session_id is not None:
            print(f"Started Session: {session_id}\n")
        else:
            print("Started Session\n")
    else:
        print(f"Continuing Session: {session_id}\n")

    return agent


def print_messages(agent):
    """Print the current chat history in a formatted panel"""
    console.print(
        Panel(
            JSON(
                json.dumps(
                    [
                        m.model_dump(include={"role", "content"})
                        for m in agent.memory.messages
                    ]
                ),
                indent=4,
            ),
            title=f"Chat History for session_id: {agent.session_id}",
            expand=True,
        )
    )


def main(user: str = "user"):
    agent = create_agent(user)

    print("Chat with an OpenAI agent!")
    exit_on = ["exit", "quit", "bye"]
    while True:
        message = Prompt.ask(f"[bold] :sunglasses: {user} [/bold]")
        if message in exit_on:
            break

        agent.print_response(message=message, stream=True, markdown=True)
        print_messages(agent)


if __name__ == "__main__":
    typer.run(main)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai sqlalchemy agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python agent_session.py
    ```
  </Step>
</Steps>


# Agent State



This example shows how to create an agent that maintains state across interactions. It demonstrates a simple counter mechanism, but this pattern can be extended to more complex state management like maintaining conversation context, user preferences, or tracking multi-step processes.

Example prompts to try:

* "Increment the counter 3 times and tell me the final count"
* "What's our current count? Add 2 more to it"
* "Let's increment the counter 5 times, but tell me each step"
* "Add 4 to our count and remind me where we started"
* "Increase the counter twice and summarize our journey"

## Code

```python agent_state.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat


# Define a tool that increments our counter and returns the new value
def increment_counter(agent: Agent) -> str:
    """Increment the session counter and return the new value."""
    agent.session_state["count"] += 1
    return f"The count is now {agent.session_state['count']}"


# Create a State Manager Agent that maintains state
agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    # Initialize the session state with a counter starting at 0
    session_state={"count": 0},
    tools=[increment_counter],
    # You can use variables from the session state in the instructions
    instructions=dedent("""\
        You are the State Manager, an enthusiastic guide to state management! 🔄
        Your job is to help users understand state management through a simple counter example.

        Follow these guidelines for every interaction:
        1. Always acknowledge the current state (count) when relevant
        2. Use the increment_counter tool to modify the state
        3. Explain state changes in a clear and engaging way

        Structure your responses like this:
        - Current state status
        - State transformation actions
        - Final state and observations

        Starting state (count) is: {count}\
    """),
    show_tool_calls=True,
    markdown=True,
)

# Example usage
agent.print_response(
    "Let's increment the counter 3 times and observe the state changes!",
    stream=True,
)

# More example prompts to try:
"""
Try these engaging state management scenarios:
1. "Update our state 4 times and track the changes"
2. "Modify the counter twice and explain the state transitions"
3. "Increment 3 times and show how state persists"
4. "Let's perform 5 state updates with observations"
5. "Add 3 to our count and explain the state management concept"
"""

print(f"Final session state: {agent.session_state}")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python agent_state.py
    ```
  </Step>
</Steps>


# Agent Team



This example shows how to create a powerful team of AI agents working together to provide comprehensive financial analysis and news reporting. The team consists of:

1. Web Agent: Searches and analyzes latest news
2. Finance Agent: Analyzes financial data and market trends
3. Lead Editor: Coordinates and combines insights from both agents

Example prompts to try:

* "What's the latest news and financial performance of Apple (AAPL)?"
* "Analyze the impact of AI developments on NVIDIA's stock (NVDA)"
* "How are EV manufacturers performing? Focus on Tesla (TSLA) and Rivian (RIVN)"
* "What's the market outlook for semiconductor companies like AMD and Intel?"
* "Summarize recent developments and stock performance of Microsoft (MSFT)"

## Code

```python agent_team.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.yfinance import YFinanceTools

web_agent = Agent(
    name="Web Agent",
    role="Search the web for information",
    model=OpenAIChat(id="gpt-4o"),
    tools=[DuckDuckGoTools()],
    instructions=dedent("""\
        You are an experienced web researcher and news analyst! 🔍

        Follow these steps when searching for information:
        1. Start with the most recent and relevant sources
        2. Cross-reference information from multiple sources
        3. Prioritize reputable news outlets and official sources
        4. Always cite your sources with links
        5. Focus on market-moving news and significant developments

        Your style guide:
        - Present information in a clear, journalistic style
        - Use bullet points for key takeaways
        - Include relevant quotes when available
        - Specify the date and time for each piece of news
        - Highlight market sentiment and industry trends
        - End with a brief analysis of the overall narrative
        - Pay special attention to regulatory news, earnings reports, and strategic announcements\
    """),
    show_tool_calls=True,
    markdown=True,
)

finance_agent = Agent(
    name="Finance Agent",
    role="Get financial data",
    model=OpenAIChat(id="gpt-4o"),
    tools=[
        YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True)
    ],
    instructions=dedent("""\
        You are a skilled financial analyst with expertise in market data! 📊

        Follow these steps when analyzing financial data:
        1. Start with the latest stock price, trading volume, and daily range
        2. Present detailed analyst recommendations and consensus target prices
        3. Include key metrics: P/E ratio, market cap, 52-week range
        4. Analyze trading patterns and volume trends
        5. Compare performance against relevant sector indices

        Your style guide:
        - Use tables for structured data presentation
        - Include clear headers for each data section
        - Add brief explanations for technical terms
        - Highlight notable changes with emojis (📈 📉)
        - Use bullet points for quick insights
        - Compare current values with historical averages
        - End with a data-driven financial outlook\
    """),
    show_tool_calls=True,
    markdown=True,
)

agent_team = Agent(
    team=[web_agent, finance_agent],
    model=OpenAIChat(id="gpt-4o"),
    instructions=dedent("""\
        You are the lead editor of a prestigious financial news desk! 📰

        Your role:
        1. Coordinate between the web researcher and financial analyst
        2. Combine their findings into a compelling narrative
        3. Ensure all information is properly sourced and verified
        4. Present a balanced view of both news and data
        5. Highlight key risks and opportunities

        Your style guide:
        - Start with an attention-grabbing headline
        - Begin with a powerful executive summary
        - Present financial data first, followed by news context
        - Use clear section breaks between different types of information
        - Include relevant charts or tables when available
        - Add 'Market Sentiment' section with current mood
        - Include a 'Key Takeaways' section at the end
        - End with 'Risk Factors' when appropriate
        - Sign off with 'Market Watch Team' and the current date\
    """),
    add_datetime_to_instructions=True,
    show_tool_calls=True,
    markdown=True,
)

# Example usage with diverse queries
agent_team.print_response(
    "Summarize analyst recommendations and share the latest news for NVDA", stream=True
)
agent_team.print_response(
    "What's the market outlook and financial performance of AI semiconductor companies?",
    stream=True,
)
agent_team.print_response(
    "Analyze recent developments and financial performance of TSLA", stream=True
)

# More example prompts to try:
"""
Advanced queries to explore:
1. "Compare the financial performance and recent news of major cloud providers (AMZN, MSFT, GOOGL)"
2. "What's the impact of recent Fed decisions on banking stocks? Focus on JPM and BAC"
3. "Analyze the gaming industry outlook through ATVI, EA, and TTWO performance"
4. "How are social media companies performing? Compare META and SNAP"
5. "What's the latest on AI chip manufacturers and their market position?"
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai duckduckgo-search yfinance agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python agent_team.py
    ```
  </Step>
</Steps>


# Agent with Knowledge



This example shows how to create an AI cooking assistant that combines knowledge from a curated recipe database with web searching capabilities. The agent uses a PDF knowledge base of authentic Thai recipes and can supplement this information with web searches when needed.

Example prompts to try:

* "How do I make authentic Pad Thai?"
* "What's the difference between red and green curry?"
* "Can you explain what galangal is and possible substitutes?"
* "Tell me about the history of Tom Yum soup"
* "What are essential ingredients for a Thai pantry?"
* "How do I make Thai basil chicken (Pad Kra Pao)?"

## Code

```python agent_with_knowledge.py
from textwrap import dedent

from agno.agent import Agent
from agno.embedder.openai import OpenAIEmbedder
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.vectordb.lancedb import LanceDb, SearchType

# Create a Recipe Expert Agent with knowledge of Thai recipes
agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    instructions=dedent("""\
        You are a passionate and knowledgeable Thai cuisine expert! 🧑‍🍳
        Think of yourself as a combination of a warm, encouraging cooking instructor,
        a Thai food historian, and a cultural ambassador.

        Follow these steps when answering questions:
        1. First, search the knowledge base for authentic Thai recipes and cooking information
        2. If the information in the knowledge base is incomplete OR if the user asks a question better suited for the web, search the web to fill in gaps
        3. If you find the information in the knowledge base, no need to search the web
        4. Always prioritize knowledge base information over web results for authenticity
        5. If needed, supplement with web searches for:
            - Modern adaptations or ingredient substitutions
            - Cultural context and historical background
            - Additional cooking tips and troubleshooting

        Communication style:
        1. Start each response with a relevant cooking emoji
        2. Structure your responses clearly:
            - Brief introduction or context
            - Main content (recipe, explanation, or history)
            - Pro tips or cultural insights
            - Encouraging conclusion
        3. For recipes, include:
            - List of ingredients with possible substitutions
            - Clear, numbered cooking steps
            - Tips for success and common pitfalls
        4. Use friendly, encouraging language

        Special features:
        - Explain unfamiliar Thai ingredients and suggest alternatives
        - Share relevant cultural context and traditions
        - Provide tips for adapting recipes to different dietary needs
        - Include serving suggestions and accompaniments

        End each response with an uplifting sign-off like:
        - 'Happy cooking! ขอให้อร่อย (Enjoy your meal)!'
        - 'May your Thai cooking adventure bring joy!'
        - 'Enjoy your homemade Thai feast!'

        Remember:
        - Always verify recipe authenticity with the knowledge base
        - Clearly indicate when information comes from web sources
        - Be encouraging and supportive of home cooks at all skill levels\
    """),
    knowledge=PDFUrlKnowledgeBase(
        urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
        vector_db=LanceDb(
            uri="tmp/lancedb",
            table_name="recipe_knowledge",
            search_type=SearchType.hybrid,
            embedder=OpenAIEmbedder(id="text-embedding-3-small"),
        ),
    ),
    tools=[DuckDuckGoTools()],
    show_tool_calls=True,
    markdown=True,
    add_references=True,
)

# Comment out after the knowledge base is loaded
if agent.knowledge is not None:
    agent.knowledge.load()

agent.print_response(
    "How do I make chicken and galangal in coconut milk soup", stream=True
)
agent.print_response("What is the history of Thai curry?", stream=True)
agent.print_response("What ingredients do I need for Pad Thai?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai lancedb tantivy pypdf duckduckgo-search agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python agent_with_knowledge.py
    ```
  </Step>
</Steps>


# Agent with Storage



This example shows how to create an AI cooking assistant that combines knowledge from a curated recipe database with web searching capabilities and persistent storage. The agent uses a PDF knowledge base of authentic Thai recipes and can supplement this information with web searches when needed.

Example prompts to try:

* "How do I make authentic Pad Thai?"
* "What's the difference between red and green curry?"
* "Can you explain what galangal is and possible substitutes?"
* "Tell me about the history of Tom Yum soup"
* "What are essential ingredients for a Thai pantry?"
* "How do I make Thai basil chicken (Pad Kra Pao)?"

## Code

```python agent_with_storage.py
from textwrap import dedent
from typing import List, Optional

import typer
from agno.agent import Agent
from agno.embedder.openai import OpenAIEmbedder
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.models.openai import OpenAIChat
from agno.storage.agent.sqlite import SqliteAgentStorage
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.vectordb.lancedb import LanceDb, SearchType
from rich import print

agent_knowledge = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=LanceDb(
        uri="tmp/lancedb",
        table_name="recipe_knowledge",
        search_type=SearchType.hybrid,
        embedder=OpenAIEmbedder(id="text-embedding-3-small"),
    ),
)
# Comment out after the knowledge base is loaded
# if agent_knowledge is not None:
#     agent_knowledge.load()

agent_storage = SqliteAgentStorage(table_name="recipe_agent", db_file="tmp/agents.db")


def recipe_agent(user: str = "user"):
    session_id: Optional[str] = None

    # Ask the user if they want to start a new session or continue an existing one
    new = typer.confirm("Do you want to start a new session?")

    if not new:
        existing_sessions: List[str] = agent_storage.get_all_session_ids(user)
        if len(existing_sessions) > 0:
            session_id = existing_sessions[0]

    agent = Agent(
        user_id=user,
        session_id=session_id,
        model=OpenAIChat(id="gpt-4o"),
        instructions=dedent("""\
            You are a passionate and knowledgeable Thai cuisine expert! 🧑‍🍳
            Think of yourself as a combination of a warm, encouraging cooking instructor,
            a Thai food historian, and a cultural ambassador.

            Follow these steps when answering questions:
            1. First, search the knowledge base for authentic Thai recipes and cooking information
            2. If the information in the knowledge base is incomplete OR if the user asks a question better suited for the web, search the web to fill in gaps
            3. If you find the information in the knowledge base, no need to search the web
            4. Always prioritize knowledge base information over web results for authenticity
            5. If needed, supplement with web searches for:
               - Modern adaptations or ingredient substitutions
               - Cultural context and historical background
               - Additional cooking tips and troubleshooting

            Communication style:
            1. Start each response with a relevant cooking emoji
            2. Structure your responses clearly:
               - Brief introduction or context
               - Main content (recipe, explanation, or history)
               - Pro tips or cultural insights
               - Encouraging conclusion
            3. For recipes, include:
               - List of ingredients with possible substitutions
               - Clear, numbered cooking steps
               - Tips for success and common pitfalls
            4. Use friendly, encouraging language

            Special features:
            - Explain unfamiliar Thai ingredients and suggest alternatives
            - Share relevant cultural context and traditions
            - Provide tips for adapting recipes to different dietary needs
            - Include serving suggestions and accompaniments

            End each response with an uplifting sign-off like:
            - 'Happy cooking! ขอให้อร่อย (Enjoy your meal)!'
            - 'May your Thai cooking adventure bring joy!'
            - 'Enjoy your homemade Thai feast!'

            Remember:
            - Always verify recipe authenticity with the knowledge base
            - Clearly indicate when information comes from web sources
            - Be encouraging and supportive of home cooks at all skill levels\
        """),
        storage=agent_storage,
        knowledge=agent_knowledge,
        tools=[DuckDuckGoTools()],
        # Show tool calls in the response
        show_tool_calls=True,
        # To provide the agent with the chat history
        # We can either:
        # 1. Provide the agent with a tool to read the chat history
        # 2. Automatically add the chat history to the messages sent to the model
        #
        # 1. Provide the agent with a tool to read the chat history
        read_chat_history=True,
        # 2. Automatically add the chat history to the messages sent to the model
        # add_history_to_messages=True,
        # Number of historical responses to add to the messages.
        # num_history_responses=3,
        markdown=True,
    )

    print("You are about to chat with an agent!")
    if session_id is None:
        session_id = agent.session_id
        if session_id is not None:
            print(f"Started Session: {session_id}\n")
        else:
            print("Started Session\n")
    else:
        print(f"Continuing Session: {session_id}\n")

    # Runs the agent as a command line application
    agent.cli_app(markdown=True)


if __name__ == "__main__":
    typer.run(recipe_agent)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai lancedb tantivy pypdf duckduckgo-search sqlalchemy agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python agent_with_storage.py
    ```
  </Step>
</Steps>


# Agent with Tools



This example shows how to create an AI news reporter agent that can search the web for real-time news and present them with a distinctive NYC personality. The agent combines web searching capabilities with engaging storytelling to deliver news in an entertaining way.

Example prompts to try:

* "What's the latest headline from Wall Street?"
* "Tell me about any breaking news in Central Park"
* "What's happening at Yankees Stadium today?"
* "Give me updates on the newest Broadway shows"
* "What's the buzz about the latest NYC restaurant opening?"

## Code

```python agent_with_tools.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

# Create a News Reporter Agent with a fun personality
agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    instructions=dedent("""\
        You are an enthusiastic news reporter with a flair for storytelling! 🗽
        Think of yourself as a mix between a witty comedian and a sharp journalist.

        Follow these guidelines for every report:
        1. Start with an attention-grabbing headline using relevant emoji
        2. Use the search tool to find current, accurate information
        3. Present news with authentic NYC enthusiasm and local flavor
        4. Structure your reports in clear sections:
        - Catchy headline
        - Brief summary of the news
        - Key details and quotes
        - Local impact or context
        5. Keep responses concise but informative (2-3 paragraphs max)
        6. Include NYC-style commentary and local references
        7. End with a signature sign-off phrase

        Sign-off examples:
        - 'Back to you in the studio, folks!'
        - 'Reporting live from the city that never sleeps!'
        - 'This is [Your Name], live from the heart of Manhattan!'

        Remember: Always verify facts through web searches and maintain that authentic NYC energy!\
    """),
    tools=[DuckDuckGoTools()],
    show_tool_calls=True,
    markdown=True,
)

# Example usage
agent.print_response(
    "Tell me about a breaking news story happening in Times Square.", stream=True
)

# More example prompts to try:
"""
Try these engaging news queries:
1. "What's the latest development in NYC's tech scene?"
2. "Tell me about any upcoming events at Madison Square Garden"
3. "What's the weather impact on NYC today?"
4. "Any updates on the NYC subway system?"
5. "What's the hottest food trend in Manhattan right now?"
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai duckduckgo-search agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python agent_with_tools.py
    ```
  </Step>
</Steps>


# Audio Agent



This example shows how to create an AI agent that can process audio input and generate audio responses. You can use this agent for various voice-based interactions, from analyzing speech content to generating natural-sounding responses.

Example audio interactions to try:

* Upload a recording of a conversation for analysis
* Have the agent respond to questions with voice output
* Process different languages and accents
* Analyze tone and emotion in speech

## Code

```python audio_agent.py
from textwrap import dedent

import requests
from agno.agent import Agent
from agno.media import Audio
from agno.models.openai import OpenAIChat
from agno.utils.audio import write_audio_to_file

# Create an AI Voice Interaction Agent
agent = Agent(
    model=OpenAIChat(
        id="gpt-4o-audio-preview",
        modalities=["text", "audio"],
        audio={"voice": "alloy", "format": "wav"},
    ),
    description=dedent("""\
        You are an expert in audio processing and voice interaction, capable of understanding
        and analyzing spoken content while providing natural, engaging voice responses.
        You excel at comprehending context, emotion, and nuance in speech.\
    """),
    instructions=dedent("""\
        As a voice interaction specialist, follow these guidelines:
        1. Listen carefully to audio input to understand both content and context
        2. Provide clear, concise responses that address the main points
        3. When generating voice responses, maintain a natural, conversational tone
        4. Consider the speaker's tone and emotion in your analysis
        5. If the audio is unclear, ask for clarification

        Focus on creating engaging and helpful voice interactions!\
    """),
)

# Fetch the audio file and convert it to a base64 encoded string
url = "https://openaiassets.blob.core.windows.net/$web/API/docs/audio/alloy.wav"
response = requests.get(url)
response.raise_for_status()

# Process the audio and get a response
agent.run(
    "What's in this recording? Please analyze the content and tone.",
    audio=[Audio(content=response.content, format="wav")],
)

# Save the audio response if available
if agent.run_response.response_audio is not None:
    write_audio_to_file(
        audio=agent.run_response.response_audio.content, filename="tmp/response.wav"
    )

# More example interactions to try:
"""
Try these voice interaction scenarios:
1. "Can you summarize the main points discussed in this recording?"
2. "What emotions or tone do you detect in the speaker's voice?"
3. "Please provide a detailed analysis of the speech patterns and clarity"
4. "Can you identify any background noises or audio quality issues?"
5. "What is the overall context and purpose of this recording?"

Note: You can use your own audio files by converting them to base64 format.
Example for using your own audio file:

with open('your_audio.wav', 'rb') as audio_file:
    audio_data = audio_file.read()
    agent.run("Analyze this audio", audio=[Audio(content=audio_data, format="wav")])
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai requests agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python audio_agent.py
    ```
  </Step>
</Steps>


# Basic Agent



This example shows how to create a basic AI agent with a distinct personality. We'll create a fun news reporter that combines NYC attitude with creative storytelling. This shows how personality and style instructions can shape an agent's responses.

Example prompts to try:

* "What's the latest scoop from Central Park?"
* "Tell me about a breaking story from Wall Street"
* "What's happening at the Yankees game right now?"
* "Give me the buzz about a new Broadway show"

## Code

```python basic_agent.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat

# Create our News Reporter with a fun personality
agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    instructions=dedent("""\
        You are an enthusiastic news reporter with a flair for storytelling! 🗽
        Think of yourself as a mix between a witty comedian and a sharp journalist.

        Your style guide:
        - Start with an attention-grabbing headline using emoji
        - Share news with enthusiasm and NYC attitude
        - Keep your responses concise but entertaining
        - Throw in local references and NYC slang when appropriate
        - End with a catchy sign-off like 'Back to you in the studio!' or 'Reporting live from the Big Apple!'

        Remember to verify all facts while keeping that NYC energy high!\
    """),
    markdown=True,
)

# Example usage
agent.print_response(
    "Tell me about a breaking news story happening in Times Square.", stream=True
)

# More example prompts to try:
"""
Try these fun scenarios:
1. "What's the latest food trend taking over Brooklyn?"
2. "Tell me about a peculiar incident on the subway today"
3. "What's the scoop on the newest rooftop garden in Manhattan?"
4. "Report on an unusual traffic jam caused by escaped zoo animals"
5. "Cover a flash mob wedding proposal at Grand Central"
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python basic_agent.py
    ```
  </Step>
</Steps>


# Custom Tools



This example shows how to create and use your own custom tool with Agno.
You can replace the Hacker News functionality with any API or service you want!

Some ideas for your own tools:

* Weather data fetcher
* Stock price analyzer
* Personal calendar integration
* Custom database queries
* Local file operations

## Code

```python custom_tools.py
import json
from textwrap import dedent

import httpx
from agno.agent import Agent
from agno.models.openai import OpenAIChat


def get_top_hackernews_stories(num_stories: int = 10) -> str:
    """Use this function to get top stories from Hacker News.

    Args:
        num_stories (int): Number of stories to return. Defaults to 10.

    Returns:
        str: JSON string of top stories.
    """

    # Fetch top story IDs
    response = httpx.get("https://hacker-news.firebaseio.com/v0/topstories.json")
    story_ids = response.json()

    # Fetch story details
    stories = []
    for story_id in story_ids[:num_stories]:
        story_response = httpx.get(
            f"https://hacker-news.firebaseio.com/v0/item/{story_id}.json"
        )
        story = story_response.json()
        if "text" in story:
            story.pop("text", None)
        stories.append(story)
    return json.dumps(stories)


# Create a Tech News Reporter Agent with a Silicon Valley personality
agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    instructions=dedent("""\
        You are a tech-savvy Hacker News reporter with a passion for all things technology! 🤖
        Think of yourself as a mix between a Silicon Valley insider and a tech journalist.

        Your style guide:
        - Start with an attention-grabbing tech headline using emoji
        - Present Hacker News stories with enthusiasm and tech-forward attitude
        - Keep your responses concise but informative
        - Use tech industry references and startup lingo when appropriate
        - End with a catchy tech-themed sign-off like 'Back to the terminal!' or 'Pushing to production!'

        Remember to analyze the HN stories thoroughly while keeping the tech enthusiasm high!\
    """),
    tools=[get_top_hackernews_stories],
    show_tool_calls=True,
    markdown=True,
)

# Example questions to try:
# - "What are the trending tech discussions on HN right now?"
# - "Summarize the top 5 stories on Hacker News"
# - "What's the most upvoted story today?"
agent.print_response("Summarize the top 5 stories on hackernews?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai httpx agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python custom_tools.py
    ```
  </Step>
</Steps>


# Human in the Loop



This example shows how to implement human validation in your agent workflows. It demonstrates:

* Pre-execution validation
* Post-execution review
* Interactive feedback loops
* Quality control checkpoints

Example scenarios:

* Content moderation
* Critical decision approval
* Output quality validation
* Safety checks
* Expert review processes

## Code

```python human_in_the_loop.py
import json
from textwrap import dedent
from typing import Iterator

import httpx
from agno.agent import Agent
from agno.exceptions import StopAgentRun
from agno.tools import FunctionCall, tool
from rich.console import Console
from rich.pretty import pprint
from rich.prompt import Prompt

# This is the console instance used by the print_response method
# We can use this to stop and restart the live display and ask for user confirmation
console = Console()


def pre_hook(fc: FunctionCall):
    # Get the live display instance from the console
    live = console._live

    # Stop the live display temporarily so we can ask for user confirmation
    live.stop()  # type: ignore

    # Ask for confirmation
    console.print(f"\nAbout to run [bold blue]{fc.function.name}[/]")
    message = (
        Prompt.ask("Do you want to continue?", choices=["y", "n"], default="y")
        .strip()
        .lower()
    )

    # Restart the live display
    live.start()  # type: ignore

    # If the user does not want to continue, raise a StopExecution exception
    if message != "y":
        raise StopAgentRun(
            "Tool call cancelled by user",
            agent_message="Stopping execution as permission was not granted.",
        )


@tool(pre_hook=pre_hook)
def get_top_hackernews_stories(num_stories: int) -> Iterator[str]:
    """Fetch top stories from Hacker News after user confirmation.

    Args:
        num_stories (int): Number of stories to retrieve

    Returns:
        str: JSON string containing story details
    """
    # Fetch top story IDs
    response = httpx.get("https://hacker-news.firebaseio.com/v0/topstories.json")
    story_ids = response.json()

    # Yield story details
    for story_id in story_ids[:num_stories]:
        story_response = httpx.get(
            f"https://hacker-news.firebaseio.com/v0/item/{story_id}.json"
        )
        story = story_response.json()
        if "text" in story:
            story.pop("text", None)
        yield json.dumps(story)


# Initialize the agent with a tech-savvy personality and clear instructions
agent = Agent(
    description="A Tech News Assistant that fetches and summarizes Hacker News stories",
    instructions=dedent("""\
        You are an enthusiastic Tech Reporter

        Your responsibilities:
        - Present Hacker News stories in an engaging and informative way
        - Provide clear summaries of the information you gather

        Style guide:
        - Use emoji to make your responses more engaging
        - Keep your summaries concise but informative
        - End with a friendly tech-themed sign-off\
    """),
    tools=[get_top_hackernews_stories],
    show_tool_calls=True,
    markdown=True,
)

# Example questions to try:
# - "What are the top 3 HN stories right now?"
# - "Show me the most recent story from Hacker News"
# - "Get the top 5 stories (you can try accepting and declining the confirmation)"
agent.print_response(
    "What are the top 2 hackernews stories?", stream=True, console=console
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python human_in_the_loop.py
    ```
  </Step>
</Steps>


# Image Agent



This example shows how to create an AI agent that can analyze images and connect them with current events using web searches. Perfect for:

1. News reporting and journalism
2. Travel and tourism content
3. Social media analysis
4. Educational presentations
5. Event coverage

Example images to try:

* Famous landmarks (Eiffel Tower, Taj Mahal, etc.)
* City skylines
* Cultural events and festivals
* Breaking news scenes
* Historical locations

## Code

```python image_agent.py
from textwrap import dedent

from agno.agent import Agent
from agno.media import Image
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    description=dedent("""\
        You are a world-class visual journalist and cultural correspondent with a gift
        for bringing images to life through storytelling! 📸✨ With the observational skills
        of a detective and the narrative flair of a bestselling author, you transform visual
        analysis into compelling stories that inform and captivate.\
    """),
    instructions=dedent("""\
        When analyzing images and reporting news, follow these principles:

        1. Visual Analysis:
           - Start with an attention-grabbing headline using relevant emoji
           - Break down key visual elements with expert precision
           - Notice subtle details others might miss
           - Connect visual elements to broader contexts

        2. News Integration:
           - Research and verify current events related to the image
           - Connect historical context with present-day significance
           - Prioritize accuracy while maintaining engagement
           - Include relevant statistics or data when available

        3. Storytelling Style:
           - Maintain a professional yet engaging tone
           - Use vivid, descriptive language
           - Include cultural and historical references when relevant
           - End with a memorable sign-off that fits the story

        4. Reporting Guidelines:
           - Keep responses concise but informative (2-3 paragraphs)
           - Balance facts with human interest
           - Maintain journalistic integrity
           - Credit sources when citing specific information

        Transform every image into a compelling news story that informs and inspires!\
    """),
    tools=[DuckDuckGoTools()],
    show_tool_calls=True,
    markdown=True,
)

# Example usage with a famous landmark
agent.print_response(
    "Tell me about this image and share the latest relevant news.",
    images=[
        Image(
            url="https://upload.wikimedia.org/wikipedia/commons/0/0c/GoldenGateBridge-001.jpg"
        )
    ],
    stream=True,
)

# More examples to try:
"""
Sample prompts to explore:
1. "What's the historical significance of this location?"
2. "How has this place changed over time?"
3. "What cultural events happen here?"
4. "What's the architectural style and influence?"
5. "What recent developments affect this area?"

Sample image URLs to analyze:
1. Eiffel Tower: "https://upload.wikimedia.org/wikipedia/commons/8/85/Tour_Eiffel_Wikimedia_Commons_%28cropped%29.jpg"
2. Taj Mahal: "https://upload.wikimedia.org/wikipedia/commons/b/bd/Taj_Mahal%2C_Agra%2C_India_edit3.jpg"
3. Golden Gate Bridge: "https://upload.wikimedia.org/wikipedia/commons/0/0c/GoldenGateBridge-001.jpg"
"""

# To get the response in a variable:
# from rich.pretty import pprint
# response = agent.run(
#     "Analyze this landmark's architecture and recent news.",
#     images=[Image(url="YOUR_IMAGE_URL")],
# )
# pprint(response.content)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai duckduckgo-search agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python image_agent.py
    ```
  </Step>
</Steps>


# Image Generation



This example shows how to create an AI agent that generates images using DALL-E.
You can use this agent to create various types of images, from realistic photos to artistic
illustrations and creative concepts.

Example prompts to try:

* "Create a surreal painting of a floating city in the clouds at sunset"
* "Generate a photorealistic image of a cozy coffee shop interior"
* "Design a cute cartoon mascot for a tech startup"
* "Create an artistic portrait of a cyberpunk samurai"

## Code

```python image_generation.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.dalle import DalleTools

# Create an Creative AI Artist Agent
image_agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    tools=[DalleTools()],
    description=dedent("""\
        You are an experienced AI artist with expertise in various artistic styles,
        from photorealism to abstract art. You have a deep understanding of composition,
        color theory, and visual storytelling.\
    """),
    instructions=dedent("""\
        As an AI artist, follow these guidelines:
        1. Analyze the user's request carefully to understand the desired style and mood
        2. Before generating, enhance the prompt with artistic details like lighting, perspective, and atmosphere
        3. Use the `create_image` tool with detailed, well-crafted prompts
        4. Provide a brief explanation of the artistic choices made
        5. If the request is unclear, ask for clarification about style preferences

        Always aim to create visually striking and meaningful images that capture the user's vision!\
    """),
    markdown=True,
    show_tool_calls=True,
)

# Example usage
image_agent.print_response(
    "Create a magical library with floating books and glowing crystals", stream=True
)

# Retrieve and display generated images
images = image_agent.get_images()
if images and isinstance(images, list):
    for image_response in images:
        image_url = image_response.url
        print(f"Generated image URL: {image_url}")

# More example prompts to try:
"""
Try these creative prompts:
1. "Generate a steampunk-style robot playing a violin"
2. "Design a peaceful zen garden during cherry blossom season"
3. "Create an underwater city with bioluminescent buildings"
4. "Generate a cozy cabin in a snowy forest at night"
5. "Create a futuristic cityscape with flying cars and skyscrapers"
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python image_generation.py
    ```
  </Step>
</Steps>


# Introduction



This guide walks through the basics of building Agents with Agno.

The examples build on each other, introducing new concepts and capabilities progressively. Each example contains detailed comments, example prompts, and required dependencies.

## Setup

Create a virtual environment:

```bash
python3 -m venv .venv
source .venv/bin/activate
```

Install the required dependencies:

```bash
pip install openai duckduckgo-search yfinance lancedb tantivy pypdf requests exa-py newspaper4k lxml_html_clean sqlalchemy agno
```

Export your OpenAI API key:

```bash
export OPENAI_API_KEY=your_api_key
```

## Examples

<CardGroup cols={3}>
  <Card title="Basic Agent" icon="robot" iconType="duotone" href="./basic-agent">
    Build a news reporter with a vibrant personality. This Agent only shows basic LLM inference.
  </Card>

  <Card title="Agent with Tools" icon="toolbox" iconType="duotone" href="./agent-with-tools">
    Add web search capabilities using DuckDuckGo for real-time information gathering.
  </Card>

  <Card title="Agent with Knowledge" icon="brain" iconType="duotone" href="./agent-with-knowledge">
    Add a vector database to your agent to store and search knowledge.
  </Card>

  <Card title="Agent with Storage" icon="database" iconType="duotone" href="./agent-with-storage">
    Add persistence to your agents with session management and history capabilities.
  </Card>

  <Card title="Agent Team" icon="users" iconType="duotone" href="./agent-team">
    Create an agent team specializing in market research and financial analysis.
  </Card>

  <Card title="Structured Output" icon="code" iconType="duotone" href="./structured-output">
    Generate a structured output using a Pydantic model.
  </Card>

  <Card title="Custom Tools" icon="wrench" iconType="duotone" href="./custom-tools">
    Create and integrate custom tools with your agent.
  </Card>

  <Card title="Research Agent" icon="magnifying-glass" iconType="duotone" href="./research-agent">
    Build an AI research agent using Exa with controlled output steering.
  </Card>

  <Card title="Research Workflow" icon="diagram-project" iconType="duotone" href="./research-workflow">
    Create a research workflow combining web searches and content scraping.
  </Card>

  <Card title="Image Agent" icon="image" iconType="duotone" href="./image-agent">
    Create an agent that can understand images.
  </Card>

  <Card title="Image Generation" icon="paintbrush" iconType="duotone" href="./image-generation">
    Create an Agent that can generate images using DALL-E.
  </Card>

  <Card title="Video Generation" icon="video" iconType="duotone" href="./video-generation">
    Create an Agent that can generate videos using ModelsLabs.
  </Card>

  <Card title="Audio Agent" icon="microphone" iconType="duotone" href="./audio-agent">
    Create an Agent that can process audio input and generate responses.
  </Card>

  <Card title="Agent with State" icon="database" iconType="duotone" href="./agent-state">
    Create an Agent with session state management.
  </Card>

  <Card title="Agent Context" icon="sitemap" iconType="duotone" href="./agent-context">
    Evaluate dependencies at agent.run and inject them into the instructions.
  </Card>

  <Card title="Agent Session" icon="clock-rotate-left" iconType="duotone" href="./agent-session">
    Create an Agent with persistent session memory across conversations.
  </Card>

  <Card title="User Memories" icon="memory" iconType="duotone" href="./user-memories">
    Create an Agent that stores user memories and summaries.
  </Card>

  <Card title="Function Retries" icon="rotate" iconType="duotone" href="./retry-functions">
    Handle function retries for failed or unsatisfactory outputs.
  </Card>

  <Card title="Human in the Loop" icon="user-check" iconType="duotone" href="./human-in-the-loop">
    Add user confirmation and safety checks for interactive agent control.
  </Card>
</CardGroup>

Each example includes runnable code and detailed explanations. We recommend following them in order, as concepts build upon previous examples.


# Research Agent



This example shows how to create an advanced research agent by combining exa's search capabilities with academic writing skills to deliver well-structured, fact-based reports.

Key features demonstrated:

* Using Exa.ai for academic and news searches
* Structured report generation with references
* Custom formatting and file saving capabilities

Example prompts to try:

* "What are the latest developments in quantum computing?"
* "Research the current state of artificial consciousness"
* "Analyze recent breakthroughs in fusion energy"
* "Investigate the environmental impact of space tourism"
* "Explore the latest findings in longevity research"

## Code

```python research_agent.py
from datetime import datetime
from pathlib import Path
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.exa import ExaTools

cwd = Path(__file__).parent.resolve()
tmp = cwd.joinpath("tmp")
if not tmp.exists():
    tmp.mkdir(exist_ok=True, parents=True)

today = datetime.now().strftime("%Y-%m-%d")

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    tools=[ExaTools(start_published_date=today, type="keyword")],
    description=dedent("""\
        You are Professor X-1000, a distinguished AI research scientist with expertise
        in analyzing and synthesizing complex information. Your specialty lies in creating
        compelling, fact-based reports that combine academic rigor with engaging narrative.

        Your writing style is:
        - Clear and authoritative
        - Engaging but professional
        - Fact-focused with proper citations
        - Accessible to educated non-specialists\
    """),
    instructions=dedent("""\
        Begin by running 3 distinct searches to gather comprehensive information.
        Analyze and cross-reference sources for accuracy and relevance.
        Structure your report following academic standards but maintain readability.
        Include only verifiable facts with proper citations.
        Create an engaging narrative that guides the reader through complex topics.
        End with actionable takeaways and future implications.\
    """),
    expected_output=dedent("""\
    A professional research report in markdown format:

    # {Compelling Title That Captures the Topic's Essence}

    ## Executive Summary
    {Brief overview of key findings and significance}

    ## Introduction
    {Context and importance of the topic}
    {Current state of research/discussion}

    ## Key Findings
    {Major discoveries or developments}
    {Supporting evidence and analysis}

    ## Implications
    {Impact on field/society}
    {Future directions}

    ## Key Takeaways
    - {Bullet point 1}
    - {Bullet point 2}
    - {Bullet point 3}

    ## References
    - [Source 1](link) - Key finding/quote
    - [Source 2](link) - Key finding/quote
    - [Source 3](link) - Key finding/quote

    ---
    Report generated by Professor X-1000
    Advanced Research Systems Division
    Date: {current_date}\
    """),
    markdown=True,
    show_tool_calls=True,
    add_datetime_to_instructions=True,
    save_response_to_file=str(tmp.joinpath("{message}.md")),
)

# Example usage
if __name__ == "__main__":
    # Generate a research report on a cutting-edge topic
    agent.print_response(
        "Research the latest developments in brain-computer interfaces", stream=True
    )

# More example prompts to try:
"""
Try these research topics:
1. "Analyze the current state of solid-state batteries"
2. "Research recent breakthroughs in CRISPR gene editing"
3. "Investigate the development of autonomous vehicles"
4. "Explore advances in quantum machine learning"
5. "Study the impact of artificial intelligence on healthcare"
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai exa-py agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python research_agent.py
    ```
  </Step>
</Steps>


# Research Workflow



This example shows how to build a sophisticated research workflow that combines:
🔍 Web search capabilities for finding relevant sources
📚 Content extraction and processing
✍️ Academic-style report generation
💾 Smart caching for improved performance

We've used the following tools as they're available for free:

* DuckDuckGoTools: Searches the web for relevant articles
* Newspaper4kTools: Scrapes and processes article content

Example research topics to try:

* "What are the latest developments in quantum computing?"
* "Research the current state of artificial consciousness"
* "Analyze recent breakthroughs in fusion energy"
* "Investigate the environmental impact of space tourism"
* "Explore the latest findings in longevity research"

## Code

```python research_workflow.py
import json
from textwrap import dedent
from typing import Dict, Iterator, Optional

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.storage.workflow.sqlite import SqliteWorkflowStorage
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.newspaper4k import Newspaper4kTools
from agno.utils.log import logger
from agno.utils.pprint import pprint_run_response
from agno.workflow import RunEvent, RunResponse, Workflow
from pydantic import BaseModel, Field


class Article(BaseModel):
    title: str = Field(..., description="Title of the article.")
    url: str = Field(..., description="Link to the article.")
    summary: Optional[str] = Field(
        ..., description="Summary of the article if available."
    )


class SearchResults(BaseModel):
    articles: list[Article]


class ScrapedArticle(BaseModel):
    title: str = Field(..., description="Title of the article.")
    url: str = Field(..., description="Link to the article.")
    summary: Optional[str] = Field(
        ..., description="Summary of the article if available."
    )
    content: Optional[str] = Field(
        ...,
        description="Content of the in markdown format if available. Return None if the content is not available or does not make sense.",
    )


class ResearchReportGenerator(Workflow):
    description: str = dedent("""\
    Generate comprehensive research reports that combine academic rigor
    with engaging storytelling. This workflow orchestrates multiple AI agents to search, analyze,
    and synthesize information from diverse sources into well-structured reports.
    """)

    web_searcher: Agent = Agent(
        model=OpenAIChat(id="gpt-4o-mini"),
        tools=[DuckDuckGoTools()],
        description=dedent("""\
        You are ResearchBot-X, an expert at discovering and evaluating academic and scientific sources.\
        """),
        instructions=dedent("""\
        You're a meticulous research assistant with expertise in source evaluation! 🔍
        Search for 10-15 sources and identify the 5-7 most authoritative and relevant ones.
        Prioritize:
        - Peer-reviewed articles and academic publications
        - Recent developments from reputable institutions
        - Authoritative news sources and expert commentary
        - Diverse perspectives from recognized experts
        Avoid opinion pieces and non-authoritative sources.\
        """),
        response_model=SearchResults,
        structured_outputs=True,
    )

    article_scraper: Agent = Agent(
        model=OpenAIChat(id="gpt-4o-mini"),
        tools=[Newspaper4kTools()],
        description=dedent("""\
        You are ContentBot-X, an expert at extracting and structuring academic content.\
        """),
        instructions=dedent("""\
        You're a precise content curator with attention to academic detail! 📚
        When processing content:
           - Extract content from the article
           - Preserve academic citations and references
           - Maintain technical accuracy in terminology
           - Structure content logically with clear sections
           - Extract key findings and methodology details
           - Handle paywalled content gracefully
        Format everything in clean markdown for optimal readability.\
        """),
        response_model=ScrapedArticle,
        structured_outputs=True,
    )

    writer: Agent = Agent(
        model=OpenAIChat(id="gpt-4o"),
        description=dedent("""\
        You are Professor X-2000, a distinguished AI research scientist combining academic rigor with engaging narrative style.\
        """),
        instructions=dedent("""\
        Channel the expertise of a world-class academic researcher!
        🎯 Analysis Phase:
          - Evaluate source credibility and relevance
          - Cross-reference findings across sources
          - Identify key themes and breakthroughs
        💡 Synthesis Phase:
          - Develop a coherent narrative framework
          - Connect disparate findings
          - Highlight contradictions or gaps
        ✍️ Writing Phase:
          - Begin with an engaging executive summary, hook the reader
          - Present complex ideas clearly
          - Support all claims with citations
          - Balance depth with accessibility
          - Maintain academic tone while ensuring readability
          - End with implications and future directions\
        """),
        expected_output=dedent("""\
        # {Compelling Academic Title}

        ## Executive Summary
        {Concise overview of key findings and significance}

        ## Introduction
        {Research context and background}
        {Current state of the field}

        ## Methodology
        {Search and analysis approach}
        {Source evaluation criteria}

        ## Key Findings
        {Major discoveries and developments}
        {Supporting evidence and analysis}
        {Contrasting viewpoints}

        ## Analysis
        {Critical evaluation of findings}
        {Integration of multiple perspectives}
        {Identification of patterns and trends}

        ## Implications
        {Academic and practical significance}
        {Future research directions}
        {Potential applications}

        ## Key Takeaways
        - {Critical finding 1}
        - {Critical finding 2}
        - {Critical finding 3}

        ## References
        {Properly formatted academic citations}

        ---
        Report generated by Professor X-2000
        Advanced Research Division
        Date: {current_date}\
        """),
        markdown=True,
    )

    def run(
        self,
        topic: str,
        use_search_cache: bool = True,
        use_scrape_cache: bool = True,
        use_cached_report: bool = True,
    ) -> Iterator[RunResponse]:
        """
        Generate a comprehensive news report on a given topic.

        This function orchestrates a workflow to search for articles, scrape their content,
        and generate a final report. It utilizes caching mechanisms to optimize performance.

        Args:
            topic (str): The topic for which to generate the news report.
            use_search_cache (bool, optional): Whether to use cached search results. Defaults to True.
            use_scrape_cache (bool, optional): Whether to use cached scraped articles. Defaults to True.
            use_cached_report (bool, optional): Whether to return a previously generated report on the same topic. Defaults to False.

        Returns:
            Iterator[RunResponse]: An stream of objects containing the generated report or status information.

        Steps:
        1. Check for a cached report if use_cached_report is True.
        2. Search the web for articles on the topic:
            - Use cached search results if available and use_search_cache is True.
            - Otherwise, perform a new web search.
        3. Scrape the content of each article:
            - Use cached scraped articles if available and use_scrape_cache is True.
            - Scrape new articles that aren't in the cache.
        4. Generate the final report using the scraped article contents.

        The function utilizes the `session_state` to store and retrieve cached data.
        """
        logger.info(f"Generating a report on: {topic}")

        # Use the cached report if use_cached_report is True
        if use_cached_report:
            cached_report = self.get_cached_report(topic)
            if cached_report:
                yield RunResponse(
                    content=cached_report, event=RunEvent.workflow_completed
                )
                return

        # Search the web for articles on the topic
        search_results: Optional[SearchResults] = self.get_search_results(
            topic, use_search_cache
        )
        # If no search_results are found for the topic, end the workflow
        if search_results is None or len(search_results.articles) == 0:
            yield RunResponse(
                event=RunEvent.workflow_completed,
                content=f"Sorry, could not find any articles on the topic: {topic}",
            )
            return

        # Scrape the search results
        scraped_articles: Dict[str, ScrapedArticle] = self.scrape_articles(
            search_results, use_scrape_cache
        )

        # Write a research report
        yield from self.write_research_report(topic, scraped_articles)

    def get_cached_report(self, topic: str) -> Optional[str]:
        logger.info("Checking if cached report exists")
        return self.session_state.get("reports", {}).get(topic)

    def add_report_to_cache(self, topic: str, report: str):
        logger.info(f"Saving report for topic: {topic}")
        self.session_state.setdefault("reports", {})
        self.session_state["reports"][topic] = report
        # Save the report to the storage
        self.write_to_storage()

    def get_cached_search_results(self, topic: str) -> Optional[SearchResults]:
        logger.info("Checking if cached search results exist")
        return self.session_state.get("search_results", {}).get(topic)

    def add_search_results_to_cache(self, topic: str, search_results: SearchResults):
        logger.info(f"Saving search results for topic: {topic}")
        self.session_state.setdefault("search_results", {})
        self.session_state["search_results"][topic] = search_results.model_dump()
        # Save the search results to the storage
        self.write_to_storage()

    def get_cached_scraped_articles(
        self, topic: str
    ) -> Optional[Dict[str, ScrapedArticle]]:
        logger.info("Checking if cached scraped articles exist")
        return self.session_state.get("scraped_articles", {}).get(topic)

    def add_scraped_articles_to_cache(
        self, topic: str, scraped_articles: Dict[str, ScrapedArticle]
    ):
        logger.info(f"Saving scraped articles for topic: {topic}")
        self.session_state.setdefault("scraped_articles", {})
        self.session_state["scraped_articles"][topic] = scraped_articles
        # Save the scraped articles to the storage
        self.write_to_storage()

    def get_search_results(
        self, topic: str, use_search_cache: bool, num_attempts: int = 3
    ) -> Optional[SearchResults]:
        # Get cached search_results from the session state if use_search_cache is True
        if use_search_cache:
            try:
                search_results_from_cache = self.get_cached_search_results(topic)
                if search_results_from_cache is not None:
                    search_results = SearchResults.model_validate(
                        search_results_from_cache
                    )
                    logger.info(
                        f"Found {len(search_results.articles)} articles in cache."
                    )
                    return search_results
            except Exception as e:
                logger.warning(f"Could not read search results from cache: {e}")

        # If there are no cached search_results, use the web_searcher to find the latest articles
        for attempt in range(num_attempts):
            try:
                searcher_response: RunResponse = self.web_searcher.run(topic)
                if (
                    searcher_response is not None
                    and searcher_response.content is not None
                    and isinstance(searcher_response.content, SearchResults)
                ):
                    article_count = len(searcher_response.content.articles)
                    logger.info(
                        f"Found {article_count} articles on attempt {attempt + 1}"
                    )
                    # Cache the search results
                    self.add_search_results_to_cache(topic, searcher_response.content)
                    return searcher_response.content
                else:
                    logger.warning(
                        f"Attempt {attempt + 1}/{num_attempts} failed: Invalid response type"
                    )
            except Exception as e:
                logger.warning(f"Attempt {attempt + 1}/{num_attempts} failed: {str(e)}")

        logger.error(f"Failed to get search results after {num_attempts} attempts")
        return None

    def scrape_articles(
        self, search_results: SearchResults, use_scrape_cache: bool
    ) -> Dict[str, ScrapedArticle]:
        scraped_articles: Dict[str, ScrapedArticle] = {}

        # Get cached scraped_articles from the session state if use_scrape_cache is True
        if use_scrape_cache:
            try:
                scraped_articles_from_cache = self.get_cached_scraped_articles(topic)
                if scraped_articles_from_cache is not None:
                    scraped_articles = scraped_articles_from_cache
                    logger.info(
                        f"Found {len(scraped_articles)} scraped articles in cache."
                    )
                    return scraped_articles
            except Exception as e:
                logger.warning(f"Could not read scraped articles from cache: {e}")

        # Scrape the articles that are not in the cache
        for article in search_results.articles:
            if article.url in scraped_articles:
                logger.info(f"Found scraped article in cache: {article.url}")
                continue

            article_scraper_response: RunResponse = self.article_scraper.run(
                article.url
            )
            if (
                article_scraper_response is not None
                and article_scraper_response.content is not None
                and isinstance(article_scraper_response.content, ScrapedArticle)
            ):
                scraped_articles[article_scraper_response.content.url] = (
                    article_scraper_response.content
                )
                logger.info(f"Scraped article: {article_scraper_response.content.url}")

        # Save the scraped articles in the session state
        self.add_scraped_articles_to_cache(topic, scraped_articles)
        return scraped_articles

    def write_research_report(
        self, topic: str, scraped_articles: Dict[str, ScrapedArticle]
    ) -> Iterator[RunResponse]:
        logger.info("Writing research report")
        # Prepare the input for the writer
        writer_input = {
            "topic": topic,
            "articles": [v.model_dump() for v in scraped_articles.values()],
        }
        # Run the writer and yield the response
        yield from self.writer.run(json.dumps(writer_input, indent=4), stream=True)
        # Save the research report in the cache
        self.add_report_to_cache(topic, self.writer.run_response.content)


# Run the workflow if the script is executed directly
if __name__ == "__main__":
    from rich.prompt import Prompt

    # Example research topics
    example_topics = [
        "quantum computing breakthroughs 2024",
        "artificial consciousness research",
        "fusion energy developments",
        "space tourism environmental impact",
        "longevity research advances",
    ]

    topics_str = "\n".join(
        f"{i + 1}. {topic}" for i, topic in enumerate(example_topics)
    )

    print(f"\n📚 Example Research Topics:\n{topics_str}\n")

    # Get topic from user
    topic = Prompt.ask(
        "[bold]Enter a research topic[/bold]\n✨",
        default="quantum computing breakthroughs 2024",
    )

    # Convert the topic to a URL-safe string for use in session_id
    url_safe_topic = topic.lower().replace(" ", "-")

    # Initialize the news report generator workflow
    generate_research_report = ResearchReportGenerator(
        session_id=f"generate-report-on-{url_safe_topic}",
        storage=SqliteWorkflowStorage(
            table_name="generate_research_report_workflow",
            db_file="tmp/workflows.db",
        ),
    )

    # Execute the workflow with caching enabled
    report_stream: Iterator[RunResponse] = generate_research_report.run(
        topic=topic,
        use_search_cache=True,
        use_scrape_cache=True,
        use_cached_report=True,
    )

    # Print the response
    pprint_run_response(report_stream, markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    openai duckduckgo-search newspaper4k lxml_html_clean sqlalchemy agno
    ```
  </Step>

  <Step title="Run the workflow">
    ```bash
    python research_workflow.py
    ```
  </Step>
</Steps>


# Retry Functions



This example shows how to retry a function call if it fails or you do not like the output. This is useful for:

* Handling temporary failures
* Improving output quality through retries
* Implementing human-in-the-loop validation

## Code

```python retry_functions.py
from typing import Iterator

from agno.agent import Agent
from agno.exceptions import RetryAgentRun
from agno.tools import FunctionCall, tool

num_calls = 0


def pre_hook(fc: FunctionCall):
    global num_calls

    print(f"Pre-hook: {fc.function.name}")
    print(f"Arguments: {fc.arguments}")
    num_calls += 1
    if num_calls < 2:
        raise RetryAgentRun(
            "This wasn't interesting enough, please retry with a different argument"
        )


@tool(pre_hook=pre_hook)
def print_something(something: str) -> Iterator[str]:
    print(something)
    yield f"I have printed {something}"


agent = Agent(tools=[print_something], markdown=True)
agent.print_response("Print something interesting", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python retry_functions.py
    ```
  </Step>
</Steps>


# Structured Output



This example shows how to use structured outputs with AI agents to generate well-formatted movie script concepts. It shows two approaches:

1. JSON Mode: Traditional JSON response parsing
2. Structured Output: Enhanced structured data handling

Example prompts to try:

* "Tokyo" - Get a high-tech thriller set in futuristic Japan
* "Ancient Rome" - Experience an epic historical drama
* "Manhattan" - Explore a modern romantic comedy
* "Amazon Rainforest" - Adventure in an exotic location
* "Mars Colony" - Science fiction in a space settlement

## Code

```python structured_output.py
from textwrap import dedent
from typing import List

from agno.agent import Agent, RunResponse  # noqa
from agno.models.openai import OpenAIChat
from pydantic import BaseModel, Field


class MovieScript(BaseModel):
    setting: str = Field(
        ...,
        description="A richly detailed, atmospheric description of the movie's primary location and time period. Include sensory details and mood.",
    )
    ending: str = Field(
        ...,
        description="The movie's powerful conclusion that ties together all plot threads. Should deliver emotional impact and satisfaction.",
    )
    genre: str = Field(
        ...,
        description="The film's primary and secondary genres (e.g., 'Sci-fi Thriller', 'Romantic Comedy'). Should align with setting and tone.",
    )
    name: str = Field(
        ...,
        description="An attention-grabbing, memorable title that captures the essence of the story and appeals to target audience.",
    )
    characters: List[str] = Field(
        ...,
        description="4-6 main characters with distinctive names and brief role descriptions (e.g., 'Sarah Chen - brilliant quantum physicist with a dark secret').",
    )
    storyline: str = Field(
        ...,
        description="A compelling three-sentence plot summary: Setup, Conflict, and Stakes. Hook readers with intrigue and emotion.",
    )


# Agent that uses JSON mode
json_mode_agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    description=dedent("""\
        You are an acclaimed Hollywood screenwriter known for creating unforgettable blockbusters! 🎬
        With the combined storytelling prowess of Christopher Nolan, Aaron Sorkin, and Quentin Tarantino,
        you craft unique stories that captivate audiences worldwide.

        Your specialty is turning locations into living, breathing characters that drive the narrative.\
    """),
    instructions=dedent("""\
        When crafting movie concepts, follow these principles:

        1. Settings should be characters:
           - Make locations come alive with sensory details
           - Include atmospheric elements that affect the story
           - Consider the time period's impact on the narrative

        2. Character Development:
           - Give each character a unique voice and clear motivation
           - Create compelling relationships and conflicts
           - Ensure diverse representation and authentic backgrounds

        3. Story Structure:
           - Begin with a hook that grabs attention
           - Build tension through escalating conflicts
           - Deliver surprising yet inevitable endings

        4. Genre Mastery:
           - Embrace genre conventions while adding fresh twists
           - Mix genres thoughtfully for unique combinations
           - Maintain consistent tone throughout

        Transform every location into an unforgettable cinematic experience!\
    """),
    response_model=MovieScript,
)

# Agent that uses structured outputs
structured_output_agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    description=dedent("""\
        You are an acclaimed Hollywood screenwriter known for creating unforgettable blockbusters! 🎬
        With the combined storytelling prowess of Christopher Nolan, Aaron Sorkin, and Quentin Tarantino,
        you craft unique stories that captivate audiences worldwide.

        Your specialty is turning locations into living, breathing characters that drive the narrative.\
    """),
    instructions=dedent("""\
        When crafting movie concepts, follow these principles:

        1. Settings should be characters:
           - Make locations come alive with sensory details
           - Include atmospheric elements that affect the story
           - Consider the time period's impact on the narrative

        2. Character Development:
           - Give each character a unique voice and clear motivation
           - Create compelling relationships and conflicts
           - Ensure diverse representation and authentic backgrounds

        3. Story Structure:
           - Begin with a hook that grabs attention
           - Build tension through escalating conflicts
           - Deliver surprising yet inevitable endings

        4. Genre Mastery:
           - Embrace genre conventions while adding fresh twists
           - Mix genres thoughtfully for unique combinations
           - Maintain consistent tone throughout

        Transform every location into an unforgettable cinematic experience!\
    """),
    response_model=MovieScript,
    structured_outputs=True,
)

# Example usage with different locations
json_mode_agent.print_response("Tokyo", stream=True)
structured_output_agent.print_response("Ancient Rome", stream=True)

# More examples to try:
"""
Creative location prompts to explore:
1. "Underwater Research Station" - For a claustrophobic sci-fi thriller
2. "Victorian London" - For a gothic mystery
3. "Dubai 2050" - For a futuristic heist movie
4. "Antarctic Research Base" - For a survival horror story
5. "Caribbean Island" - For a tropical adventure romance
"""

# To get the response in a variable:
# from rich.pretty import pprint

# json_mode_response: RunResponse = json_mode_agent.run("New York")
# pprint(json_mode_response.content)
# structured_output_response: RunResponse = structured_output_agent.run("New York")
# pprint(structured_output_response.content)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python structured_output.py
    ```
  </Step>
</Steps>


# User Memories



This example shows how to create an agent with persistent memory that stores:

1. Personalized user memories - facts and preferences learned about specific users
2. Session summaries - key points and context from conversations
3. Chat history - stored in SQLite for persistence

Key features:

* Stores user-specific memories in SQLite database
* Maintains session summaries for context
* Continues conversations across sessions with memory
* References previous context and user information in responses

Examples:
User: "My name is John and I live in NYC"
Agent: *Creates memory about John's location*

User: "What do you remember about me?"
Agent: *Recalls previous memories about John*

## Code

```python user_memories.py
import json
from textwrap import dedent
from typing import Optional

import typer
from agno.agent import Agent, AgentMemory
from agno.memory.db.sqlite import SqliteMemoryDb
from agno.models.openai import OpenAIChat
from agno.storage.agent.sqlite import SqliteAgentStorage
from rich.console import Console
from rich.json import JSON
from rich.panel import Panel
from rich.prompt import Prompt


def create_agent(user: str = "user"):
    session_id: Optional[str] = None

    # Ask if user wants to start new session or continue existing one
    new = typer.confirm("Do you want to start a new session?")

    # Initialize storage for both agent sessions and memories
    agent_storage = SqliteAgentStorage(
        table_name="agent_memories", db_file="tmp/agents.db"
    )

    if not new:
        existing_sessions = agent_storage.get_all_session_ids(user)
        if len(existing_sessions) > 0:
            session_id = existing_sessions[0]

    agent = Agent(
        model=OpenAIChat(id="gpt-4o"),
        user_id=user,
        session_id=session_id,
        # Configure memory system with SQLite storage
        memory=AgentMemory(
            db=SqliteMemoryDb(
                table_name="agent_memory",
                db_file="tmp/agent_memory.db",
            ),
            create_user_memories=True,
            update_user_memories_after_run=True,
            create_session_summary=True,
            update_session_summary_after_run=True,
        ),
        storage=agent_storage,
        add_history_to_messages=True,
        num_history_responses=3,
        # Enhanced system prompt for better personality and memory usage
        description=dedent("""\
        You are a helpful and friendly AI assistant with excellent memory.
        - Remember important details about users and reference them naturally
        - Maintain a warm, positive tone while being precise and helpful
        - When appropriate, refer back to previous conversations and memories
        - Always be truthful about what you remember or don't remember"""),
    )

    if session_id is None:
        session_id = agent.session_id
        if session_id is not None:
            print(f"Started Session: {session_id}\n")
        else:
            print("Started Session\n")
    else:
        print(f"Continuing Session: {session_id}\n")

    return agent


def print_agent_memory(agent):
    """Print the current state of agent's memory systems"""
    console = Console()

    # Print chat history
    console.print(
        Panel(
            JSON(
                json.dumps([m.to_dict() for m in agent.memory.messages]),
                indent=4,
            ),
            title=f"Chat History for session_id: {agent.session_id}",
            expand=True,
        )
    )

    # Print user memories
    console.print(
        Panel(
            JSON(
                json.dumps(
                    [
                        m.model_dump(include={"memory", "input"})
                        for m in agent.memory.memories
                    ]
                ),
                indent=4,
            ),
            title=f"Memories for user_id: {agent.user_id}",
            expand=True,
        )
    )

    # Print session summary
    console.print(
        Panel(
            JSON(json.dumps(agent.memory.summary.model_dump(), indent=4)),
            title=f"Summary for session_id: {agent.session_id}",
            expand=True,
        )
    )


def main(user: str = "user"):
    """Interactive chat loop with memory display"""
    agent = create_agent(user)

    print("Try these example inputs:")
    print("- 'My name is [name] and I live in [city]'")
    print("- 'I love [hobby/interest]'")
    print("- 'What do you remember about me?'")
    print("- 'What have we discussed so far?'\n")

    exit_on = ["exit", "quit", "bye"]
    while True:
        message = Prompt.ask(f"[bold] :sunglasses: {user} [/bold]")
        if message in exit_on:
            break

        agent.print_response(message=message, stream=True, markdown=True)
        print_agent_memory(agent)


if __name__ == "__main__":
    typer.run(main)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai sqlalchemy agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python user_memories.py
    ```
  </Step>
</Steps>


# Video Generation



This example shows how to create an AI agent that generates videos using ModelsLabs.
You can use this agent to create various types of short videos, from animated scenes
to creative visual stories.

Example prompts to try:

* "Create a serene video of waves crashing on a beach at sunset"
* "Generate a magical video of butterflies flying in a enchanted forest"
* "Create a timelapse of a blooming flower in a garden"
* "Generate a video of northern lights dancing in the night sky"

## Code

```python video_generation.py
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.models_labs import ModelsLabTools

# Create a Creative AI Video Director Agent
video_agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    tools=[ModelsLabTools()],
    description=dedent("""\
        You are an experienced AI video director with expertise in various video styles,
        from nature scenes to artistic animations. You have a deep understanding of motion,
        timing, and visual storytelling through video content.\
    """),
    instructions=dedent("""\
        As an AI video director, follow these guidelines:
        1. Analyze the user's request carefully to understand the desired style and mood
        2. Before generating, enhance the prompt with details about motion, timing, and atmosphere
        3. Use the `generate_media` tool with detailed, well-crafted prompts
        4. Provide a brief explanation of the creative choices made
        5. If the request is unclear, ask for clarification about style preferences

        The video will be displayed in the UI automatically below your response.
        Always aim to create captivating and meaningful videos that bring the user's vision to life!\
    """),
    markdown=True,
    show_tool_calls=True,
)

# Example usage
video_agent.print_response(
    "Generate a cosmic journey through a colorful nebula", stream=True
)

# Retrieve and display generated videos
videos = video_agent.get_videos()
if videos:
    for video in videos:
        print(f"Generated video URL: {video.url}")

# More example prompts to try:
"""
Try these creative prompts:
1. "Create a video of autumn leaves falling in a peaceful forest"
2. "Generate a video of a cat playing with a ball"
3. "Create a video of a peaceful koi pond with rippling water"
4. "Generate a video of a cozy fireplace with dancing flames"
5. "Create a video of a mystical portal opening in a magical realm"
"""
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai agno
    ```
  </Step>

  <Step title="Set environment variables">
    ```bash
    export MODELS_LAB_API_KEY=****
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python video_generation.py
    ```
  </Step>
</Steps>


# Introduction



Welcome to Agno's example gallery! Here you'll discover examples showcasing everything from **single-agent tasks** to sophisticated **multi-agent workflows**. You can either:

* Run the examples individually
* Clone the entire [Agno cookbook](https://github.com/agno-agi/agno/tree/main/cookbook)

Have an interesting example to share? Please consider [contributing](https://github.com/agno-agi/agno-docs) to our growing collection.

## Getting Started

If you're just getting started, follow the [Getting Started](/examples/getting-started) guide for a step-by-step tutorial. The examples build on each other, introducing new concepts and capabilities progressively.

## Use Cases

Build real-world applications with Agno.

<CardGroup cols={3}>
  <Card title="Simple Agents" icon="user-astronaut" iconType="duotone" href="/examples/agents">
    Simple agents for web scraping, data processing, financial analysis, etc.
  </Card>

  <Card title="Advanced Workflows" icon="diagram-project" iconType="duotone" href="/examples/workflows">
    Advanced workflows for creating blog posts, investment reports, etc.
  </Card>

  <Card title="Full stack Applications" icon="brain-circuit" iconType="duotone" href="/examples/apps">
    Full stack applications like the LLM OS that come with a UI, database etc.
  </Card>
</CardGroup>

## Agent Concepts

Explore Agent concepts with detailed examples.

<CardGroup cols={3}>
  <Card title="Multimodal" icon="image" iconType="duotone" href="/examples/concepts/multimodal">
    Learn how to use multimodal Agents
  </Card>

  <Card title="RAG" icon="book-bookmark" iconType="duotone" href="/examples/concepts/rag">
    Learn how to use Agentic RAG
  </Card>

  <Card title="Knowledge" icon="brain-circuit" iconType="duotone" href="/examples/concepts/knowledge">
    Add domain-specific knowledge to your Agents
  </Card>

  <Card title="Teams" icon="users" iconType="duotone" href="/examples/concepts/teams">
    Scale your Agents with teams
  </Card>

  <Card title="Async" icon="bolt" iconType="duotone" href="/examples/concepts/async">
    Run Agents asynchronously
  </Card>

  <Card title="Hybrid search" icon="magnifying-glass-plus" iconType="duotone" href="/examples/concepts/hybrid-search">
    Combine semantic and keyword search
  </Card>

  <Card title="Memory" icon="database" iconType="duotone" href="/examples/concepts/memory">
    Let Agents remember past conversations
  </Card>

  <Card title="Tools" icon="screwdriver-wrench" iconType="duotone" href="/examples/concepts/tools">
    Extend your Agents with 100s or tools
  </Card>

  <Card title="Storage" icon="hard-drive" iconType="duotone" href="/examples/concepts/storage">
    Store Agents sessions in a database
  </Card>

  <Card title="Vector Databases" icon="database" iconType="duotone" href="/examples/concepts/vectordb">
    Store Knowledge in Vector Databases
  </Card>

  <Card title="Embedders" icon="database" iconType="duotone" href="/examples/concepts/embedders">
    Convert text to embeddings to store in VectorDbs
  </Card>
</CardGroup>

## Models

Explore different models with Agno.

<CardGroup cols={3}>
  <Card title="OpenAI" icon="network-wired" iconType="duotone" href="/examples/models/openai">
    Examples using OpenAI GPT models
  </Card>

  <Card title="Ollama" icon="laptop-code" iconType="duotone" href="/examples/models/ollama">
    Examples using Ollama models locally
  </Card>

  <Card title="Anthropic" icon="network-wired" iconType="duotone" href="/examples/models/anthropic">
    Examples using Anthropic models like Claude
  </Card>

  <Card title="Cohere" icon="brain-circuit" iconType="duotone" href="/examples/models/cohere">
    Examples using Cohere command models
  </Card>

  <Card title="DeepSeek" icon="circle-nodes" iconType="duotone" href="/examples/models/deepseek">
    Examples using DeepSeek models
  </Card>

  <Card title="Gemini" icon="google" iconType="duotone" href="/examples/models/gemini">
    Examples using Google Gemini models
  </Card>

  <Card title="Groq" icon="bolt" iconType="duotone" href="/examples/models/groq">
    Examples using Groq's fast inference
  </Card>

  <Card title="Mistral" icon="wind" iconType="duotone" href="/examples/models/mistral">
    Examples using Mistral models
  </Card>

  <Card title="Azure" icon="microsoft" iconType="duotone" href="/examples/models/azure">
    Examples using Azure OpenAI
  </Card>

  <Card title="Fireworks" icon="sparkles" iconType="duotone" href="/examples/models/fireworks">
    Examples using Fireworks models
  </Card>

  <Card title="AWS" icon="aws" iconType="duotone" href="/examples/models/aws">
    Examples using Amazon Bedrock
  </Card>

  <Card title="Hugging Face" icon="face-awesome" iconType="duotone" href="/examples/models/huggingface">
    Examples using Hugging Face models
  </Card>

  <Card title="NVIDIA" icon="microchip" iconType="duotone" href="/examples/models/nvidia">
    Examples using NVIDIA models
  </Card>

  <Card title="Together" icon="people-group" iconType="duotone" href="/examples/models/together">
    Examples using Together AI models
  </Card>

  <Card title="Vertex AI" icon="google" iconType="duotone" href="/examples/models/vertexai">
    Examples using Google Vertex AI models
  </Card>

  <Card title="xAI" icon="brain-circuit" iconType="duotone" href="/examples/models/xai">
    Examples using xAI models
  </Card>
</CardGroup>


# Basic Agent



## Code

```python cookbook/models/anthropic/basic.py
from agno.agent import Agent, RunResponse  # noqa
from agno.models.anthropic import Claude

agent = Agent(model=Claude(id="claude-3-5-sonnet-20241022"), markdown=True)

# Get the response in a variable
# run: RunResponse = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export ANTHROPIC_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U anthropic agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/anthropic/basic.py
      ```

      ```bash Windows
      python cookbook/models/anthropic/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent



## Code

```python cookbook/models/anthropic/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunResponse  # noqa
from agno.models.anthropic import Claude

agent = Agent(model=Claude(id="claude-3-5-sonnet-20241022"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunResponse] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export ANTHROPIC_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U anthropic agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/anthropic/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/anthropic/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Agent



## Code

```python cookbook/models/anthropic/image_agent.py
from agno.agent import Agent
from agno.media import Image
from agno.models.anthropic import Claude
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Claude(id="claude-3-5-sonnet-20241022"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

agent.print_response(
    "Tell me about this image and search the web for more information.",
    images=[
        Image(
            url="https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg"
        ),
    ],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export ANTHROPIC_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U anthropic duckduckgo-search agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/anthropic/image_agent.py
      ```

      ```bash Windows
      python cookbook/models/anthropic/image_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Knowledge



## Code

```python cookbook/models/anthropic/knowledge.py
from agno.agent import Agent
from agno.embedder.azure_openai import AzureOpenAIEmbedder
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.models.anthropic import Claude
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=PgVector(
        table_name="recipes",
        db_url=db_url,
        embedder=AzureOpenAIEmbedder(),
    ),
)
knowledge_base.load(recreate=False)  # Comment out after first run

agent = Agent(
    model=Claude(id="claude-3-5-sonnet-20241022"),
    knowledge=knowledge_base,
    show_tool_calls=True,
    debug_mode=True,
)
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API keys">
    ```bash
    export ANTHROPIC_API_KEY=xxx
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U anthropic sqlalchemy pgvector pypdf openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/anthropic/knowledge.py
      ```

      ```bash Windows
      python cookbook/models/anthropic/knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Storage



## Code

```python cookbook/models/anthropic/storage.py
from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.storage.agent.postgres import PostgresAgentStorage
from agno.tools.duckduckgo import DuckDuckGoTools

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

agent = Agent(
    model=Claude(id="claude-3-5-sonnet-20241022"),
    storage=PostgresAgentStorage(table_name="agent_sessions", db_url=db_url),
    tools=[DuckDuckGoTools()],
    add_history_to_messages=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export ANTHROPIC_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U anthropic sqlalchemy psycopg duckduckgo-search agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/anthropic/storage.py
      ```

      ```bash Windows
      python cookbook/models/anthropic/storage.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs



## Code

```python cookbook/models/anthropic/structured_output.py
from typing import List

from agno.agent import Agent, RunResponse  # noqa
from agno.models.anthropic import Claude
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


movie_agent = Agent(
    model=Claude(id="claude-3-5-sonnet-20240620"),
    description="You help people write movie scripts.",
    response_model=MovieScript,
)

# Get the response in a variable
run: RunResponse = movie_agent.run("New York")
pprint(run.content)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export ANTHROPIC_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U anthropic agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/anthropic/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/anthropic/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools



## Code

```python cookbook/models/anthropic/tool_use.py
from agno.agent import Agent
from agno.models.anthropic import Claude
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Claude(id="claude-3-5-sonnet-20240620"),
    tools=[DuckDuckGoTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Whats happening in France?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export ANTHROPIC_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U anthropic duckduckgo-search agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/anthropic/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/anthropic/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent



## Code

```python cookbook/models/aws/bedrock_claude/basic.py
from agno.agent import Agent, RunResponse  # noqa
from agno.models.aws.claude import Claude

agent = Agent(
    model=Claude(id="anthropic.claude-3-5-sonnet-20240620-v1:0"), markdown=True
)

# Get the response in a variable
# run: RunResponse = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your AWS Credentials">
    ```bash
    export AWS_ACCESS_KEY_ID=***
    export AWS_SECRET_ACCESS_KEY=***
    export AWS_DEFAULT_REGION=***
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U boto3 agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/aws/bedrock_claude/basic.py
      ```

      ```bash Windows
      python cookbook/models/aws/bedrock_claude/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent



## Code

```python cookbook/models/aws/bedrock_claude/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunResponse  # noqa
from agno.models.aws.claude import Claude

agent = Agent(
    model=Claude(id="anthropic.claude-3-5-sonnet-20240620-v1:0"), markdown=True
)

# Get the response in a variable
# run_response: Iterator[RunResponse] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your AWS Credentials">
    ```bash
    export AWS_ACCESS_KEY_ID=***
    export AWS_SECRET_ACCESS_KEY=***
    export AWS_DEFAULT_REGION=***
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U boto3 agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/aws/bedrock_claude/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/aws/bedrock_claude/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Knowledge



## Code

```python cookbook/models/aws/bedrock_claude/knowledge.py
from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.models.aws.claude import Claude
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=PgVector(table_name="recipes", db_url=db_url),
)
knowledge_base.load(recreate=True)  # Comment out after first run

agent = Agent(
    model=Claude(id="claude-3-5-sonnet-20241022"),
    knowledge=knowledge_base,
    show_tool_calls=True,
)
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your AWS Credentials">
    ```bash
    export AWS_ACCESS_KEY_ID=***
    export AWS_SECRET_ACCESS_KEY=***
    export AWS_DEFAULT_REGION=***
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U boto3 sqlalchemy pgvector pypdf openai psycopg agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/aws/bedrock_claude/knowledge.py
      ```

      ```bash Windows
      python cookbook/models/aws/bedrock_claude/knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Storage



## Code

```python cookbook/models/aws/bedrock_claude/storage.py
from agno.agent import Agent
from agno.models.aws.claude import Claude
from agno.storage.agent.postgres import PostgresAgentStorage
from agno.tools.duckduckgo import DuckDuckGoTools

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

agent = Agent(
    model=Claude(id="anthropic.claude-3-5-sonnet-20240620-v1:0"),
    storage=PostgresAgentStorage(table_name="agent_sessions", db_url=db_url),
    tools=[DuckDuckGoTools()],
    add_history_to_messages=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your AWS Credentials">
    ```bash
    export AWS_ACCESS_KEY_ID=***
    export AWS_SECRET_ACCESS_KEY=***
    export AWS_DEFAULT_REGION=***
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U boto3 duckduckgo-search sqlalchemy psycopg agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/aws/bedrock_claude/storage.py
      ```

      ```bash Windows
      python cookbook/models/aws/bedrock_claude/storage.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs



## Code

```python cookbook/models/aws/bedrock_claude/structured_output.py
from typing import List

from agno.agent import Agent, RunResponse  # noqa
from agno.models.aws.claude import Claude
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


movie_agent = Agent(
    model=Claude(id="anthropic.claude-3-5-sonnet-20240620-v1:0"),
    description="You help people write movie scripts.",
    response_model=MovieScript,
)

# Get the response in a variable
# movie_agent: RunResponse = movie_agent.run("New York")
# pprint(movie_agent.content)

movie_agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your AWS Credentials">
    ```bash
    export AWS_ACCESS_KEY_ID=***
    export AWS_SECRET_ACCESS_KEY=***
    export AWS_DEFAULT_REGION=***
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U boto3 agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/aws/bedrock_claude/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/aws/bedrock_claude/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools



## Code

```python cookbook/models/aws/bedrock_claude/tool_use.py
from agno.agent import Agent
from agno.models.aws.claude import Claude
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Claude(id="anthropic.claude-3-5-sonnet-20240620-v1:0"),
    tools=[DuckDuckGoTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Whats happening in France?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your AWS Credentials">
    ```bash
    export AWS_ACCESS_KEY_ID=***
    export AWS_SECRET_ACCESS_KEY=***
    export AWS_DEFAULT_REGION=***
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U boto3 duckduckgo-search agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/aws/bedrock_claude/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/aws/bedrock_claude/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent



## Code

```python cookbook/models/azure/openai/basic.py
from agno.agent import Agent, RunResponse  # noqa
from agno.models.azure import AzureOpenAI

agent = Agent(model=AzureOpenAI(id="gpt-4o"), markdown=True)

# Get the response in a variable
# run: RunResponse = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response on the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export AZURE_OPENAI_API_KEY=xxx
    export AZURE_OPENAI_ENDPOINT=xxx
    export AZURE_DEPLOYMENT=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/azure/openai/basic.py
      ```

      ```bash Windows
      python cookbook/models/azure/openai/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Streaming



## Code

```python cookbook/models/azure/openai/basic_stream.py
from typing import Iterator  # noqa

from agno.agent import Agent, RunResponse  # noqa
from agno.models.azure import AzureOpenAI

agent = Agent(model=AzureOpenAI(id="gpt-4o"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunResponse] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response on the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export AZURE_OPENAI_API_KEY=xxx
    export AZURE_OPENAI_ENDPOINT=xxx
    export AZURE_DEPLOYMENT=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/azure/openai/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/azure/openai/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Knowledge Base



## Code

```python cookbook/models/azure/openai/knowledge.py
from agno.agent import Agent
from agno.embedder.azure_openai import AzureOpenAIEmbedder
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.models.azure import AzureOpenAI
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=PgVector(
        table_name="recipes",
        db_url=db_url,
        embedder=AzureOpenAIEmbedder(),
    ),
)
knowledge_base.load(recreate=False)  # Comment out after first run

agent = Agent(
    model=AzureOpenAI(id="gpt-4o"),
    knowledge=knowledge_base,
    show_tool_calls=True,
    debug_mode=True,
)
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export AZURE_OPENAI_API_KEY=xxx
    export AZURE_OPENAI_ENDPOINT=xxx
    export AZURE_DEPLOYMENT=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno duckduckgo-search sqlalchemy pgvector pypdf
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/azure/openai/knowledge.py
      ```

      ```bash Windows
      python cookbook/models/azure/openai/knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Storage



## Code

```python cookbook/models/azure/openai/storage.py
from agno.agent import Agent
from agno.models.azure import AzureOpenAI
from agno.storage.agent.postgres import PostgresAgentStorage
from agno.tools.duckduckgo import DuckDuckGoTools

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

agent = Agent(
    model=AzureOpenAI(id="gpt-4o"),
    storage=PostgresAgentStorage(table_name="agent_sessions", db_url=db_url),
    tools=[DuckDuckGoTools()],
    add_history_to_messages=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export AZURE_OPENAI_API_KEY=xxx
    export AZURE_OPENAI_ENDPOINT=xxx
    export AZURE_DEPLOYMENT=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai sqlalchemy psycopg duckduckgo-search agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/azure/openai/storage.py
      ```

      ```bash Windows
      python cookbook/models/azure/openai/storage.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs



## Code

```python cookbook/models/azure/openai/structured_output.py
from typing import List

from agno.agent import Agent, RunResponse  # noqa
from agno.models.azure import AzureOpenAI
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


agent = Agent(
    model=AzureOpenAI(id="gpt-4o"),
    description="You help people write movie scripts.",
    response_model=MovieScript,
    # debug_mode=True,
)

# Get the response in a variable
# run: RunResponse = agent.run("New York")
# pprint(run.content)

agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export AZURE_OPENAI_API_KEY=xxx
    export AZURE_OPENAI_ENDPOINT=xxx
    export AZURE_DEPLOYMENT=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/azure/openai/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/azure/openai/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools



## Code

```python cookbook/models/azure/openai/tool_use.py
from agno.agent import Agent
from agno.models.azure import AzureOpenAI
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=AzureOpenAI(id="gpt-4o"),
    tools=[DuckDuckGoTools()],
    show_tool_calls=True,
    markdown=True,
)

agent.print_response("Whats happening in France?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export AZURE_OPENAI_API_KEY=xxx
    export AZURE_OPENAI_ENDPOINT=xxx
    export AZURE_DEPLOYMENT=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno duckduckgo-search
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/azure/openai/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/azure/openai/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent



## Code

```python cookbook/models/cohere/basic.py
from agno.agent import Agent, RunResponse  # noqa
from agno.models.cohere import Cohere

agent = Agent(model=Cohere(id="command-r-08-2024"), markdown=True)

# Get the response in a variable
# run: RunResponse = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export CO_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U cohere agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/cohere/basic.py
      ```

      ```bash Windows
      python cookbook/models/cohere/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent



## Code

```python cookbook/models/cohere/basic_stream.py
from agno.agent import Agent, RunResponse  # noqa
from agno.models.cohere import Cohere

agent = Agent(model=Cohere(id="command-r-08-2024"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunResponse] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export CO_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U cohere agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/cohere/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/cohere/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Knowledge



## Code

```python cookbook/models/cohere/knowledge.py
from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.models.cohere import Cohere
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=PgVector(table_name="recipes", db_url=db_url),
)
knowledge_base.load(recreate=False)  # Comment out after first run

agent = Agent(
    model=Cohere(id="command-r-08-2024"),
    knowledge=knowledge_base,
    show_tool_calls=True,
)
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export CO_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U cohere sqlalchemy pgvector pypdf agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/cohere/knowledge.py
      ```

      ```bash Windows
      python cookbook/models/cohere/knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Storage



## Code

```python cookbook/models/cohere/storage.py
from agno.agent import Agent
from agno.models.cohere import Cohere
from agno.storage.agent.postgres import PostgresAgentStorage
from agno.tools.duckduckgo import DuckDuckGoTools

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

agent = Agent(
    model=Cohere(id="command-r-08-2024"),
    storage=PostgresAgentStorage(table_name="agent_sessions", db_url=db_url),
    tools=[DuckDuckGoTools()],
    add_history_to_messages=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export CO_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U cohere sqlalchemy psycopg duckduckgo-search agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/cohere/storage.py
      ```

      ```bash Windows
      python cookbook/models/cohere/storage.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs



## Code

```python cookbook/models/cohere/structured_output.py
from typing import List

from agno.agent import Agent, RunResponse  # noqa
from agno.models.cohere import Cohere
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


json_mode_agent = Agent(
    model=Cohere(id="command-r-08-2024"),
    description="You help people write movie scripts.",
    response_model=MovieScript,
    # debug_mode=True,
)

# Get the response in a variable
# json_mode_response: RunResponse = json_mode_agent.run("New York")
# pprint(json_mode_response.content)

json_mode_agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export CO_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U cohere agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/cohere/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/cohere/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools



## Code

```python cookbook/models/cohere/tool_use.py
from agno.agent import Agent
from agno.models.cohere import Cohere
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Cohere(id="command-r-08-2024"),
    tools=[DuckDuckGoTools()],
    show_tool_calls=True,
    markdown=True,
)

agent.print_response("Whats happening in France?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export CO_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U cohere duckduckgo-search agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/cohere/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/cohere/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent



## Code

```python cookbook/models/deepseek/basic.py
from agno.agent import Agent, RunResponse  # noqa
from agno.models.deepseek import DeepSeek

agent = Agent(model=DeepSeek(id="deepseek-chat"), markdown=True)

# Get the response in a variable
# run: RunResponse = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export DEEPSEEK_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/deepseek/basic.py
      ```

      ```bash Windows
      python cookbook/models/deepseek/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent



## Code

```python cookbook/models/deepseek/basic_stream.py
from agno.agent import Agent, RunResponse  # noqa
from agno.models.deepseek import DeepSeek

agent = Agent(model=DeepSeek(id="deepseek-chat"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunResponse] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export DEEPSEEK_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/deepseek/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/deepseek/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs



## Code

```python cookbook/models/deepseek/structured_output.py
from typing import List

from agno.agent import Agent, RunResponse  # noqa
from agno.models.deepseek import DeepSeek
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


json_mode_agent = Agent(
    model=DeepSeek(id="deepseek-chat"),
    description="You help people write movie scripts.",
    response_model=MovieScript,
)

# Get the response in a variable
# json_mode_response: RunResponse = json_mode_agent.run("New York")
# pprint(json_mode_response.content)

json_mode_agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export DEEPSEEK_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/deepseek/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/deepseek/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools



## Code

```python cookbook/models/deepseek/tool_use.py
from agno.agent import Agent
from agno.models.deepseek import DeepSeek
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=DeepSeek(id="deepseek-chat"),
    tools=[DuckDuckGoTools()],
    show_tool_calls=True,
    markdown=True,
)

agent.print_response("Whats happening in France?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export DEEPSEEK_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai duckduckgo-search agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/deepseek/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/deepseek/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent



## Code

```python cookbook/models/fireworks/basic.py
from agno.agent import Agent, RunResponse  # noqa
from agno.models.fireworks import Fireworks

agent = Agent(
    model=Fireworks(id="accounts/fireworks/models/llama-v3p1-405b-instruct"),
    markdown=True,
)

# Get the response in a variable
# run: RunResponse = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export FIREWORKS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/fireworks/basic.py
      ```

      ```bash Windows
      python cookbook/models/fireworks/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent



## Code

```python cookbook/models/fireworks/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunResponse  # noqa
from agno.models.fireworks import Fireworks

agent = Agent(
    model=Fireworks(id="accounts/fireworks/models/llama-v3p1-405b-instruct"),
    markdown=True,
)

# Get the response in a variable
# run_response: Iterator[RunResponse] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export FIREWORKS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/fireworks/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/fireworks/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs



## Code

```python cookbook/models/fireworks/structured_output.py
from typing import List

from agno.agent import Agent, RunResponse  # noqa
from agno.models.fireworks import Fireworks
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


# Agent that uses JSON mode
agent = Agent(
    model=Fireworks(id="accounts/fireworks/models/llama-v3p1-405b-instruct"),
    description="You write movie scripts.",
    response_model=MovieScript,
)

# Get the response in a variable
# response: RunResponse = agent.run("New York")
# pprint(json_mode_response.content)

agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export FIREWORKS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/fireworks/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/fireworks/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools



## Code

```python cookbook/models/fireworks/tool_use.py
from agno.agent import Agent
from agno.models.fireworks import Fireworks
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Fireworks(id="accounts/fireworks/models/llama-v3p1-405b-instruct"),
    tools=[DuckDuckGoTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Whats happening in France?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export FIREWORKS_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai duckduckgo-search agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/fireworks/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/fireworks/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Audio Agent



## Code

```python cookbook/models/google/gemini/audio_input.py
from pathlib import Path

import requests
from agno.agent import Agent
from agno.media import Audio
from agno.models.google import Gemini

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp"),
    markdown=True,
)

url = "https://openaiassets.blob.core.windows.net/$web/API/docs/audio/alloy.wav"

# Download the audio file from the URL as bytes
response = requests.get(url)
audio_content = response.content

agent.print_response(
    "Tell me about this audio",
    audio=[Audio(content=audio_content)],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-generativeai requests agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/audio_input.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/audio_input.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent



## Code

```python cookbook/models/google/gemini/basic.py
from agno.agent import Agent, RunResponse  # noqa
from agno.models.google import Gemini

agent = Agent(model=Gemini(id="gemini-2.0-flash-exp"), markdown=True)

# Get the response in a variable
# run: RunResponse = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-generativeai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/basic.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent



## Code

```python cookbook/models/google/gemini/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunResponse  # noqa
from agno.models.google import Gemini

agent = Agent(model=Gemini(id="gemini-2.0-flash-exp"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunResponse] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-generativeai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Flash Thinking Agent



## Code

```python cookbook/models/google/gemini/flash_thinking_agent.py
from agno.agent import Agent
from agno.models.google import Gemini

task = (
    "Three missionaries and three cannibals need to cross a river. "
    "They have a boat that can carry up to two people at a time. "
    "If, at any time, the cannibals outnumber the missionaries on either side of the river, the cannibals will eat the missionaries. "
    "How can all six people get across the river safely? Provide a step-by-step solution and show the solutions as an ascii diagram"
)

agent = Agent(model=Gemini(id="gemini-2.0-flash-thinking-exp-1219"), markdown=True)
agent.print_response(task, stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-generativeai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/flash_thinking_agent.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/flash_thinking_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Agent



## Code

```python cookbook/models/google/gemini/image_input.py
from agno.agent import Agent
from agno.media import Image
from agno.models.google import Gemini
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

agent.print_response(
    "Tell me about this image and give me the latest news about it.",
    images=[
        Image(
            url="https://upload.wikimedia.org/wikipedia/commons/b/bf/Krakow_-_Kosciol_Mariacki.jpg"
        ),
    ],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-generativeai duckduckgo-search agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/image_input.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/image_input.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Knowledge



## Code

```python cookbook/models/google/gemini/knowledge.py
from agno.agent import Agent
from agno.embedder.google import GeminiEmbedder
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.models.google import Gemini
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=PgVector(
        table_name="recipes",
        db_url=db_url,
        embedder=GeminiEmbedder(),
    ),
)
knowledge_base.load(recreate=True)  # Comment out after first run

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp"),
    knowledge=knowledge_base,
    show_tool_calls=True,
)
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-generativeai sqlalchemy pgvector pypdf agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/knowledge.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Storage



## Code

```python cookbook/models/google/gemini/storage.py
from agno.agent import Agent
from agno.models.google import Gemini
from agno.storage.agent.postgres import PostgresAgentStorage
from agno.tools.duckduckgo import DuckDuckGoTools

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp"),
    storage=PostgresAgentStorage(table_name="agent_sessions", db_url=db_url),
    tools=[DuckDuckGoTools()],
    add_history_to_messages=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-generativeai sqlalchemy psycopg duckduckgo-search agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/storage.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/storage.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs



## Code

```python cookbook/models/google/gemini/structured_output.py
from typing import List

from agno.agent import Agent, RunResponse  # noqa
from agno.models.google import Gemini
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


movie_agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp"),
    description="You help people write movie scripts.",
    response_model=MovieScript,
)

movie_agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-generativeai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools



## Code

```python cookbook/models/google/gemini/tool_use.py
from agno.agent import Agent
from agno.models.google import Gemini
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp"),
    tools=[DuckDuckGoTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Whats happening in France?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-generativeai duckduckgo-search agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Video Agent



## Code

```python cookbook/models/google/gemini/video_agent.py
from pathlib import Path

from agno.agent import Agent
from agno.media import Video
from agno.models.google import Gemini

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp"),
    markdown=True,
)

# Please download "GreatRedSpot.mp4" using
# wget https://storage.googleapis.com/generativeai-downloads/images/GreatRedSpot.mp4
video_path = Path(__file__).parent.joinpath("GreatRedSpot.mp4")

agent.print_response("Tell me about this video", videos=[Video(filepath=video_path)])
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GOOGLE_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-generativeai agno
    ```
  </Step>

  <Step title="Download sample video">
    ```bash
    wget https://storage.googleapis.com/generativeai-downloads/images/GreatRedSpot.mp4
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/google/gemini/video_agent.py
      ```

      ```bash Windows
      python cookbook/models/google/gemini/video_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent



## Code

```python cookbook/models/groq/basic.py
from agno.agent import Agent, RunResponse  # noqa
from agno.models.groq import Groq

agent = Agent(model=Groq(id="llama-3.3-70b-versatile"), markdown=True)

# Get the response in a variable
# run: RunResponse = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response on the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GROQ_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U groq agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/groq/basic.py
      ```

      ```bash Windows
      python cookbook/models/groq/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent



## Code

```python cookbook/models/groq/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunResponse  # noqa
from agno.models.groq import Groq

agent = Agent(model=Groq(id="llama-3.3-70b-versatile"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunResponse] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response on the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GROQ_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U groq agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/groq/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/groq/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Agent



## Code

```python cookbook/models/groq/image_agent.py
from agno.agent import Agent
from agno.media import Image
from agno.models.groq import Groq

agent = Agent(model=Groq(id="llama-3.2-90b-vision-preview"))

agent.print_response(
    "Tell me about this image",
    images=[
        Image(url="https://upload.wikimedia.org/wikipedia/commons/f/f2/LPU-v1-die.jpg"),
    ],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GROQ_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U groq agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/groq/image_agent.py
      ```

      ```bash Windows
      python cookbook/models/groq/image_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Knowledge



## Code

```python cookbook/models/groq/knowledge.py
from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.models.groq import Groq
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=PgVector(table_name="recipes", db_url=db_url),
)
knowledge_base.load(recreate=False)  # Comment out after first run

agent = Agent(
    model=Groq(id="llama-3.3-70b-versatile"),
    knowledge=knowledge_base,
    show_tool_calls=True,
)
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GROQ_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U groq sqlalchemy pgvector pypdf openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/groq/knowledge.py
      ```

      ```bash Windows
      python cookbook/models/groq/knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Storage



## Code

```python cookbook/models/groq/storage.py
from agno.agent import Agent
from agno.models.groq import Groq
from agno.storage.agent.postgres import PostgresAgentStorage
from agno.tools.duckduckgo import DuckDuckGoTools

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

agent = Agent(
    model=Groq(id="llama-3.3-70b-versatile"),
    storage=PostgresAgentStorage(table_name="agent_sessions", db_url=db_url),
    tools=[DuckDuckGoTools()],
    add_history_to_messages=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GROQ_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U groq duckduckgo-search sqlalchemy psycopg agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/groq/storage.py
      ```

      ```bash Windows
      python cookbook/models/groq/storage.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs



## Code

```python cookbook/models/groq/structured_output.py
from typing import List

from agno.agent import Agent, RunResponse  # noqa
from agno.models.groq import Groq
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


json_mode_agent = Agent(
    model=Groq(id="llama-3.3-70b-versatile"),
    description="You help people write movie scripts.",
    response_model=MovieScript,
)

json_mode_agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GROQ_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U groq agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/groq/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/groq/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools



## Code

```python cookbook/models/groq/tool_use.py
from agno.agent import Agent
from agno.models.groq import Groq
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.newspaper4k import Newspaper4kTools

agent = Agent(
    model=Groq(id="llama-3.3-70b-versatile"),
    tools=[DuckDuckGoTools(), Newspaper4kTools()],
    description="You are a senior NYT researcher writing an article on a topic.",
    instructions=[
        "For a given topic, search for the top 5 links.",
        "Then read each URL and extract the article text, if a URL isn't available, ignore it.",
        "Analyse and prepare an NYT worthy article based on the information.",
    ],
    markdown=True,
    show_tool_calls=True,
    add_datetime_to_instructions=True,
)
agent.print_response("Simulation theory", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export GROQ_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U groq duckduckgo-search newspaper4k lxml_html_clean agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/groq/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/groq/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent



## Code

```python cookbook/models/huggingface/basic.py
from agno.agent import Agent
from agno.models.huggingface import HuggingFace

agent = Agent(
    model=HuggingFace(
        id="mistralai/Mistral-7B-Instruct-v0.2", max_tokens=4096, temperature=0
    ),
)
agent.print_response(
    "What is meaning of life and then recommend 5 best books to read about it"
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export HF_TOKEN=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U huggingface_hub agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/huggingface/basic.py
      ```

      ```bash Windows
      python cookbook/models/huggingface/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent



## Code

```python cookbook/models/huggingface/basic_stream.py
from agno.agent import Agent
from agno.models.huggingface import HuggingFace

agent = Agent(
    model=HuggingFace(
        id="mistralai/Mistral-7B-Instruct-v0.2", max_tokens=4096, temperature=0
    ),
)
agent.print_response(
    "What is meaning of life and then recommend 5 best books to read about it",
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export HF_TOKEN=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U huggingface_hub agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/huggingface/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/huggingface/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Llama Essay Writer



## Code

```python cookbook/models/huggingface/llama_essay_writer.py
import os
from getpass import getpass

from agno.agent import Agent
from agno.models.huggingface import HuggingFace

agent = Agent(
    model=HuggingFace(
        id="meta-llama/Meta-Llama-3-8B-Instruct",
        max_tokens=4096,
    ),
    description="You are an essay writer. Write a 300 words essay on topic that will be provided by user",
)
agent.print_response("topic: AI")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export HF_TOKEN=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U huggingface_hub agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/huggingface/llama_essay_writer.py
      ```

      ```bash Windows
      python cookbook/models/huggingface/llama_essay_writer.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent



## Code

```python cookbook/models/mistral/basic.py
from agno.agent import Agent, RunResponse  # noqa
from agno.models.mistral import MistralChat

mistral_api_key = os.getenv("MISTRAL_API_KEY")

agent = Agent(
    model=MistralChat(
        id="mistral-large-latest",
        api_key=mistral_api_key,
    ),
    markdown=True,
)

# Get the response in a variable
# run: RunResponse = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export MISTRAL_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U mistralai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/mistral/basic.py
      ```

      ```bash Windows
      python cookbook/models/mistral/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent



## Code

```python cookbook/models/mistral/basic_stream.py
from agno.agent import Agent, RunResponse  # noqa
from agno.models.mistral import MistralChat

mistral_api_key = os.getenv("MISTRAL_API_KEY")

agent = Agent(
    model=MistralChat(
        id="mistral-large-latest",
        api_key=mistral_api_key,
    ),
    markdown=True,
)

# Get the response in a variable
# run_response: Iterator[RunResponse] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export MISTRAL_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U mistralai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/mistral/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/mistral/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs



## Code

```python cookbook/models/mistral/structured_output.py
import os
from typing import List

from agno.agent import Agent, RunResponse  # noqa
from agno.models.mistral import MistralChat
from agno.tools.duckduckgo import DuckDuckGoTools
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa

mistral_api_key = os.getenv("MISTRAL_API_KEY")


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


json_mode_agent = Agent(
    model=MistralChat(
        id="mistral-large-latest",
        api_key=mistral_api_key,
    ),
    tools=[DuckDuckGoTools()],
    description="You help people write movie scripts.",
    response_model=MovieScript,
    show_tool_calls=True,
    debug_mode=True,
)

# Get the response in a variable
# json_mode_response: RunResponse = json_mode_agent.run("New York")
# pprint(json_mode_response.content)

json_mode_agent.print_response("Find a cool movie idea about London and write it.")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export MISTRAL_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U mistralai duckduckgo-search agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/mistral/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/mistral/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools



## Code

```python cookbook/models/mistral/tool_use.py
from agno.agent import Agent
from agno.models.mistral import MistralChat
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=MistralChat(
        id="mistral-large-latest",
    ),
    tools=[DuckDuckGoTools()],
    show_tool_calls=True,
    markdown=True,
)

agent.print_response("Whats happening in France?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export MISTRAL_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U mistralai duckduckgo-search agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/mistral/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/mistral/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent



## Code

```python cookbook/models/nvidia/basic.py
from agno.agent import Agent, RunResponse  # noqa
from agno.models.nvidia import Nvidia

agent = Agent(model=Nvidia(id="meta/llama-3.3-70b-instruct"), markdown=True)

# Get the response in a variable
# run: RunResponse = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export NVIDIA_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/nvidia/basic.py
      ```

      ```bash Windows
      python cookbook/models/nvidia/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent



## Code

```python cookbook/models/nvidia/basic_stream.py
from agno.agent import Agent, RunResponse  # noqa
from agno.models.nvidia import Nvidia

agent = Agent(model=Nvidia(id="meta/llama-3.3-70b-instruct"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunResponse] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export NVIDIA_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/nvidia/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/nvidia/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools



## Code

```python cookbook/models/nvidia/tool_use.py
from agno.agent import Agent
from agno.models.nvidia import Nvidia
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Nvidia(id="meta/llama-3.3-70b-instruct"),
    tools=[DuckDuckGoTools()],
    show_tool_calls=True,
    markdown=True,
)

agent.print_response("Whats happening in France?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export NVIDIA_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai duckduckgo-search agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/nvidia/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/nvidia/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent



## Code

```python cookbook/models/ollama/basic.py
from agno.agent import Agent, RunResponse  # noqa
from agno.models.ollama import Ollama

agent = Agent(model=Ollama(id="llama3.1:8b"), markdown=True)

# Get the response in a variable
# run: RunResponse = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull llama3.1:8b
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ollama/basic.py
      ```

      ```bash Windows
      python cookbook/models/ollama/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent



## Code

```python cookbook/models/ollama/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunResponse  # noqa
from agno.models.ollama import Ollama

agent = Agent(model=Ollama(id="llama3.1:8b"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunResponse] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull llama3.1:8b
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ollama/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/ollama/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Agent



## Code

```python cookbook/models/ollama/image_agent.py
from pathlib import Path

from agno.agent import Agent
from agno.media import Image
from agno.models.ollama import Ollama

agent = Agent(
    model=Ollama(id="llama3.2-vision"),
    markdown=True,
)

image_path = Path(__file__).parent.joinpath("super-agents.png")
agent.print_response(
    "Write a 3 sentence fiction story about the image",
    images=[Image(filepath=image_path)],
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull llama3.2-vision
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ollama/image_agent.py
      ```

      ```bash Windows
      python cookbook/models/ollama/image_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Knowledge



## Code

```python cookbook/models/ollama/knowledge.py
from agno.agent import Agent
from agno.embedder.ollama import OllamaEmbedder
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.models.ollama import Ollama
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=PgVector(
        table_name="recipes",
        db_url=db_url,
        embedder=OllamaEmbedder(id="llama3.2", dimensions=3072),
    ),
)
knowledge_base.load(recreate=True)  # Comment out after first run

agent = Agent(
    model=Ollama(id="llama3.2"),
    knowledge=knowledge_base,
    show_tool_calls=True,
)
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull llama3.2
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama sqlalchemy pgvector pypdf agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ollama/knowledge.py
      ```

      ```bash Windows
      python cookbook/models/ollama/knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Set Ollama Client



## Code

```python cookbook/models/ollama/set_client.py
from agno.agent import Agent, RunResponse  # noqa
from agno.models.ollama import Ollama
from agno.tools.yfinance import YFinanceTools
from ollama import Client as OllamaClient

agent = Agent(
    model=Ollama(id="llama3.2", client=OllamaClient()),
    tools=[YFinanceTools(stock_price=True)],
    markdown=True,
)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull llama3.2
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama yfinance agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ollama/set_client.py
      ```

      ```bash Windows
      python cookbook/models/ollama/set_client.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Storage



## Code

```python cookbook/models/ollama/storage.py
from agno.agent import Agent
from agno.models.ollama import Ollama
from agno.storage.agent.postgres import PostgresAgentStorage
from agno.tools.duckduckgo import DuckDuckGoTools

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

agent = Agent(
    model=Ollama(id="llama3.1:8b"),
    storage=PostgresAgentStorage(table_name="agent_sessions", db_url=db_url),
    tools=[DuckDuckGoTools()],
    add_history_to_messages=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull llama3.1:8b
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama sqlalchemy psycopg duckduckgo-search agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ollama/storage.py
      ```

      ```bash Windows
      python cookbook/models/ollama/storage.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs



## Code

```python cookbook/models/ollama/structured_output.py
import asyncio
from typing import List

from agno.agent import Agent
from agno.models.ollama import Ollama
from pydantic import BaseModel, Field


class MovieScript(BaseModel):
    name: str = Field(..., description="Give a name to this movie")
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


# Agent that returns a structured output
structured_output_agent = Agent(
    model=Ollama(id="llama3.2"),
    description="You write movie scripts.",
    response_model=MovieScript,
    structured_outputs=True,
)

# Run the agent synchronously
structured_output_agent.print_response("Llamas ruling the world")


# Run the agent asynchronously
async def run_agents_async():
    await structured_output_agent.aprint_response("Llamas ruling the world")


asyncio.run(run_agents_async())
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull llama3.2
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ollama/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/ollama/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools



## Code

```python cookbook/models/ollama/tool_use.py
from agno.agent import Agent
from agno.models.ollama import Ollama
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Ollama(id="llama3.1:8b"),
    tools=[DuckDuckGoTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Whats happening in France?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install Ollama">
    Follow the [installation guide](https://github.com/ollama/ollama?tab=readme-ov-file#macos) and run:

    ```bash
    ollama pull llama3.1:8b
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U ollama duckduckgo-search agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/ollama/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/ollama/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Audio Input Agent



## Code

```python cookbook/models/openai/audio_input_agent.py
import requests
from agno.agent import Agent, RunResponse  # noqa
from agno.media import Audio
from agno.models.openai import OpenAIChat

# Fetch the audio file and convert it to a base64 encoded string
url = "https://openaiassets.blob.core.windows.net/$web/API/docs/audio/alloy.wav"
response = requests.get(url)
response.raise_for_status()
wav_data = response.content

# Provide the agent with the audio file and get result as text
agent = Agent(
    model=OpenAIChat(id="gpt-4o-audio-preview", modalities=["text"]),
    markdown=True,
)
agent.print_response(
    "What is in this audio?", audio=[Audio(content=wav_data, format="wav")]
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai requests agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/audio_input_agent.py
      ```

      ```bash Windows
      python cookbook/models/openai/audio_input_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Audio Output Agent



## Code

```python cookbook/models/openai/audio_output_agent.py
from agno.agent import Agent, RunResponse  # noqa
from agno.models.openai import OpenAIChat
from agno.utils.audio import write_audio_to_file


# Provide the agent with the audio file and audio configuration and get result as text + audio
agent = Agent(
    model=OpenAIChat(
        id="gpt-4o-audio-preview",
        modalities=["text", "audio"],
        audio={"voice": "alloy", "format": "wav"},
    ),
    markdown=True,
)
response: RunResponse = agent.run("Tell me a 5 second scary story")

# Save the response audio to a file
if response.response_audio is not None:
    write_audio_to_file(
        audio=agent.run_response.response_audio.content, filename="tmp/scary_story.wav"
    )
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/audio_output_agent.py
      ```

      ```bash Windows
      python cookbook/models/openai/audio_output_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent



## Code

```python cookbook/models/openai/basic.py
from agno.agent import Agent, RunResponse  # noqa
from agno.models.openai import OpenAIChat

agent = Agent(model=OpenAIChat(id="gpt-4o"), markdown=True)

# Get the response in a variable
# run: RunResponse = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")

agent.run_response.metrics
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/basic.py
      ```

      ```bash Windows
      python cookbook/models/openai/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent



## Code

```python cookbook/models/openai/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunResponse  # noqa
from agno.models.openai import OpenAIChat

agent = Agent(model=OpenAIChat(id="gpt-4o"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunResponse] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/openai/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Generate Images



## Code

```python cookbook/models/openai/generate_images.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.dalle import DalleTools

image_agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    tools=[DalleTools()],
    description="You are an AI agent that can generate images using DALL-E.",
    instructions="When the user asks you to create an image, use the `create_image` tool to create the image.",
    markdown=True,
    show_tool_calls=True,
)

image_agent.print_response("Generate an image of a white siamese cat")

images = image_agent.get_images()
if images and isinstance(images, list):
    for image_response in images:
        image_url = image_response.url
        print(image_url)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/generate_images.py
      ```

      ```bash Windows
      python cookbook/models/openai/generate_images.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Image Agent



## Code

```python cookbook/models/openai/image_agent.py
from agno.agent import Agent
from agno.media import Image
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    tools=[DuckDuckGoTools()],
    markdown=True,
)

agent.print_response(
    "Tell me about this image and give me the latest news about it.",
    images=[
        Image(
            url="https://upload.wikimedia.org/wikipedia/commons/b/bf/Krakow_-_Kosciol_Mariacki.jpg"
        )
    ],
    stream=True,
)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai duckduckgo-search agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/image_agent.py
      ```

      ```bash Windows
      python cookbook/models/openai/image_agent.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Knowledge



## Code

```python cookbook/models/openai/knowledge.py
from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.models.openai import OpenAIChat
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=PgVector(table_name="recipes", db_url=db_url),
)
knowledge_base.load(recreate=True)  # Comment out after first run

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    knowledge=knowledge_base,
    use_tools=True,
    show_tool_calls=True,
)
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai sqlalchemy pgvector pypdf agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/knowledge.py
      ```

      ```bash Windows
      python cookbook/models/openai/knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Reasoning Effort



## Code

```python cookbook/models/openai/reasoning/reasoning_effort.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.yfinance import YFinanceTools

agent = Agent(
    model=OpenAIChat(id="o3-mini", reasoning_effort="high"),
    tools=[YFinanceTools(enable_all=True)],
    show_tool_calls=True,
    markdown=True,
)

agent.print_response("Write a report on the NVDA, is it a good buy?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai yfinance agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/reasoning/reasoning_effort.py
      ```

      ```bash Windows
      python cookbook/models/openai/reasoning/reasoning_effort.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Storage



## Code

```python cookbook/models/openai/storage.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.storage.agent.postgres import PostgresAgentStorage
from agno.tools.duckduckgo import DuckDuckGoTools

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    storage=PostgresAgentStorage(table_name="agent_sessions", db_url=db_url),
    tools=[DuckDuckGoTools()],
    add_history_to_messages=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai sqlalchemy psycopg duckduckgo-search agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/storage.py
      ```

      ```bash Windows
      python cookbook/models/openai/storage.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs



## Code

```python cookbook/models/openai/structured_output.py
from typing import List

from agno.agent import Agent, RunResponse  # noqa
from agno.models.openai import OpenAIChat
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


# Agent that uses JSON mode
json_mode_agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    description="You write movie scripts.",
    response_model=MovieScript,
)

# Agent that uses structured outputs
structured_output_agent = Agent(
    model=OpenAIChat(id="gpt-4o-2024-08-06"),
    description="You write movie scripts.",
    response_model=MovieScript,
    structured_outputs=True,
)


# Get the response in a variable
# json_mode_response: RunResponse = json_mode_agent.run("New York")
# pprint(json_mode_response.content)
# structured_output_response: RunResponse = structured_output_agent.run("New York")
# pprint(structured_output_response.content)

json_mode_agent.print_response("New York")
structured_output_agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/openai/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools



## Code

```python cookbook/models/openai/tool_use.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    tools=[DuckDuckGoTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Whats happening in France?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai duckduckgo-search agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/openai/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/openai/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent



## Code

```python cookbook/models/together/basic.py
from agno.agent import Agent, RunResponse  # noqa
from agno.models.together import Together

agent = Agent(
    model=Together(id="meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo"), markdown=True
)

# Get the response in a variable
# run: RunResponse = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export TOGETHER_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U together openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/together/basic.py
      ```

      ```bash Windows
      python cookbook/models/together/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent



## Code

```python cookbook/models/together/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunResponse  # noqa
from agno.models.together import Together

agent = Agent(
    model=Together(id="meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo"), markdown=True
)

# Get the response in a variable
# run_response: Iterator[RunResponse] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export TOGETHER_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U together openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/together/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/together/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs



## Code

```python cookbook/models/together/structured_output.py
from typing import List

from agno.agent import Agent, RunResponse  # noqa
from agno.models.together import Together
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


# Agent that uses JSON mode
json_mode_agent = Agent(
    model=Together(id="meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo"),
    description="You write movie scripts.",
    response_model=MovieScript,
)

# Get the response in a variable
# json_mode_response: RunResponse = json_mode_agent.run("New York")
# pprint(json_mode_response.content)

json_mode_agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export TOGETHER_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U together openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/together/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/together/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools



## Code

```python cookbook/models/together/tool_use.py
from agno.agent import Agent
from agno.models.together import Together
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Together(id="meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo"),
    tools=[DuckDuckGoTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Whats happening in France?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export TOGETHER_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U together openai duckduckgo-search agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/together/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/together/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent



## Code

```python cookbook/models/vertexai/basic.py
from agno.agent import Agent, RunResponse  # noqa
from agno.models.vertexai import Gemini

agent = Agent(model=Gemini(id="gemini-2.0-flash-exp"), markdown=True)

# Get the response in a variable
# run: RunResponse = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Authenticate with Google Cloud">
    Follow the [Google Cloud Authentication Guide](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal)
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-cloud-aiplatform agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/vertexai/basic.py
      ```

      ```bash Windows
      python cookbook/models/vertexai/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent



## Code

```python cookbook/models/vertexai/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunResponse  # noqa
from agno.models.vertexai import Gemini

agent = Agent(model=Gemini(id="gemini-2.0-flash-exp"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunResponse] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Authenticate with Google Cloud">
    Follow the [Google Cloud Authentication Guide](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal)
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-cloud-aiplatform agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/vertexai/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/vertexai/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Knowledge



## Code

```python cookbook/models/vertexai/knowledge.py
from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.models.vertexai import Gemini
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=PgVector(table_name="recipes", db_url=db_url),
)
knowledge_base.load(recreate=True)  # Comment out after first run

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp"),
    knowledge=knowledge_base,
    show_tool_calls=True,
)
agent.print_response("How to make Thai curry?", markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Authenticate with Google Cloud">
    Follow the [Google Cloud Authentication Guide](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal)
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-cloud-aiplatform sqlalchemy pgvector pypdf agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/vertexai/knowledge.py
      ```

      ```bash Windows
      python cookbook/models/vertexai/knowledge.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Storage



## Code

```python cookbook/models/vertexai/storage.py
from agno.agent import Agent
from agno.models.vertexai import Gemini
from agno.storage.agent.postgres import PostgresAgentStorage
from agno.tools.duckduckgo import DuckDuckGoTools

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp"),
    storage=PostgresAgentStorage(table_name="agent_sessions", db_url=db_url),
    tools=[DuckDuckGoTools()],
    add_history_to_messages=True,
    debug_mode=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Authenticate with Google Cloud">
    Follow the [Google Cloud Authentication Guide](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal)
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-cloud-aiplatform sqlalchemy psycopg duckduckgo-search agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/vertexai/storage.py
      ```

      ```bash Windows
      python cookbook/models/vertexai/storage.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Structured Outputs



## Code

```python cookbook/models/vertexai/structured_output.py
from typing import List

from agno.agent import Agent, RunResponse  # noqa
from agno.models.vertexai import Gemini
from pydantic import BaseModel, Field
from rich.pretty import pprint  # noqa


class MovieScript(BaseModel):
    setting: str = Field(
        ..., description="Provide a nice setting for a blockbuster movie."
    )
    ending: str = Field(
        ...,
        description="Ending of the movie. If not available, provide a happy ending.",
    )
    genre: str = Field(
        ...,
        description="Genre of the movie. If not available, select action, thriller or romantic comedy.",
    )
    name: str = Field(..., description="Give a name to this movie")
    characters: List[str] = Field(..., description="Name of characters for this movie.")
    storyline: str = Field(
        ..., description="3 sentence storyline for the movie. Make it exciting!"
    )


movie_agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp"),
    description="You help people write movie scripts.",
    response_model=MovieScript,
)

# Get the response in a variable
# run: RunResponse = movie_agent.run("New York")
# pprint(run.content)

movie_agent.print_response("New York")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Authenticate with Google Cloud">
    Follow the [Google Cloud Authentication Guide](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal)
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-cloud-aiplatform agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/vertexai/structured_output.py
      ```

      ```bash Windows
      python cookbook/models/vertexai/structured_output.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools



## Code

```python cookbook/models/vertexai/tool_use.py
from agno.agent import Agent
from agno.models.vertexai import Gemini
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=Gemini(id="gemini-2.0-flash-exp"),
    tools=[DuckDuckGoTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Whats happening in France?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Authenticate with Google Cloud">
    Follow the [Google Cloud Authentication Guide](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal)
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U google-cloud-aiplatform duckduckgo-search agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/vertexai/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/vertexai/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Basic Agent



## Code

```python cookbook/models/xai/basic.py
from agno.agent import Agent, RunResponse  # noqa
from agno.models.xai import xAI

agent = Agent(model=xAI(id="grok-beta"), markdown=True)

# Get the response in a variable
# run: RunResponse = agent.run("Share a 2 sentence horror story")
# print(run.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story")
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export XAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/xai/basic.py
      ```

      ```bash Windows
      python cookbook/models/xai/basic.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Streaming Agent



## Code

```python cookbook/models/xai/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunResponse  # noqa
from agno.models.xai import xAI

agent = Agent(model=xAI(id="grok-beta"), markdown=True)

# Get the response in a variable
# run_response: Iterator[RunResponse] = agent.run("Share a 2 sentence horror story", stream=True)
# for chunk in run_response:
#     print(chunk.content)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export XAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/xai/basic_stream.py
      ```

      ```bash Windows
      python cookbook/models/xai/basic_stream.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Agent with Tools



## Code

```python cookbook/models/xai/tool_use.py
from agno.agent import Agent
from agno.models.xai import xAI
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=xAI(id="grok-beta"),
    tools=[DuckDuckGoTools()],
    show_tool_calls=True,
    markdown=True,
)
agent.print_response("Whats happening in France?", stream=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Set your API key">
    ```bash
    export XAI_API_KEY=xxx
    ```
  </Step>

  <Step title="Install libraries">
    ```bash
    pip install -U openai duckduckgo-search agno
    ```
  </Step>

  <Step title="Run Agent">
    <CodeGroup>
      ```bash Mac
      python cookbook/models/xai/tool_use.py
      ```

      ```bash Windows
      python cookbook/models/xai/tool_use.py
      ```
    </CodeGroup>
  </Step>
</Steps>


# Blog Post Generator



This advanced example demonstrates how to build a sophisticated blog post generator that combines
web research capabilities with professional writing expertise. The workflow uses a multi-stage
approach:

1. Intelligent web research and source gathering
2. Content extraction and processing
3. Professional blog post writing with proper citations

Key capabilities:

* Advanced web research and source evaluation
* Content scraping and processing
* Professional writing with SEO optimization
* Automatic content caching for efficiency
* Source attribution and fact verification

Example blog topics to try:

* "The Rise of Artificial General Intelligence: Latest Breakthroughs"
* "How Quantum Computing is Revolutionizing Cybersecurity"
* "Sustainable Living in 2024: Practical Tips for Reducing Carbon Footprint"
* "The Future of Work: AI and Human Collaboration"
* "Space Tourism: From Science Fiction to Reality"
* "Mindfulness and Mental Health in the Digital Age"
* "The Evolution of Electric Vehicles: Current State and Future Trends"

## Code

```python blog_post_generator.py
import json
from textwrap import dedent
from typing import Dict, Iterator, Optional

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.storage.workflow.sqlite import SqliteWorkflowStorage
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.newspaper4k import Newspaper4kTools
from agno.utils.log import logger
from agno.utils.pprint import pprint_run_response
from agno.workflow import RunEvent, RunResponse, Workflow
from pydantic import BaseModel, Field


class NewsArticle(BaseModel):
    title: str = Field(..., description="Title of the article.")
    url: str = Field(..., description="Link to the article.")
    summary: Optional[str] = Field(
        ..., description="Summary of the article if available."
    )


class SearchResults(BaseModel):
    articles: list[NewsArticle]


class ScrapedArticle(BaseModel):
    title: str = Field(..., description="Title of the article.")
    url: str = Field(..., description="Link to the article.")
    summary: Optional[str] = Field(
        ..., description="Summary of the article if available."
    )
    content: Optional[str] = Field(
        ...,
        description="Full article content in markdown format. None if content is unavailable.",
    )


class BlogPostGenerator(Workflow):
    """Advanced workflow for generating professional blog posts with proper research and citations."""

    description: str = dedent("""\
    An intelligent blog post generator that creates engaging, well-researched content.
    This workflow orchestrates multiple AI agents to research, analyze, and craft
    compelling blog posts that combine journalistic rigor with engaging storytelling.
    The system excels at creating content that is both informative and optimized for
    digital consumption.
    """)

    # Search Agent: Handles intelligent web searching and source gathering
    searcher: Agent = Agent(
        model=OpenAIChat(id="gpt-4o-mini"),
        tools=[DuckDuckGoTools()],
        description=dedent("""\
        You are BlogResearch-X, an elite research assistant specializing in discovering
        high-quality sources for compelling blog content. Your expertise includes:

        - Finding authoritative and trending sources
        - Evaluating content credibility and relevance
        - Identifying diverse perspectives and expert opinions
        - Discovering unique angles and insights
        - Ensuring comprehensive topic coverage\
        """),
        instructions=(
            "1. Search Strategy 🔍\n"
            "   - Find 10-15 relevant sources and select the 5-7 best ones\n"
            "   - Prioritize recent, authoritative content\n"
            "   - Look for unique angles and expert insights\n"
            "2. Source Evaluation 📊\n"
            "   - Verify source credibility and expertise\n"
            "   - Check publication dates for timeliness\n"
            "   - Assess content depth and uniqueness\n"
            "3. Diversity of Perspectives 🌐\n"
            "   - Include different viewpoints\n"
            "   - Gather both mainstream and expert opinions\n"
            "   - Find supporting data and statistics"
        ),
        response_model=SearchResults,
        structured_outputs=True,
    )

    # Content Scraper: Extracts and processes article content
    article_scraper: Agent = Agent(
        model=OpenAIChat(id="gpt-4o-mini"),
        tools=[Newspaper4kTools()],
        description=dedent("""\
        You are ContentBot-X, a specialist in extracting and processing digital content
        for blog creation. Your expertise includes:

        - Efficient content extraction
        - Smart formatting and structuring
        - Key information identification
        - Quote and statistic preservation
        - Maintaining source attribution\
        """),
        instructions=(
            "1. Content Extraction 📑\n"
            "   - Extract content from the article\n"
            "   - Preserve important quotes and statistics\n"
            "   - Maintain proper attribution\n"
            "   - Handle paywalls gracefully\n"
            "2. Content Processing 🔄\n"
            "   - Format text in clean markdown\n"
            "   - Preserve key information\n"
            "   - Structure content logically\n"
            "3. Quality Control ✅\n"
            "   - Verify content relevance\n"
            "   - Ensure accurate extraction\n"
            "   - Maintain readability"
        ),
        response_model=ScrapedArticle,
        structured_outputs=True,
    )

    # Content Writer Agent: Crafts engaging blog posts from research
    writer: Agent = Agent(
        model=OpenAIChat(id="gpt-4o"),
        description=dedent("""\
        You are BlogMaster-X, an elite content creator combining journalistic excellence
        with digital marketing expertise. Your strengths include:

        - Crafting viral-worthy headlines
        - Writing engaging introductions
        - Structuring content for digital consumption
        - Incorporating research seamlessly
        - Optimizing for SEO while maintaining quality
        - Creating shareable conclusions\
        """),
        instructions=(
            "1. Content Strategy 📝\n"
            "   - Craft attention-grabbing headlines\n"
            "   - Write compelling introductions\n"
            "   - Structure content for engagement\n"
            "   - Include relevant subheadings\n"
            "2. Writing Excellence ✍️\n"
            "   - Balance expertise with accessibility\n"
            "   - Use clear, engaging language\n"
            "   - Include relevant examples\n"
            "   - Incorporate statistics naturally\n"
            "3. Source Integration 🔍\n"
            "   - Cite sources properly\n"
            "   - Include expert quotes\n"
            "   - Maintain factual accuracy\n"
            "4. Digital Optimization 💻\n"
            "   - Structure for scanability\n"
            "   - Include shareable takeaways\n"
            "   - Optimize for SEO\n"
            "   - Add engaging subheadings"
        ),
        expected_output=dedent("""\
        # {Viral-Worthy Headline}

        ## Introduction
        {Engaging hook and context}

        ## {Compelling Section 1}
        {Key insights and analysis}
        {Expert quotes and statistics}

        ## {Engaging Section 2}
        {Deeper exploration}
        {Real-world examples}

        ## {Practical Section 3}
        {Actionable insights}
        {Expert recommendations}

        ## Key Takeaways
        - {Shareable insight 1}
        - {Practical takeaway 2}
        - {Notable finding 3}

        ## Sources
        {Properly attributed sources with links}
        """),
        markdown=True,
    )

    def run(
        self,
        topic: str,
        use_search_cache: bool = True,
        use_scrape_cache: bool = True,
        use_cached_report: bool = True,
    ) -> Iterator[RunResponse]:
        logger.info(f"Generating a blog post on: {topic}")

        # Use the cached blog post if use_cache is True
        if use_cached_report:
            cached_blog_post = self.get_cached_blog_post(topic)
            if cached_blog_post:
                yield RunResponse(
                    content=cached_blog_post, event=RunEvent.workflow_completed
                )
                return

        # Search the web for articles on the topic
        search_results: Optional[SearchResults] = self.get_search_results(
            topic, use_search_cache
        )
        # If no search_results are found for the topic, end the workflow
        if search_results is None or len(search_results.articles) == 0:
            yield RunResponse(
                event=RunEvent.workflow_completed,
                content=f"Sorry, could not find any articles on the topic: {topic}",
            )
            return

        # Scrape the search results
        scraped_articles: Dict[str, ScrapedArticle] = self.scrape_articles(
            search_results, use_scrape_cache
        )

        # Write a blog post
        yield from self.write_blog_post(topic, scraped_articles)

    def get_cached_blog_post(self, topic: str) -> Optional[str]:
        logger.info("Checking if cached blog post exists")
        return self.session_state.get("blog_posts", {}).get(topic)

    def add_blog_post_to_cache(self, topic: str, blog_post: str):
        logger.info(f"Saving blog post for topic: {topic}")
        self.session_state.setdefault("blog_posts", {})
        self.session_state["blog_posts"][topic] = blog_post
        # Save the blog post to the storage
        self.write_to_storage()

    def get_cached_search_results(self, topic: str) -> Optional[SearchResults]:
        logger.info("Checking if cached search results exist")
        return self.session_state.get("search_results", {}).get(topic)

    def add_search_results_to_cache(self, topic: str, search_results: SearchResults):
        logger.info(f"Saving search results for topic: {topic}")
        self.session_state.setdefault("search_results", {})
        self.session_state["search_results"][topic] = search_results.model_dump()
        # Save the search results to the storage
        self.write_to_storage()

    def get_cached_scraped_articles(
        self, topic: str
    ) -> Optional[Dict[str, ScrapedArticle]]:
        logger.info("Checking if cached scraped articles exist")
        return self.session_state.get("scraped_articles", {}).get(topic)

    def add_scraped_articles_to_cache(
        self, topic: str, scraped_articles: Dict[str, ScrapedArticle]
    ):
        logger.info(f"Saving scraped articles for topic: {topic}")
        self.session_state.setdefault("scraped_articles", {})
        self.session_state["scraped_articles"][topic] = scraped_articles
        # Save the scraped articles to the storage
        self.write_to_storage()

    def get_search_results(
        self, topic: str, use_search_cache: bool, num_attempts: int = 3
    ) -> Optional[SearchResults]:
        # Get cached search_results from the session state if use_search_cache is True
        if use_search_cache:
            try:
                search_results_from_cache = self.get_cached_search_results(topic)
                if search_results_from_cache is not None:
                    search_results = SearchResults.model_validate(
                        search_results_from_cache
                    )
                    logger.info(
                        f"Found {len(search_results.articles)} articles in cache."
                    )
                    return search_results
            except Exception as e:
                logger.warning(f"Could not read search results from cache: {e}")

        # If there are no cached search_results, use the searcher to find the latest articles
        for attempt in range(num_attempts):
            try:
                searcher_response: RunResponse = self.searcher.run(topic)
                if (
                    searcher_response is not None
                    and searcher_response.content is not None
                    and isinstance(searcher_response.content, SearchResults)
                ):
                    article_count = len(searcher_response.content.articles)
                    logger.info(
                        f"Found {article_count} articles on attempt {attempt + 1}"
                    )
                    # Cache the search results
                    self.add_search_results_to_cache(topic, searcher_response.content)
                    return searcher_response.content
                else:
                    logger.warning(
                        f"Attempt {attempt + 1}/{num_attempts} failed: Invalid response type"
                    )
            except Exception as e:
                logger.warning(f"Attempt {attempt + 1}/{num_attempts} failed: {str(e)}")

        logger.error(f"Failed to get search results after {num_attempts} attempts")
        return None

    def scrape_articles(
        self, search_results: SearchResults, use_scrape_cache: bool
    ) -> Dict[str, ScrapedArticle]:
        scraped_articles: Dict[str, ScrapedArticle] = {}

        # Get cached scraped_articles from the session state if use_scrape_cache is True
        if use_scrape_cache:
            try:
                scraped_articles_from_cache = self.get_cached_scraped_articles(topic)
                if scraped_articles_from_cache is not None:
                    scraped_articles = scraped_articles_from_cache
                    logger.info(
                        f"Found {len(scraped_articles)} scraped articles in cache."
                    )
                    return scraped_articles
            except Exception as e:
                logger.warning(f"Could not read scraped articles from cache: {e}")

        # Scrape the articles that are not in the cache
        for article in search_results.articles:
            if article.url in scraped_articles:
                logger.info(f"Found scraped article in cache: {article.url}")
                continue

            article_scraper_response: RunResponse = self.article_scraper.run(
                article.url
            )
            if (
                article_scraper_response is not None
                and article_scraper_response.content is not None
                and isinstance(article_scraper_response.content, ScrapedArticle)
            ):
                scraped_articles[article_scraper_response.content.url] = (
                    article_scraper_response.content
                )
                logger.info(f"Scraped article: {article_scraper_response.content.url}")

        # Save the scraped articles in the session state
        self.add_scraped_articles_to_cache(topic, scraped_articles)
        return scraped_articles

    def write_blog_post(
        self, topic: str, scraped_articles: Dict[str, ScrapedArticle]
    ) -> Iterator[RunResponse]:
        logger.info("Writing blog post")
        # Prepare the input for the writer
        writer_input = {
            "topic": topic,
            "articles": [v.model_dump() for v in scraped_articles.values()],
        }
        # Run the writer and yield the response
        yield from self.writer.run(json.dumps(writer_input, indent=4), stream=True)
        # Save the blog post in the cache
        self.add_blog_post_to_cache(topic, self.writer.run_response.content)


# Run the workflow if the script is executed directly
if __name__ == "__main__":
    import random

    from rich.prompt import Prompt

    # Fun example prompts to showcase the generator's versatility
    example_prompts = [
        "Why Cats Secretly Run the Internet",
        "The Science Behind Why Pizza Tastes Better at 2 AM",
        "Time Travelers' Guide to Modern Social Media",
        "How Rubber Ducks Revolutionized Software Development",
        "The Secret Society of Office Plants: A Survival Guide",
        "Why Dogs Think We're Bad at Smelling Things",
        "The Underground Economy of Coffee Shop WiFi Passwords",
        "A Historical Analysis of Dad Jokes Through the Ages",
    ]

    # Get topic from user
    topic = Prompt.ask(
        "[bold]Enter a blog post topic[/bold] (or press Enter for a random example)\n✨",
        default=random.choice(example_prompts),
    )

    # Convert the topic to a URL-safe string for use in session_id
    url_safe_topic = topic.lower().replace(" ", "-")

    # Initialize the blog post generator workflow
    # - Creates a unique session ID based on the topic
    # - Sets up SQLite storage for caching results
    generate_blog_post = BlogPostGenerator(
        session_id=f"generate-blog-post-on-{url_safe_topic}",
        storage=SqliteWorkflowStorage(
            table_name="generate_blog_post_workflows",
            db_file="tmp/workflows.db",
        ),
    )

    # Execute the workflow with caching enabled
    # Returns an iterator of RunResponse objects containing the generated content
    blog_post: Iterator[RunResponse] = generate_blog_post.run(
        topic=topic,
        use_search_cache=True,
        use_scrape_cache=True,
        use_cached_report=True,
    )

    # Print the response
    pprint_run_response(blog_post, markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    openai duckduckgo-search newspaper4k lxml_html_clean sqlalchemy agno
    ```
  </Step>

  <Step title="Run the workflow">
    ```bash
    python blog_post_generator.py
    ```
  </Step>
</Steps>


# Investment Report Generator



This advanced example shows how to build a sophisticated investment analysis system that combines
market research, financial analysis, and portfolio management. The workflow uses a three-stage
approach:

1. Comprehensive stock analysis and market research
2. Investment potential evaluation and ranking
3. Strategic portfolio allocation recommendations

Key capabilities:

* Real-time market data analysis
* Professional financial research
* Investment risk assessment
* Portfolio allocation strategy
* Detailed investment rationale

Example companies to analyze:

* "AAPL, MSFT, GOOGL" (Tech Giants)
* "NVDA, AMD, INTC" (Semiconductor Leaders)
* "TSLA, F, GM" (Automotive Innovation)
* "JPM, BAC, GS" (Banking Sector)
* "AMZN, WMT, TGT" (Retail Competition)
* "PFE, JNJ, MRNA" (Healthcare Focus)
* "XOM, CVX, BP" (Energy Sector)

## Code

```python investment_report_generator.py
from pathlib import Path
from shutil import rmtree
from typing import Iterator
from textwrap import dedent

from agno.agent import Agent, RunResponse
from agno.storage.workflow.sqlite import SqliteWorkflowStorage
from agno.tools.yfinance import YFinanceTools
from agno.utils.log import logger
from agno.utils.pprint import pprint_run_response
from agno.workflow import Workflow

reports_dir = Path(__file__).parent.joinpath("reports", "investment")
if reports_dir.is_dir():
    rmtree(path=reports_dir, ignore_errors=True)
reports_dir.mkdir(parents=True, exist_ok=True)
stock_analyst_report = str(reports_dir.joinpath("stock_analyst_report.md"))
research_analyst_report = str(reports_dir.joinpath("research_analyst_report.md"))
investment_report = str(reports_dir.joinpath("investment_report.md"))


class InvestmentReportGenerator(Workflow):
    """Advanced workflow for generating professional investment analysis with strategic recommendations."""

    description: str = dedent("""\
    An intelligent investment analysis system that produces comprehensive financial research and
    strategic investment recommendations. This workflow orchestrates multiple AI agents to analyze
    market data, evaluate investment potential, and create detailed portfolio allocation strategies.
    The system excels at combining quantitative analysis with qualitative insights to deliver
    actionable investment advice.
    """)

    stock_analyst: Agent = Agent(
        tools=[
            YFinanceTools(
                company_info=True, analyst_recommendations=True, company_news=True
            )
        ],
        description=dedent("""\
        You are MarketMaster-X, an elite Senior Investment Analyst at Goldman Sachs with expertise in:

        - Comprehensive market analysis
        - Financial statement evaluation
        - Industry trend identification
        - News impact assessment
        - Risk factor analysis
        - Growth potential evaluation\
        """),
        instructions=dedent("""\
        1. Market Research 📊
           - Analyze company fundamentals and metrics
           - Review recent market performance
           - Evaluate competitive positioning
           - Assess industry trends and dynamics
        2. Financial Analysis 💹
           - Examine key financial ratios
           - Review analyst recommendations
           - Analyze recent news impact
           - Identify growth catalysts
        3. Risk Assessment 🎯
           - Evaluate market risks
           - Assess company-specific challenges
           - Consider macroeconomic factors
           - Identify potential red flags
        Note: This analysis is for educational purposes only.\
        """),
        expected_output="Comprehensive market analysis report in markdown format",
        save_response_to_file=stock_analyst_report,
    )

    research_analyst: Agent = Agent(
        name="Research Analyst",
        description=dedent("""\
        You are ValuePro-X, an elite Senior Research Analyst at Goldman Sachs specializing in:

        - Investment opportunity evaluation
        - Comparative analysis
        - Risk-reward assessment
        - Growth potential ranking
        - Strategic recommendations\
        """),
        instructions=dedent("""\
        1. Investment Analysis 🔍
           - Evaluate each company's potential
           - Compare relative valuations
           - Assess competitive advantages
           - Consider market positioning
        2. Risk Evaluation 📈
           - Analyze risk factors
           - Consider market conditions
           - Evaluate growth sustainability
           - Assess management capability
        3. Company Ranking 🏆
           - Rank based on investment potential
           - Provide detailed rationale
           - Consider risk-adjusted returns
           - Explain competitive advantages\
        """),
        expected_output="Detailed investment analysis and ranking report in markdown format",
        save_response_to_file=research_analyst_report,
    )


    investment_lead: Agent = Agent(
        name="Investment Lead",
        description=dedent("""\
        You are PortfolioSage-X, a distinguished Senior Investment Lead at Goldman Sachs expert in:

        - Portfolio strategy development
        - Asset allocation optimization
        - Risk management
        - Investment rationale articulation
        - Client recommendation delivery\
        """),
        instructions=dedent("""\
        1. Portfolio Strategy 💼
           - Develop allocation strategy
           - Optimize risk-reward balance
           - Consider diversification
           - Set investment timeframes
        2. Investment Rationale 📝
           - Explain allocation decisions
           - Support with analysis
           - Address potential concerns
           - Highlight growth catalysts
        3. Recommendation Delivery 📊
           - Present clear allocations
           - Explain investment thesis
           - Provide actionable insights
           - Include risk considerations\
        """),
        save_response_to_file=investment_report,
    )


    def run(self, companies: str) -> Iterator[RunResponse]:
        logger.info(f"Getting investment reports for companies: {companies}")
        initial_report: RunResponse = self.stock_analyst.run(companies)
        if initial_report is None or not initial_report.content:
            yield RunResponse(
                run_id=self.run_id,
                content="Sorry, could not get the stock analyst report.",
            )
            return

        logger.info("Ranking companies based on investment potential.")
        ranked_companies: RunResponse = self.research_analyst.run(
            initial_report.content
        )
        if ranked_companies is None or not ranked_companies.content:
            yield RunResponse(
                run_id=self.run_id, content="Sorry, could not get the ranked companies."
            )
            return

        logger.info(
            "Reviewing the research report and producing an investment proposal."
        )
        yield from self.investment_lead.run(ranked_companies.content, stream=True)



# Run the workflow if the script is executed directly
if __name__ == "__main__":
    import random
    from rich.prompt import Prompt

    # Example investment scenarios to showcase the analyzer's capabilities
    example_scenarios = [
        "AAPL, MSFT, GOOGL",  # Tech Giants
        "NVDA, AMD, INTC",    # Semiconductor Leaders
        "TSLA, F, GM",        # Automotive Innovation
        "JPM, BAC, GS",       # Banking Sector
        "AMZN, WMT, TGT",     # Retail Competition
        "PFE, JNJ, MRNA",     # Healthcare Focus
        "XOM, CVX, BP",       # Energy Sector
    ]

    # Get companies from user with example suggestion
    companies = Prompt.ask(
        "[bold]Enter company symbols (comma-separated)[/bold] "
        "(or press Enter for a suggested portfolio)\n✨",
        default=random.choice(example_scenarios),
    )

    # Convert companies to URL-safe string for session_id
    url_safe_companies = companies.lower().replace(" ", "-").replace(",", "")

    # Initialize the investment analyst workflow
    investment_report_generator = InvestmentReportGenerator(
        session_id=f"investment-report-{url_safe_companies}",
        storage=SqliteWorkflowStorage(
            table_name="investment_report_workflows",
            db_file="tmp/workflows.db",
        ),
    )

    # Execute the workflow
    report: Iterator[RunResponse] = investment_report_generator.run(companies=companies)

    # Print the report
    pprint_run_response(report, markdown=True)
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai yfinance agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python investment_report_generator.py
    ```
  </Step>
</Steps>


# Personalized Email Generator



This workflow helps sales professionals craft highly personalized cold emails by:

1. Researching target companies through their websites
2. Analyzing their business model, tech stack, and unique attributes
3. Generating personalized email drafts
4. Sending test emails to yourself for review before actual outreach

Why is this helpful?

* You always have an extra review step—emails are sent to you first.
  This ensures you can fine-tune messaging before reaching your actual prospect.
* Ideal for iterating on tone, style, and personalization en masse.

Who should use this?

* SDRs, Account Executives, Business Development Managers
* Founders, Marketing Professionals, B2B Sales Representatives
* Anyone building relationships or conducting outreach at scale

Example use cases:

* SaaS sales outreach
* Consulting service proposals
* Partnership opportunities
* Investor relations
* Recruitment outreach
  • Event invitations

The script will send draft emails to your email if `DEMO_MODE=False`. If `DEMO_MODE=True`, it prints the email to the console for review.

Then you can confidently send the refined emails to your prospects!

## Code

```python personalized_email_generator.py
import json
from datetime import datetime
from textwrap import dedent
from typing import Dict, Iterator, List, Optional

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.storage.workflow.sqlite import SqliteWorkflowStorage
from agno.tools.exa import ExaTools
from agno.utils.log import logger
from agno.utils.pprint import pprint_run_response
from agno.workflow import RunResponse, Workflow
from pydantic import BaseModel, Field

# Demo mode
# - set to True to print email to console
# - set to False to send to yourself
DEMO_MODE = True
today = datetime.now().strftime("%Y-%m-%d")

# Example leads - Replace with your actual targets
leads: Dict[str, Dict[str, str]] = {
    "Notion": {
        "name": "Notion",
        "website": "https://www.notion.so",
        "contact_name": "Ivan Zhao",
        "position": "CEO",
    },
    # Add more companies as needed
}

# Updated sender details for an AI analytics company
sender_details_dict: Dict[str, str] = {
    "name": "Sarah Chen",
    "email": "your.email@company.com",  # Your email goes here
    "organization": "Data Consultants Inc",
    "service_offered": "We help build data products and offer data consulting services",
    "calendar_link": "https://calendly.com/data-consultants-inc",
    "linkedin": "https://linkedin.com/in/your-profile",
    "phone": "+1 (555) 123-4567",
    "website": "https://www.data-consultants.com",
}

email_template = """\
Hey [RECIPIENT_NAME]

[PERSONAL_NOTE]

[PROBLEM_THEY_HAVE]

[SOLUTION_YOU_OFFER]

[SOCIAL_PROOF]

Here's my cal link if you're open to a call: [CALENDAR_LINK] ☕️

[SIGNATURE]

P.S. You can also dm me on X\
"""


class CompanyInfo(BaseModel):
    """
    Stores in-depth data about a company gathered during the research phase.
    """

    # Basic Information
    company_name: str = Field(..., description="Company name")
    website_url: str = Field(..., description="Company website URL")

    # Business Details
    industry: Optional[str] = Field(None, description="Primary industry")
    core_business: Optional[str] = Field(None, description="Main business focus")
    business_model: Optional[str] = Field(None, description="B2B, B2C, etc.")

    # Marketing Information
    motto: Optional[str] = Field(None, description="Company tagline/slogan")
    value_proposition: Optional[str] = Field(None, description="Main value proposition")
    target_audience: Optional[List[str]] = Field(
        None, description="Target customer segments"
    )

    # Company Metrics
    company_size: Optional[str] = Field(None, description="Employee count range")
    founded_year: Optional[int] = Field(None, description="Year founded")
    locations: Optional[List[str]] = Field(None, description="Office locations")

    # Technical Details
    technologies: Optional[List[str]] = Field(None, description="Technology stack")
    integrations: Optional[List[str]] = Field(None, description="Software integrations")

    # Market Position
    competitors: Optional[List[str]] = Field(None, description="Main competitors")
    unique_selling_points: Optional[List[str]] = Field(
        None, description="Key differentiators"
    )
    market_position: Optional[str] = Field(None, description="Market positioning")

    # Social Proof
    customers: Optional[List[str]] = Field(None, description="Notable customers")
    case_studies: Optional[List[str]] = Field(None, description="Success stories")
    awards: Optional[List[str]] = Field(None, description="Awards and recognition")

    # Recent Activity
    recent_news: Optional[List[str]] = Field(None, description="Recent news/updates")
    blog_topics: Optional[List[str]] = Field(None, description="Recent blog topics")

    # Pain Points & Opportunities
    challenges: Optional[List[str]] = Field(None, description="Potential pain points")
    growth_areas: Optional[List[str]] = Field(None, description="Growth opportunities")

    # Contact Information
    email_address: Optional[str] = Field(None, description="Contact email")
    phone: Optional[str] = Field(None, description="Contact phone")
    social_media: Optional[Dict[str, str]] = Field(
        None, description="Social media links"
    )

    # Additional Fields
    pricing_model: Optional[str] = Field(None, description="Pricing strategy and tiers")
    user_base: Optional[str] = Field(None, description="Estimated user base size")
    key_features: Optional[List[str]] = Field(None, description="Main product features")
    integration_ecosystem: Optional[List[str]] = Field(
        None, description="Integration partners"
    )
    funding_status: Optional[str] = Field(
        None, description="Latest funding information"
    )
    growth_metrics: Optional[Dict[str, str]] = Field(
        None, description="Key growth indicators"
    )


class PersonalisedEmailGenerator(Workflow):
    """
    Personalized email generation system that:

    1. Scrapes the target company's website
    2. Gathers essential info (tech stack, position in market, new updates)
    3. Generates a personalized cold email used for B2B outreach

    This workflow is designed to help you craft outreach that resonates
    specifically with your prospect, addressing known challenges and
    highlighting tailored solutions.
    """

    description: str = dedent("""\
        AI-Powered B2B Outreach Workflow:
        --------------------------------------------------------
        1. Research & Analyze
        2. Generate Personalized Email
        3. Send Draft to Yourself
        --------------------------------------------------------
        This creates a frictionless review layer, letting you refine each
        email before sending it to real prospects.
        Perfect for data-driven, personalized B2B outreach at scale.
    """)

    scraper: Agent = Agent(
        model=OpenAIChat(id="gpt-4o"),
        tools=[ExaTools()],
        description=dedent("""\
            You are an expert SaaS business analyst specializing in:

            🔍 Product Intelligence
            - Feature analysis
            - User experience evaluation
            - Integration capabilities
            - Platform scalability
            - Enterprise readiness

            📊 Market Position Analysis
            - Competitive advantages
            - Market penetration
            - Growth trajectory
            - Enterprise adoption
            - International presence

            💡 Technical Architecture
            - Infrastructure setup
            - Security standards
            - API capabilities
            - Data management
            - Compliance status

            🎯 Business Intelligence
            - Revenue model analysis
            - Customer acquisition strategy
            - Enterprise pain points
            - Scaling challenges
            - Integration opportunities\
        """),
        instructions=dedent("""\
            1. Start with the company website and analyze:
            - Homepage messaging
            - Product/service pages
            - About us section
            - Blog content
            - Case studies
            - Team pages

            2. Look for specific details about:
            - Recent company news
            - Customer testimonials
            - Technology partnerships
            - Industry awards
            - Growth indicators

            3. Identify potential pain points:
            - Scaling challenges
            - Market pressures
            - Technical limitations
            - Operational inefficiencies

            4. Focus on actionable insights that could:
            - Drive business growth
            - Improve operations
            - Enhance customer experience
            - Increase market share

            Remember: Quality over quantity. Focus on insights that could lead to meaningful business conversations.\
        """),
        response_model=CompanyInfo,
        structured_outputs=True,
    )

    email_creator: Agent = Agent(
        model=OpenAIChat(id="gpt-4o"),
        description=dedent("""\
            You are writing for a friendly, empathetic 20-year-old sales rep whose
            style is cool, concise, and respectful. Tone is casual yet professional.

            - Be polite but natural, using simple language.
            - Never sound robotic or use big cliché words like "delve", "synergy" or "revolutionary."
            - Clearly address problems the prospect might be facing and how we solve them.
            - Keep paragraphs short and friendly, with a natural voice.
            - End on a warm, upbeat note, showing willingness to help.\
        """),
        instructions=dedent("""\
            Please craft a highly personalized email that has:

            1. A simple, personal subject line referencing the problem or opportunity.
            2. At least one area for improvement or highlight from research.
            3. A quick explanation of how we can help them (no heavy jargon).
            4. References a known challenge from the research.
            5. Avoid words like "delve", "explore", "synergy", "amplify", "game changer", "revolutionary", "breakthrough".
            6. Use first-person language ("I") naturally.
            7. Maintain a 20-year-old’s friendly style—brief and to the point.
            8. Avoid placing the recipient's name in the subject line.

            Use the following structural template, but ensure the final tone
            feels personal and conversation-like, not automatically generated:
            ----------------------------------------------------------------------
            """)
        + "Email Template to work with:\n"
        + email_template,
        markdown=False,
        add_datetime_to_instructions=True,
    )

    def get_cached_company_data(self, company_name: str) -> Optional[CompanyInfo]:
        """Retrieve cached company research data"""
        logger.info(f"Checking cache for company data: {company_name}")
        cached_data = self.session_state.get("company_research", {}).get(company_name)
        if cached_data:
            return CompanyInfo.model_validate(cached_data)
        return None

    def cache_company_data(self, company_name: str, company_data: CompanyInfo):
        """Cache company research data"""
        logger.info(f"Caching company data for: {company_name}")
        self.session_state.setdefault("company_research", {})
        self.session_state["company_research"][company_name] = company_data.model_dump()
        self.write_to_storage()

    def get_cached_email(self, company_name: str) -> Optional[str]:
        """Retrieve cached email content"""
        logger.info(f"Checking cache for email: {company_name}")
        return self.session_state.get("generated_emails", {}).get(company_name)

    def cache_email(self, company_name: str, email_content: str):
        """Cache generated email content"""
        logger.info(f"Caching email for: {company_name}")
        self.session_state.setdefault("generated_emails", {})
        self.session_state["generated_emails"][company_name] = email_content
        self.write_to_storage()

    def run(
        self,
        use_research_cache: bool = True,
        use_email_cache: bool = True,
    ) -> Iterator[RunResponse]:
        """
        Orchestrates the entire personalized marketing workflow:

        1. Looks up or retrieves from cache the company's data.
        2. If uncached, uses the scraper agent to research the company website.
        3. Passes that data to the email_creator agent to generate a targeted email.
        4. Yields the generated email content for review or distribution.
        """
        logger.info("Starting personalized marketing workflow...")

        for company_name, company_info in leads.items():
            try:
                logger.info(f"Processing company: {company_name}")

                # Check email cache first
                if use_email_cache:
                    cached_email = self.get_cached_email(company_name)
                    if cached_email:
                        logger.info(f"Using cached email for {company_name}")
                        yield RunResponse(content=cached_email)
                        continue

                # 1. Research Phase with caching
                company_data = None
                if use_research_cache:
                    company_data = self.get_cached_company_data(company_name)
                    if company_data:
                        logger.info(f"Using cached company data for {company_name}")

                if not company_data:
                    logger.info("Starting company research...")
                    scraper_response = self.scraper.run(
                        json.dumps(company_info, indent=4)
                    )

                    if not scraper_response or not scraper_response.content:
                        logger.warning(
                            f"No data returned for {company_name}. Skipping."
                        )
                        continue

                    company_data = scraper_response.content
                    if not isinstance(company_data, CompanyInfo):
                        logger.error(
                            f"Invalid data format for {company_name}. Skipping."
                        )
                        continue

                    # Cache the research results
                    self.cache_company_data(company_name, company_data)

                # 2. Generate email
                logger.info("Generating personalized email...")
                email_context = json.dumps(
                    {
                        "contact_name": company_info.get(
                            "contact_name", "Decision Maker"
                        ),
                        "position": company_info.get("position", "Leader"),
                        "company_info": company_data.model_dump(),
                        "recipient_email": sender_details_dict["email"],
                        "sender_details": sender_details_dict,
                    },
                    indent=4,
                )
                yield from self.email_creator.run(
                    f"Generate a personalized email using this context:\n{email_context}",
                    stream=True,
                )

                # Cache the generated email content
                self.cache_email(company_name, self.email_creator.run_response.content)

                # Obtain final email content:
                email_content = self.email_creator.run_response.content

                # 3. If not in demo mode, you'd handle sending the email here.
                #    Implementation details omitted.
                if not DEMO_MODE:
                    logger.info(
                        "Production mode: Attempting to send email to yourself..."
                    )
                    # Implementation for sending the email goes here.

            except Exception as e:
                logger.error(f"Error processing {company_name}: {e}")
                raise


def main():
    """
    Main entry point for running the personalized email generator workflow.
    """
    try:
        # Create workflow with SQLite storage
        workflow = PersonalisedEmailGenerator(
            session_id="personalized-email-generator",
            storage=SqliteWorkflowStorage(
                table_name="personalized_email_workflows",
                db_file="tmp/workflows.db",
            ),
        )

        # Run workflow with caching
        responses = workflow.run(
            use_research_cache=True,
            use_email_cache=False,
        )

        # Process and pretty-print responses
        pprint_run_response(responses, markdown=True)

        logger.info("Workflow completed successfully!")
    except Exception as e:
        logger.error(f"Workflow failed: {e}")
        raise


if __name__ == "__main__":
    main()
```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai exa_py agno
    ```
  </Step>

  <Step title="Run the agent">
    ```bash
    python personalized_email_generator.py
    ```
  </Step>
</Steps>


# Startup Idea Validator



This workflow helps entrepreneurs validate their startup ideas by:

1. Clarifying and refining the core business concept
2. Evaluating originality compared to existing solutions
3. Defining clear mission and objectives
4. Conducting comprehensive market research and analysis

Why is this helpful?

* Get objective feedback on your startup idea before investing resources
* Understand your total addressable market and target segments
* Validate assumptions about market opportunity and competition
* Define clear mission and objectives to guide execution

Example startup ideas to try:

* A marketplace for AI-generated images
* A platform for local farmers to sell their produce directly to consumers
* A mobile app for scheduling and managing doctor appointments

## Code

```python startup_idea_validator.py
import json
from typing import Iterator, Optional

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.storage.workflow.sqlite import SqliteWorkflowStorage
from agno.tools.googlesearch import GoogleSearch
from agno.utils.log import logger
from agno.utils.pprint import pprint_run_response
from agno.workflow import RunEvent, RunResponse, Workflow
from pydantic import BaseModel, Field


class IdeaClarification(BaseModel):
    originality: str = Field(..., description="Originality of the idea.")
    mission: str = Field(..., description="Mission of the company.")
    objectives: str = Field(..., description="Objectives of the company.")


class MarketResearch(BaseModel):
    total_addressable_market: str = Field(
        ..., description="Total addressable market (TAM)."
    )
    serviceable_available_market: str = Field(
        ..., description="Serviceable available market (SAM)."
    )
    serviceable_obtainable_market: str = Field(
        ..., description="Serviceable obtainable market (SOM)."
    )
    target_customer_segments: str = Field(..., description="Target customer segments.")


class StartupIdeaValidator(Workflow):
    idea_clarifier_agent: Agent = Agent(
        model=OpenAIChat(id="gpt-4o-mini"),
        instructions=[
            "Given a user's startup idea, its your goal to refine that idea. ",
            "Evaluates the originality of the idea by comparing it with existing concepts. ",
            "Define the mission and objectives of the startup.",
        ],
        add_history_to_messages=True,
        add_datetime_to_instructions=True,
        response_model=IdeaClarification,
        structured_outputs=True,
        debug_mode=False,
    )

    market_research_agent: Agent = Agent(
        model=OpenAIChat(id="gpt-4o-mini"),
        tools=[GoogleSearch()],
        instructions=[
            "You are provided with a startup idea and the company's mission and objectives. ",
            "Estimate the total addressable market (TAM), serviceable available market (SAM), and serviceable obtainable market (SOM). ",
            "Define target customer segments and their characteristics. ",
            "Search the web for resources if you need to.",
        ],
        add_history_to_messages=True,
        add_datetime_to_instructions=True,
        response_model=MarketResearch,
        structured_outputs=True,
        debug_mode=False,
    )

    competitor_analysis_agent: Agent = Agent(
        model=OpenAIChat(id="gpt-4o-mini"),
        tools=[GoogleSearch()],
        instructions=[
            "You are provided with a startup idea and some market research related to the idea. ",
            "Identify existing competitors in the market. ",
            "Perform Strengths, Weaknesses, Opportunities, and Threats (SWOT) analysis for each competitor. ",
            "Assess the startup’s potential positioning relative to competitors.",
        ],
        add_history_to_messages=True,
        add_datetime_to_instructions=True,
        markdown=True,
        debug_mode=False,
    )

    report_agent: Agent = Agent(
        model=OpenAIChat(id="gpt-4o-mini"),
        instructions=[
            "You are provided with a startup idea and other data about the idea. ",
            "Summarise everything into a single report.",
        ],
        add_history_to_messages=True,
        add_datetime_to_instructions=True,
        markdown=True,
        debug_mode=False,
    )

    def get_idea_clarification(self, startup_idea: str) -> Optional[IdeaClarification]:
        try:
            response: RunResponse = self.idea_clarifier_agent.run(startup_idea)

            # Check if we got a valid response
            if not response or not response.content:
                logger.warning("Empty Idea Clarification response")
            # Check if the response is of the expected type
            if not isinstance(response.content, IdeaClarification):
                logger.warning("Invalid response type")

            return response.content

        except Exception as e:
            logger.warning(f"Failed: {str(e)}")

        return None

    def get_market_research(
        self, startup_idea: str, idea_clarification: IdeaClarification
    ) -> Optional[MarketResearch]:
        agent_input = {"startup_idea": startup_idea, **idea_clarification.model_dump()}

        try:
            response: RunResponse = self.market_research_agent.run(
                json.dumps(agent_input, indent=4)
            )

            # Check if we got a valid response
            if not response or not response.content:
                logger.warning("Empty Market Research response")

            # Check if the response is of the expected type
            if not isinstance(response.content, MarketResearch):
                logger.warning("Invalid response type")

            return response.content

        except Exception as e:
            logger.warning(f"Failed: {str(e)}")

        return None

    def get_competitor_analysis(
        self, startup_idea: str, market_research: MarketResearch
    ) -> Optional[str]:
        agent_input = {"startup_idea": startup_idea, **market_research.model_dump()}

        try:
            response: RunResponse = self.competitor_analysis_agent.run(
                json.dumps(agent_input, indent=4)
            )

            # Check if we got a valid response
            if not response or not response.content:
                logger.warning("Empty Competitor Analysis response")

            return response.content

        except Exception as e:
            logger.warning(f"Failed: {str(e)}")

        return None

    def run(self, startup_idea: str) -> Iterator[RunResponse]:
        logger.info(f"Generating a startup validation report for: {startup_idea}")

        # Clarify and quantify the idea
        idea_clarification: Optional[IdeaClarification] = self.get_idea_clarification(
            startup_idea
        )

        if idea_clarification is None:
            yield RunResponse(
                event=RunEvent.workflow_completed,
                content=f"Sorry, could not even clarify the idea: {startup_idea}",
            )
            return

        # Do some market research
        market_research: Optional[MarketResearch] = self.get_market_research(
            startup_idea, idea_clarification
        )

        if market_research is None:
            yield RunResponse(
                event=RunEvent.workflow_completed,
                content="Market research failed",
            )
            return

        competitor_analysis: Optional[str] = self.get_competitor_analysis(
            startup_idea, market_research
        )

        # Compile the final report
        final_response: RunResponse = self.report_agent.run(
            json.dumps(
                {
                    "startup_idea": startup_idea,
                    **idea_clarification.model_dump(),
                    **market_research.model_dump(),
                    "competitor_analysis_report": competitor_analysis,
                },
                indent=4,
            )
        )

        yield RunResponse(
            content=final_response.content, event=RunEvent.workflow_completed
        )


# Run the workflow if the script is executed directly
if __name__ == "__main__":
    from rich.prompt import Prompt

    # Get idea from user
    idea = Prompt.ask(
        "[bold]What is your startup idea?[/bold]\n✨",
        default="A marketplace for Christmas Ornaments made from leather",
    )

    # Convert the idea to a URL-safe string for use in session_id
    url_safe_idea = idea.lower().replace(" ", "-")

    startup_idea_validator = StartupIdeaValidator(
        description="Startup Idea Validator",
        session_id=f"validate-startup-idea-{url_safe_idea}",
        storage=SqliteWorkflowStorage(
            table_name="validate_startup_ideas_workflow",
            db_file="tmp/workflows.db",
        ),
        debug_mode=True,
    )

    final_report: Iterator[RunResponse] = startup_idea_validator.run(startup_idea=idea)

    pprint_run_response(final_report, markdown=True)

```

## Usage

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="Install libraries">
    ```bash
    pip install openai agno
    ```
  </Step>

  <Step title="Run the workflow">
    ```bash
    python startup_idea_validator.py
    ```
  </Step>
</Steps>


# Command line authentication



If you run `ag auth` and you get the error: `CLI authentication failed` or your CLI gets stuck on

```
Waiting for a response from browser...
```

It means that your CLI was not able to authenticate with your Agno account on [app.agno.com](https://app.agno.com)

The quickest fix for this is to export your `AGNO_API_KEY` environment variable. You can do this by running the following command:

```bash
export AGNO_API_KEY=<your_api_key>
```

Your API key can be found on [app.agno.com](https://app.agno.com) in the sidebar under `API Key`.

<img src="https://mintlify.s3.us-west-1.amazonaws.com/agno/images/cli-faq.png" alt="agno-api-key" width={600} />

Reason for CLI authentication failure:

* Some browsers like Safari and Brave block connection to the localhost domain. Browsers like Chrome work great with `ag setup`.


# Connecting to Tableplus



If you want to inspect your pgvector container to explore your storage or knowledge base, you can use TablePlus. Follow these steps:

## Step 1: Start Your `pgvector` Container

Run the following command to start a `pgvector` container locally:

```bash
docker run -d \
  -e POSTGRES_DB=ai \
  -e POSTGRES_USER=ai \
  -e POSTGRES_PASSWORD=ai \
  -e PGDATA=/var/lib/postgresql/data/pgdata \
  -v pgvolume:/var/lib/postgresql/data \
  -p 5532:5432 \
  --name pgvector \
  agno/pgvector:16
```

* `POSTGRES_DB=ai` sets the default database name.
* `POSTGRES_USER=ai` and `POSTGRES_PASSWORD=ai` define the database credentials.
* The container exposes port `5432` (mapped to `5532` on your local machine).

## Step 2: Configure TablePlus

1. **Open TablePlus**: Launch the TablePlus application.
2. **Create a New Connection**: Click on the `+` icon to add a new connection.
3. **Select `PostgreSQL`**: Choose PostgreSQL as the database type.

Fill in the following connection details:

* **Host**: `localhost`
* **Port**: `5532`
* **Database**: `ai`
* **User**: `ai`
* **Password**: `ai`

<img src="https://mintlify.s3.us-west-1.amazonaws.com/agno/images/tableplus.png" />


# Could Not Connect To Docker



If you have Docker up and running and get the following error, please read on:

```bash
ERROR    Could not connect to docker. Please confirm docker is installed and running
ERROR    Error while fetching server API version: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))
```

## Quick fix

Create the `/var/run/docker.sock` symlink using:

```shell
sudo ln -s "$HOME/.docker/run/docker.sock" /var/run/docker.sock
```

In 99% of the cases, this should work. If it doesnt, try:

```shell
sudo chown $USER /var/run/docker.sock
```

## Full details

Agno uses [docker-py](https://github.com/docker/docker-py) to run containers, and if the `/var/run/docker.sock` is missing or has incorrect permissions, it cannot connect to docker.

**To fix, please create the `/var/run/docker.sock` file using:**

```shell
sudo ln -s "$HOME/.docker/run/docker.sock" /var/run/docker.sock
```

If that does not work, check the permissions using `ls -l /var/run/docker.sock`.

If the `/var/run/docker.sock` does not exist, check if the `$HOME/.docker/run/docker.sock` file is missing. If its missing, please reinstall Docker.

**If none of this works and the `/var/run/docker.sock` exists:**

* Give your user permissions to the `/var/run/docker.sock` file:

```shell
sudo chown $USER /var/run/docker.sock
```

* Give your user permissions to the docker group:

```shell
sudo usermod -a -G docker $USER
```

## More info

* [Docker-py Issue](https://github.com/docker/docker-py/issues/3059#issuecomment-1294369344)
* [Stackoverflow answer](https://stackoverflow.com/questions/48568172/docker-sock-permission-denied/56592277#56592277)


# Setting Environment Variables



To configure your environment for applications, you may need to set environment variables. This guide provides instructions for setting environment variables in both macOS (Shell) and Windows (PowerShell and Windows Command Prompt).

## macOS

### Setting Environment Variables in Shell

#### Temporary Environment Variables

These environment variables will only be available in the current shell session.

```shell
export VARIABLE_NAME="value"
```

To display the environment variable:

```shell
echo $VARIABLE_NAME
```

#### Permanent Environment Variables

To make environment variables persist across sessions, add them to your shell configuration file (e.g., `.bashrc`, `.bash_profile`, `.zshrc`).

For Zsh:

```shell
echo 'export VARIABLE_NAME="value"' >> ~/.zshrc
source ~/.zshrc
```

To display the environment variable:

```shell
echo $VARIABLE_NAME
```

## Windows

### Setting Environment Variables in PowerShell

#### Temporary Environment Variables

These environment variables will only be available in the current PowerShell session.

```powershell
$env:VARIABLE_NAME = "value"
```

To display the environment variable:

```powershell
echo $env:VARIABLE_NAME
```

#### Permanent Environment Variables

To make environment variables persist across sessions, add them to your PowerShell profile script (e.g., `Microsoft.PowerShell_profile.ps1`).

```powershell
notepad $PROFILE
```

Add the following line to the profile script:

```powershell
$env:VARIABLE_NAME = "value"
```

Save and close the file, then reload the profile:

```powershell
. $PROFILE
```

To display the environment variable:

```powershell
echo $env:VARIABLE_NAME
```

### Setting Environment Variables in Windows Command Prompt

#### Temporary Environment Variables

These environment variables will only be available in the current Command Prompt session.

```cmd
set VARIABLE_NAME=value
```

To display the environment variable:

```cmd
echo %VARIABLE_NAME%
```

#### Permanent Environment Variables

To make environment variables persist across sessions, you can use the `setx` command:

```cmd
setx VARIABLE_NAME "value"
```

Note: After setting an environment variable using `setx`, you need to restart the Command Prompt or any applications that need to read the new environment variable.

To display the environment variable in a new Command Prompt session:

```cmd
echo %VARIABLE_NAME%
```

By following these steps, you can effectively set and display environment variables in macOS Shell, Windows Command Prompt, and PowerShell. This will ensure your environment is properly configured for your applications.


# OpenAI Key Request While Using Other Models



If you see a request for an OpenAI API key but haven't explicitly configured OpenAI, it's because Agno uses OpenAI models by default in several places, including:

* The default model when unspecified in `Agent`
* The default embedder is OpenAIEmbedder with VectorDBs, unless specified

## Quick fix: Configure a Different Model

It is best to specify the model for the agent explicitly, otherwise it would default to `OpenAIChat`.

For example, to use Google's Gemini instead of OpenAI:

```python
from agno.agent import Agent, RunResponse
from agno.models.google import Gemini

agent = Agent(
    model=Gemini(id="gemini-1.5-flash"),
    markdown=True,
)

# Print the response in the terminal
agent.print_response("Share a 2 sentence horror story.")
```

For more details on configuring different model providers, check our [models documentation](../models/)

## Quick fix: Configure a Different Embedder

The same applies to embeddings. If you want to use a different embedder instead of `OpenAIEmbedder`, configure it explicitly.

For example, to use Google's Gemini as an embedder, use `GeminiEmbedder`:

```python
from agno.agent import AgentKnowledge
from agno.vectordb.pgvector import PgVector
from agno.embedder.google import GeminiEmbedder

# Embed sentence in database
embeddings = GeminiEmbedder().get_embedding("The quick brown fox jumps over the lazy dog.")

# Print the embeddings and their dimensions
print(f"Embeddings: {embeddings[:5]}")
print(f"Dimensions: {len(embeddings)}")

# Use an embedder in a knowledge base
knowledge_base = AgentKnowledge(
    vector_db=PgVector(
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        table_name="gemini_embeddings",
        embedder=GeminiEmbedder(),
    ),
    num_documents=2,
)
```

For more details on configuring different model providers, check our [Embeddings documentation](../embedder/)


# Tokens-per-minute rate limiting



![Chat with pdf](https://mintlify.s3.us-west-1.amazonaws.com/agno/images/tpm_issues.png)

If you face any problems with proprietary models (like OpenAI models) where you are rate limited, we provide the option to set `exponential_backoff=True` and to change `delay_between_retries` to a value in seconds (defaults to 1 second).

For example:

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    description="You are an enthusiastic news reporter with a flair for storytelling!",
    markdown=True,
    exponential_backoff=True,
    delay_between_retries=2
)
agent.print_response("Tell me about a breaking news story from New York.", stream=True)
```

See our [models documentation](../models/) for specific information about rate limiting.

In the case of OpenAI, they have tier based rate limits. See the [docs](https://platform.openai.com/docs/guides/rate-limits/usage-tiers) for more information.


# Your first Agent



## What are Agents?

Agents are autonomous programs that use language models to achieve tasks. They solve problems by running tools, accessing knowledge and memory to improve responses.

Instead of a rigid binary definition, let's think of Agents in terms of agency and autonomy.

* **Level 0**: Agents with no tools (basic inference tasks).
* **Level 1**: Agents with tools for autonomous task execution.
* **Level 2**: Agents with knowledge, combining memory and reasoning.
* **Level 3**: Teams of agents collaborating on complex workflows.

## Basic Agent

```python basic_agent.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    description="You are an enthusiastic news reporter with a flair for storytelling!",
    markdown=True
)
agent.print_response("Tell me about a breaking news story from New York.", stream=True)
```

To run the agent, install dependencies and export your `OPENAI_API_KEY`.

<Steps>
  <Step title="Setup your virtual environment">
    <CodeGroup>
      ```bash Mac
      python3 -m venv .venv
      source .venv/bin/activate
      ```

      ```bash Windows
      python3 -m venv aienv
      aienv/scripts/activate
      ```
    </CodeGroup>
  </Step>

  <Step title="Install dependencies">
    <CodeGroup>
      ```bash Mac
      pip install -U openai agno
      ```

      ```bash Windows
      pip install -U openai agno
      ```
    </CodeGroup>
  </Step>

  <Step title="Export your OpenAI key">
    <CodeGroup>
      ```bash Mac
      export OPENAI_API_KEY=sk-***
      ```

      ```bash Windows
      setx OPENAI_API_KEY sk-***
      ```
    </CodeGroup>
  </Step>

  <Step title="Run the agent">
    ```shell
    python basic_agent.py
    ```
  </Step>
</Steps>

## Agent with tools

This basic agent will obviously make up a story, lets give it a tool to search the web.

```python agent_with_tools.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    description="You are an enthusiastic news reporter with a flair for storytelling!",
    tools=[DuckDuckGoTools()],
    show_tool_calls=True,
    markdown=True
)
agent.print_response("Tell me about a breaking news story from New York.", stream=True)
```

Install dependencies and run the Agent

<Steps>
  <Step title="Install dependencies">
    <CodeGroup>
      ```bash Mac
      pip install -U duckduckgo-search
      ```

      ```bash Windows
      pip install -U duckduckgo-search
      ```
    </CodeGroup>
  </Step>

  <Step title="Run the agent">
    ```shell
    python agent_with_tools.py
    ```
  </Step>
</Steps>

Now you should see a much more relevant result.

## Agent with knowledge

Agents can store knowledge in a vector database and use it for RAG or dynamic few-shot learning.

**Agno agents use Agentic RAG** by default, which means they will search their knowledge base for the specific information they need to achieve their task.

```python agent_with_knowledge.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.embedder.openai import OpenAIEmbedder
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.lancedb import LanceDb, SearchType

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    description="You are a Thai cuisine expert!",
    instructions=[
        "Search your knowledge base for Thai recipes.",
        "If the question is better suited for the web, search the web to fill in gaps.",
        "Prefer the information in your knowledge base over the web results."
    ],
    knowledge=PDFUrlKnowledgeBase(
        urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
        vector_db=LanceDb(
            uri="tmp/lancedb",
            table_name="recipes",
            search_type=SearchType.hybrid,
            embedder=OpenAIEmbedder(id="text-embedding-3-small"),
        ),
    ),
    tools=[DuckDuckGoTools()],
    show_tool_calls=True,
    markdown=True
)

# Comment out after the knowledge base is loaded
if agent.knowledge is not None:
    agent.knowledge.load()

agent.print_response("How do I make chicken and galangal in coconut milk soup", stream=True)
agent.print_response("What is the history of Thai curry?", stream=True)
```

Install dependencies and run the Agent

<Steps>
  <Step title="Install dependencies">
    <CodeGroup>
      ```bash Mac
      pip install -U lancedb tantivy pypdf duckduckgo-search
      ```

      ```bash Windows
      pip install -U lancedb tantivy pypdf duckduckgo-search
      ```
    </CodeGroup>
  </Step>

  <Step title="Run the agent">
    ```shell
    python agent_with_knowledge.py
    ```
  </Step>
</Steps>

## Multi Agent Teams

Agents work best when they have a singular purpose, a narrow scope and a small number of tools. When the number of tools grows beyond what the language model can handle or the tools belong to different categories, use a team of agents to spread the load.

```python agent_team.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.yfinance import YFinanceTools

web_agent = Agent(
    name="Web Agent",
    role="Search the web for information",
    model=OpenAIChat(id="gpt-4o"),
    tools=[DuckDuckGoTools()],
    instructions="Always include sources",
    show_tool_calls=True,
    markdown=True,
)

finance_agent = Agent(
    name="Finance Agent",
    role="Get financial data",
    model=OpenAIChat(id="gpt-4o"),
    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True)],
    instructions="Use tables to display data",
    show_tool_calls=True,
    markdown=True,
)

agent_team = Agent(
    team=[web_agent, finance_agent],
    model=OpenAIChat(id="gpt-4o"),
    instructions=["Always include sources", "Use tables to display data"],
    show_tool_calls=True,
    markdown=True,
)

agent_team.print_response("What's the market outlook and financial performance of AI semiconductor companies?", stream=True)
```

Install dependencies and run the Agent team

<Steps>
  <Step title="Install dependencies">
    <CodeGroup>
      ```bash Mac
      pip install -U duckduckgo-search yfinance
      ```

      ```bash Windows
      pip install -U duckduckgo-search yfinance
      ```
    </CodeGroup>
  </Step>

  <Step title="Run the agent">
    ```shell
    python agent_team.py
    ```
  </Step>
</Steps>

## Debugging

Want to see the system prompt, user messages and tool calls?

Agno includes a built-in debugger that will print debug logs in the terminal. Set `debug_mode=True` on any agent or set `AGNO_DEBUG=true` in your environment.

```python debugging.py
from agno.agent import Agent

agent = Agent(markdown=True, debug_mode=True)
agent.print_response("Share a 2 sentence horror story")
```

Run the agent to view debug logs in the terminal:

```shell
python debugging.py
```

<img height="200" src="https://mintlify.s3.us-west-1.amazonaws.com/agno/images/debugging.png" style={{ borderRadius: "8px" }} />


# Community



## Building something amazing with Agno?

Share what you're building on [X](https://agno.link/x) or join our [Discord](https://agno.link/discord) to connect with other developers and explore new ideas together.

## Got questions?

Head over to our [community forum](https://agno.link/community) for help and insights from the team.

## Looking for dedicated support?

We've helped many companies turn ideas into production-grade AI products. Here's how we can help you:

1. **Build agents** tailored to your needs.
2. **Integrate your agents** with your products.
3. **Monitor, improve and scale** your AI systems.

[Book a call](https://cal.com/team/agno/intro) with us to get started. Our prices start at **\$16k/month** and we specialize in taking companies from idea to production within 3 months.


# Agent Observability



## Monitoring

Want to monitor and track your Agents?

Agno provides built-in monitoring capabilities that track session and performance metrics through [app.agno.com](https://app.agno.com). To enable monitoring:

1. **Authenticate** (one of these methods):

   * Run `agno setup` in your terminal
   * Export `AGNO_API_KEY=***` in your environment

2. **Enable monitoring** (one of these methods):
   * Set `monitoring=True` when creating an Agent
   * Set `AGNO_MONITOR=true` in your environment

Create a file `monitoring.py` with the following code:

```python monitoring.py
from agno.agent import Agent

agent = Agent(markdown=True, monitoring=True)
agent.print_response("Share a 2 sentence horror story")
```

Run the agent locally and view your sessions at [app.agno.com/sessions](https://app.agno.com/sessions)

<img height="200" src="https://mintlify.s3.us-west-1.amazonaws.com/agno/images/monitoring.png" style={{ borderRadius: "8px" }} />

<Info>Facing issues? Check out our [troubleshooting guide](/faq/cli-auth)</Info>


# Agent Playground

**Agno provides a beautiful Agent UI for interacting with your agents.**

<Frame caption="Agent Playground">
  <img height="200" src="https://mintlify.s3.us-west-1.amazonaws.com/agno/images/agent_playground.png" style={{ borderRadius: '8px' }} />
</Frame>

<Note>
  No data is sent to [agno.com](https://app.agno.com), all agent data is stored locally in your sqlite database.
</Note>

## Running Playground Locally

Let's run the playground application locally so we can chat with our Agents using the Agent UI. Create a file `playground.py`

```python playground.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.playground import Playground, serve_playground_app
from agno.storage.agent.sqlite import SqliteAgentStorage
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.yfinance import YFinanceTools

agent_storage: str = "tmp/agents.db"

web_agent = Agent(
    name="Web Agent",
    model=OpenAIChat(id="gpt-4o"),
    tools=[DuckDuckGoTools()],
    instructions=["Always include sources"],
    # Store the agent sessions in a sqlite database
    storage=SqliteAgentStorage(table_name="web_agent", db_file=agent_storage),
    # Adds the current date and time to the instructions
    add_datetime_to_instructions=True,
    # Adds the history of the conversation to the messages
    add_history_to_messages=True,
    # Number of history responses to add to the messages
    num_history_responses=5,
    # Adds markdown formatting to the messages
    markdown=True,
)

finance_agent = Agent(
    name="Finance Agent",
    model=OpenAIChat(id="gpt-4o"),
    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True, company_news=True)],
    instructions=["Always use tables to display data"],
    storage=SqliteAgentStorage(table_name="finance_agent", db_file=agent_storage),
    add_datetime_to_instructions=True,
    add_history_to_messages=True,
    num_history_responses=5,
    markdown=True,
)

app = Playground(agents=[web_agent, finance_agent]).get_app()

if __name__ == "__main__":
    serve_playground_app("playground:app", reload=True)
```

<Tip>Make sure the `serve_playground_app()` points to the file that contains your `Playground` app.</Tip>

## Authenticate with Agno

Authenticate with agno.com so your local application can let agno know that you are running a playground application. Run:

<Note>
  No data is sent to agno.com, only that you're running a playground application at port 7777.
</Note>

```shell
ag setup
```

\[or] export your `AGNO_API_KEY` from [app.agno.com](https://app.agno.com)

<CodeGroup>
  ```bash Mac
  export AGNO_API_KEY=ag-***
  ```

  ```bash Windows
  setx AGNO_API_KEY ag-***
  ```
</CodeGroup>

## Run the playground app

Install dependencies and run your playground application:

```shell
pip install openai duckduckgo-search yfinance sqlalchemy 'fastapi[standard]' agno

python playground.py
```

## View the playground

* Open the link provided or navigate to `http://app.agno.com/playground` (login required)
* Select the `localhost:7777` endpoint and start chatting with your agents!

<video autoPlay muted controls className="w-full aspect-video" src="https://mintlify.s3.us-west-1.amazonaws.com/agno/images/AgentPlayground.mp4" />


# Contributing to Agno



Agno is an open-source project and we welcome contributions.

## 👩‍💻 How to contribute

Please follow the [fork and pull request](https://docs.github.com/en/get-started/quickstart/contributing-to-projects) workflow:

* Fork the repository.
* Create a new branch for your feature.
* Add your feature or improvement.
* Send a pull request.
* We appreciate your support & input!

## Development setup

1. Clone the repository.
2. Create a virtual environment:
   * For Unix, use `./scripts/dev_setup.sh`.
   * This setup will:
     * Create a `.venv` virtual environment in the current directory.
     * Install the required packages.
     * Install the `agno` package in editable mode.
3. Activate the virtual environment:
   * On Unix: `source .venv/bin/activate`

> From here on you have to use `uv pip install` to install missing packages

## Formatting and validation

Ensure your code meets our quality standards by running the appropriate formatting and validation script before submitting a pull request:

* For Unix:
  * `./scripts/format.sh`
  * `./scripts/validate.sh`

These scripts will perform code formatting with `ruff` and static type checks with `mypy`.

Read more about the guidelines [here](https://github.com/agno-agi/agno/tree/main/cookbook/CONTRIBUTING.md)

Message us on [Discord](https://discord.gg/4MtYHHrgA8) or post on [Discourse](https://community.agno.com/) if you have any questions or need help with credits.


# Install & Setup



## Install agno

We highly recommend:

* Installing `agno` using `pip` in a python virtual environment.

<Steps>
  <Step title="Create a virtual environment">
    <CodeGroup>
      ```bash Mac
      python3 -m venv ~/.venvs/agno
      source ~/.venvs/agno/bin/activate
      ```

      ```bash Windows
      python3 -m venv agnoenv
      agnoenv/scripts/activate
      ```
    </CodeGroup>
  </Step>

  <Step title="Install agno">
    Install `agno` using pip

    <CodeGroup>
      ```bash Mac
      pip install -U agno
      ```

      ```bash Windows
      pip install -U agno
      ```
    </CodeGroup>
  </Step>
</Steps>

<br />

<Note>
  If you encounter errors, try updating pip using `python -m pip install --upgrade pip`
</Note>

***

## Upgrade agno

To upgrade `agno`, run this in your virtual environment

```bash
pip install -U agno --no-cache-dir
```

***

## Setup Agno

Log-in and connect to agno.com using `ag setup`

```bash
ag setup
```


# Run Local Agent API



This guide will walk you through:

* Creating a minimal FastAPI app with an Agno agent
* Containerizing it with Docker
* Running it locally along with a PostgreSQL database for knowledge and memory

## Setup

<Steps>
  <Step title="Create a new directory for your project">
    Create a new directory for your project and navigate to it. After following this guide, your project structure will should look like this:

    ```shell
    mkdir my-project
    cd my-project
    ```

    After following this guide, your project structure will should look like this:

    ```shell
    my-project/
    ├── main.py
    ├── Dockerfile
    ├── requirements.txt
    ├── docker-compose.yml
    ```
  </Step>

  <Step title="Create a `requirements.txt` file and add the required dependencies:">
    ```txt requirements.txt
    fastapi
    agno
    openai
    pgvector
    pypdf
    psycopg[binary]
    sqlalchemy
    uvicorn
    ```
  </Step>
</Steps>

## Step 1: Create a FastAPI App with an Agno Agent

<Steps>
  <Step title="Create a new Python file, e.g., `main.py`, and add the following code to create a minimal FastAPI app with an Agno agent:">
    ```python main.py
    from fastapi import FastAPI
    from agno.agent import Agent
    from agno.models.openai import OpenAIChat

    app = FastAPI()

    agent = Agent(
        model=OpenAIChat(id="gpt-4o"),
        description="You are a helpful assistant.",
        markdown=True,
    )

    @app.get("/ask")
    async def ask(query: str):
        response = agent.run(query)
        return {"response": response.content}
    ```
  </Step>

  <Step title="Create and activate a virtual environment:">
    ```bash
    python -m venv .venv
    source .venv/bin/activate
    ```
  </Step>

  <Step title="Install the required dependencies by running:">
    ```bash
    pip install -r requirements.txt
    ```
  </Step>

  <Step title="Set your OPENAI_API_KEY environment variable:">
    ```bash
    export OPENAI_API_KEY=your_api_key
    ```
  </Step>

  <Step title="Run the FastAPI app with `uvicorn main:app --reload`.">
    ```bash
    uvicorn main:app --reload
    ```
  </Step>
</Steps>

## Step 2: Create a Dockerfile

<Steps>
  <Step title="In the same directory, create a new file named `Dockerfile` with the following content:">
    ```dockerfile Dockerfile
    FROM agnohq/python:3.12

    WORKDIR /app

    COPY requirements.txt .
    RUN pip install --no-cache-dir -r requirements.txt

    COPY . .

    CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
    ```
  </Step>

  <Step title="Build the Docker image by running:">
    ```bash
    docker build -t my-agent-app .
    ```
  </Step>

  <Step title="Run the Docker container with:">
    ```bash
    docker run -p 8000:8000 -e OPENAI_API_KEY=your_api_key my-agent-app
    ```
  </Step>

  <Step title="Access your app">
    You can now access the FastAPI app at `http://localhost:8000`.
  </Step>
</Steps>

## Step 3: Add Knowledge and Memory with PostgreSQL

<Steps>
  <Step title="Update your `main.py` file to include knowledge and memory storage using PostgreSQL:">
    ```python main.py
    from fastapi import FastAPI
    from agno.agent import Agent
    from agno.models.openai import OpenAIChat
    from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
    from agno.vectordb.pgvector import PgVector
    from agno.storage.agent.postgres import PostgresAgentStorage

    app = FastAPI()

    db_url = "postgresql+psycopg://agno:agno@db/agno"

    knowledge_base = PDFUrlKnowledgeBase(
        urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
        vector_db=PgVector(table_name="recipes", db_url=db_url),
    )
    knowledge_base.load(recreate=True)

    agent = Agent(
        model=OpenAIChat(id="gpt-4o"),
        description="You are a Thai cuisine expert!",
        knowledge=knowledge_base,
        storage=PostgresAgentStorage(table_name="agent_sessions", db_url=db_url),
        markdown=True,
    )

    @app.get("/ask")
    async def ask(query: str):
        response = agent.run(query)
        return {"response": response.content}
    ```
  </Step>

  <Step title="Create a `docker-compose.yml` file in the same directory with the following content:">
    ```yaml docker-compose.yml
    services:
      app:
        build: .
        ports:
          - "8000:8000"
        environment:
          - OPENAI_API_KEY=${OPENAI_API_KEY}
        depends_on:
          db:
            condition: service_healthy

      db:
        image: agnohq/pgvector:16
        environment:
          POSTGRES_DB: agno
          POSTGRES_USER: agno
          POSTGRES_PASSWORD: agno
        volumes:
          - pgdata:/var/lib/postgresql/data
        healthcheck:
          test: ["CMD-SHELL", "pg_isready -U agno"]
          interval: 2s
          timeout: 5s
          retries: 5

    volumes:
      pgdata:
    ```
  </Step>

  <Step title="Run the Docker Compose setup with:">
    ```bash
    docker-compose up --build
    ```

    This will start the FastAPI app and the PostgreSQL database, allowing your agent to use knowledge and memory storage.

    You can now access the FastAPI app at `http://localhost:8000` and interact with your agent that has knowledge and memory capabilities.

    You can test the agent by running `curl http://localhost:8000/ask?query="What is the recipe for pad thai?"`.
  </Step>
</Steps>


# Migrate from Phidata to Agno



This guide helps you migrate your codebase to adapt to the major refactor accompanying the launch of Agno.

## General Namespace Updates

This refactor includes comprehensive updates to namespaces to improve clarity and consistency. Pay close attention to the following changes:

* All `phi` namespaces are now replaced with `agno` to reflect the updated structure.
* Submodules and classes have been renamed to better represent their functionality and context.

## Interface Changes

### Module and Namespace Updates

* **Models**:
  * `phi.model.x` ➔ `agno.models.x`
    * All model classes now reside under the `agno.models` namespace, consolidating related functionality in a single location.
* **Knowledge Bases**:
  * `phi.knowledge_base.x` ➔ `agno.knowledge.x`
    * Knowledge bases have been restructured for better organization under `agno.knowledge`.
* **Document Readers**:
  * `phi.document.reader.xxx` ➔ `agno.document.reader.xxx_reader`
    * Document readers now include a `_reader` suffix for clarity and consistency.
* **Toolkits**:
  * All Agno toolkits now have a `Tools` suffix. For example, `DuckDuckGo` ➔ `DuckDuckGoTools`.
    * This change standardizes the naming of tools, making their purpose more explicit.

### Multi-Modal Interface Updates

The multi-modal interface now uses specific types for different media inputs and outputs:

#### Inputs

* **Images**:
  ```python
  class Image(BaseModel):
      url: Optional[str] = None  # Remote location for image
      filepath: Optional[Union[Path, str]] = None  # Absolute local location for image
      content: Optional[Any] = None  # Actual image bytes content
      detail: Optional[str] = None # Low, medium, high, or auto
      id: Optional[str] = None
  ```
  * Images are now represented by a dedicated `Image` class, providing additional metadata and control over image handling.

* **Audio**:
  ```python
  class Audio(BaseModel):
      filepath: Optional[Union[Path, str]] = None  # Absolute local location for audio
      content: Optional[Any] = None  # Actual audio bytes content
      format: Optional[str] = None
  ```
  * Audio files are handled through the `Audio` class, allowing specification of content and format.

* **Video**:
  ```python
  class Video(BaseModel):
      filepath: Optional[Union[Path, str]] = None  # Absolute local location for video
      content: Optional[Any] = None  # Actual video bytes content
  ```
  * Videos have their own `Video` class, enabling better handling of video data.

#### Outputs

* `RunResponse` now includes updated artifact types:
  * `RunResponse.images` is a list of type `ImageArtifact`:
    ```python
    class ImageArtifact(Media):
        id: str
        url: str  # Remote location for file
        alt_text: Optional[str] = None
    ```

  * `RunResponse.audio` is a list of type `AudioArtifact`:
    ```python
    class AudioArtifact(Media):
        id: str
        url: Optional[str] = None  # Remote location for file
        base64_audio: Optional[str] = None  # Base64-encoded audio data
        length: Optional[str] = None
        mime_type: Optional[str] = None
    ```

  * `RunResponse.videos` is a list of type `VideoArtifact`:
    ```python
    class VideoArtifact(Media):
        id: str
        url: str  # Remote location for file
        eta: Optional[str] = None
        length: Optional[str] = None
    ```

  * `RunResponse.response_audio` is of type `AudioOutput`:
    ```python
    class AudioOutput(BaseModel):
        id: str
        content: str  # Base64 encoded
        expires_at: int
        transcript: str
    ```
    * This response audio corresponds to the model's response in audio format.

### Model Name Changes

* `Hermes` ➔ `OllamaHermes`
* `AzureOpenAIChat` ➔ `AzureOpenAI`
* `CohereChat` ➔ `Cohere`
* `DeepSeekChat` ➔ `DeepSeek`
* `GeminiOpenAIChat` ➔ `GeminiOpenAI`
* `HuggingFaceChat` ➔ `HuggingFace`

For example:

```python
from agno.agent import Agent
from agno.models.ollama.hermes import OllamaHermes

agent = Agent(
    model=OllamaHermes(id="hermes3"),
    description="Share 15 minute healthy recipes.",
    markdown=True,
)
agent.print_response("Share a breakfast recipe.")
```

### Storage Class Updates

* **Agent Storage**:
  * `PgAgentStorage` ➔ `PostgresAgentStorage`
  * `SqlAgentStorage` ➔ `SqliteAgentStorage`
  * `MongoAgentStorage` ➔ `MongoDbAgentStorage`
  * `S2AgentStorage` ➔ `SingleStoreAgentStorage`
* **Workflow Storage**:
  * `SqlWorkflowStorage` ➔ `SqliteWorkflowStorage`
  * `PgWorkflowStorage` ➔ `PostgresWorkflowStorage`
  * `MongoWorkflowStorage` ➔ `MongoDbWorkflowStorage`

### Knowledge Base Updates

* `phi.knowledge.pdf.PDFUrlKnowledgeBase` ➔ `agno.knowledge.pdf_url.PDFUrlKnowledgeBase`
* `phi.knowledge.csv.CSVUrlKnowledgeBase` ➔ `agno.knowledge.csv_url.CSVUrlKnowledgeBase`

### Embedders updates

Embedders now all take id instead of model as a parameter. For example:

* `OllamaEmbedder(model="llama3.2")` -> `OllamaEmbedder(id="llama3.2")`

### Reader Updates

* `phi.document.reader.arxiv` ➔ `agno.document.reader.arxiv_reader`
* `phi.document.reader.docx` ➔ `agno.document.reader.docx_reader`
* `phi.document.reader.json` ➔ `agno.document.reader.json_reader`
* `phi.document.reader.pdf` ➔ `agno.document.reader.pdf_reader`
* `phi.document.reader.s3.pdf` ➔ `agno.document.reader.s3.pdf_reader`
* `phi.document.reader.s3.text` ➔ `agno.document.reader.s3.text_reader`
* `phi.document.reader.text` ➔ `agno.document.reader.text_reader`
* `phi.document.reader.website` ➔ `agno.document.reader.website_reader`

***

Follow the steps above to ensure your codebase is compatible with the latest version of Agno AI. If you encounter any issues, don't hesitate to contact us on [Discourse](https://community.phidata.com/) or [Discord](https://discord.gg/4MtYHHrgA8).


# Welcome to Agno

**Agno is a lightweight framework for building multi-modal Agents.**

## Simple, Fast, and Agnostic

Agno is designed with three core principles:

* **Simplicity**: No graphs, chains, or convoluted patterns -- just pure python.
* **Uncompromising Performance**: Blazing fast agents with a minimal memory footprint.
* **Truly Agnostic**: Any model, any provider, any modality -- future-proof design.

## Key features

Here's why you should build Agents with Agno:

* **Lightning Fast**: Agent creation is 5000x faster than LangGraph (see [performance](https://github.com/agno-agi/agno/tree?tab=readme-ov-file#performance)).
* **Model Agnostic**: Use any model, any provider, no lock-in.
* **Multi Modal**: Native support for text, image, audio and video.
* **Multi Agent**: Delegate tasks across a team of specialized agents.
* **Memory Management**: Store user sessions and agent state in a database.
* **Knowledge Stores**: Use vector databases for Agentic RAG or dynamic few-shot.
* **Structured Outputs**: Make Agents respond with structured data.
* **Monitoring**: Track agent sessions and performance in real-time on [agno.com](https://app.agno.com).

## Get Started

If you're new to Agno, start here to build your first Agent.

<CardGroup cols={3}>
  <Card title="Build your first Agent" icon="user-astronaut" iconType="duotone" href="/get-started/agents">
    Learn how to build Agents with Agno
  </Card>

  <Card title="Agent Playground" icon="comment-dots" iconType="duotone" href="/get-started/playground">
    Chat with your Agents using a beautiful Agent UI
  </Card>

  <Card title="Agent Observability" icon="rocket-launch" iconType="duotone" href="/get-started/monitoring">
    Monitor your Agents on [agno.com](https://app.agno.com)
  </Card>
</CardGroup>

After that, checkout the [Examples Gallery](/examples) to discover real-world applications built with Agno.

## Build with Agno

Agno is a battle-tested framework with best-in-class performance, checkout the following guides to dive-in:

<CardGroup cols={3}>
  <Card title="Agents" icon="user-astronaut" iconType="duotone" href="/agents">
    Learn core Agent concepts
  </Card>

  <Card title="Models" icon="microchip" iconType="duotone" href="/models">
    Use any model, any provider, no lock-in
  </Card>

  <Card title="Tools" icon="screwdriver-wrench" iconType="duotone" href="/tools">
    Use 100s of tools to extend your Agents
  </Card>

  <Card title="Knowledge" icon="brain" iconType="duotone" href="/knowledge">
    Add domain-specific knowledge to your Agents
  </Card>

  <Card title="Vector Databases" icon="spider-web" iconType="duotone" href="/vectordb">
    Add semantic search and retrieval to your Agents
  </Card>

  <Card title="Storage" icon="database" iconType="duotone" href="/storage">
    Persist agent states and conversations in a database
  </Card>

  <Card title="Memory" icon="lightbulb" iconType="duotone" href="/agents/memory">
    Remember user details and session summaries
  </Card>

  <Card title="Embeddings" icon="network-wired" iconType="duotone" href="/embedder">
    Generate embeddings for your knowledge base
  </Card>

  <Card title="Workflows" icon="diagram-project" iconType="duotone" href="/workflows">
    Build complex workflows with Agents
  </Card>
</CardGroup>


# ArXiv Knowledge Base



The **ArxivKnowledgeBase** reads Arxiv articles, converts them into vector embeddings and loads them to a vector database.

## Usage

<Note>
  We are using a local PgVector database for this example. [Make sure it's running](https://docs.agno.com/vectordb/pgvector)
</Note>

```shell
pip install arxiv
```

```python knowledge_base.py
from agno.knowledge.arxiv import ArxivKnowledgeBase
from agno.vectordb.pgvector import PgVector

knowledge_base = ArxivKnowledgeBase(
    queries=["Generative AI", "Machine Learning"],
    # Table name: ai.arxiv_documents
    vector_db=PgVector(
        table_name="arxiv_documents",
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
    ),
)
```

Then use the `knowledge_base` with an `Agent`:

```python agent.py
from agno.agent import Agent
from knowledge_base import knowledge_base

agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
)
agent.knowledge.load(recreate=False)

agent.print_response("Ask me about something from the knowledge base")
```

## Params

| Parameter | Type          | Default         | Description                                                                                        |
| --------- | ------------- | --------------- | -------------------------------------------------------------------------------------------------- |
| `queries` | `List[str]`   | `[]`            | Queries to search                                                                                  |
| `reader`  | `ArxivReader` | `ArxivReader()` | A `ArxivReader` that reads the articles and converts them into `Documents` for the vector database |

`ArxivKnowledgeBase` is a subclass of the [AgentKnowledge](/reference/knowledge/base) class and has access to the same params.

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/arxiv_kb.py)


# Combined KnowledgeBase



The **CombinedKnowledgeBase** combines multiple knowledge bases into 1 and is used when your app needs information using multiple sources.

## Usage

<Note>
  We are using a local PgVector database for this example. [Make sure it's running](https://docs.agno.com/vectordb/pgvector)
</Note>

```shell
pip install pypdf bs4
```

```python knowledge_base.py
from agno.knowledge.combined import CombinedKnowledgeBase
from agno.vectordb.pgvector import PgVector
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.knowledge.website import WebsiteKnowledgeBase
from agno.knowledge.pdf import PDFKnowledgeBase


url_pdf_knowledge_base = PDFUrlKnowledgeBase(
    urls=["pdf_url"],
    # Table name: ai.pdf_documents
    vector_db=PgVector(
        table_name="pdf_documents",
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
    ),
)

website_knowledge_base = WebsiteKnowledgeBase(
    urls=["https://docs.agno.com/introduction"],
    # Number of links to follow from the seed URLs
    max_links=10,
    # Table name: ai.website_documents
    vector_db=PgVector(
        table_name="website_documents",
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
    ),
)

local_pdf_knowledge_base = PDFKnowledgeBase(
    path="data/pdfs",
    # Table name: ai.pdf_documents
    vector_db=PgVector(
        table_name="pdf_documents",
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
    ),
    reader=PDFReader(chunk=True),
)

knowledge_base = CombinedKnowledgeBase(
    sources=[
        url_pdf_knowledge_base,
        website_knowledge_base,
        local_pdf_knowledge_base,
    ],
    vector_db=PgVector(
        # Table name: ai.combined_documents
        table_name="combined_documents",
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
    ),
)
```

Then use the `knowledge_base` with an Agent:

```python agent.py
from agno.agent import Agent
from knowledge_base import knowledge_base

agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
)
agent.knowledge.load(recreate=False)

agent.print_response("Ask me about something from the knowledge base")
```

## Params

| Parameter | Type                   | Default | Description              |
| --------- | ---------------------- | ------- | ------------------------ |
| `sources` | `List[AgentKnowledge]` | `[]`    | List of knowledge bases. |

`CombinedKnowledgeBase` is a subclass of the [AgentKnowledge](/reference/knowledge/base) class and has access to the same params.

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/combined_kb.py)


# CSV Knowledge Base



The **CSVKnowledgeBase** reads **local CSV** files, converts them into vector embeddings and loads them to a vector database.

## Usage

<Note>
  We are using a local PgVector database for this example. [Make sure it's running](https://docs.agno.com/vectordb/pgvector)
</Note>

```python
from agno.knowledge.csv import CSVKnowledgeBase
from agno.vectordb.pgvector import PgVector

knowledge_base = CSVKnowledgeBase(
    path="data/csv",
    # Table name: ai.csv_documents
    vector_db=PgVector(
        table_name="csv_documents",
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
    ),
)
```

Then use the `knowledge_base` with an `Agent`:

```python
from agno.agent import Agent
from knowledge_base import knowledge_base

agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
)
agent.knowledge.load(recreate=False)

agent.print_response("Ask me about something from the knowledge base")
```

## Params

| Parameter | Type               | Default       | Description                                                                                    |
| --------- | ------------------ | ------------- | ---------------------------------------------------------------------------------------------- |
| `path`    | `Union[str, Path]` | -             | Path to the CSV file                                                                           |
| `reader`  | `CSVReader`        | `CSVReader()` | A `CSVReader` that reads the CSV file and converts it into `Documents` for the vector database |

`CSVKnowledgeBase` is a subclass of the [AgentKnowledge](/reference/knowledge/base) class and has access to the same params.

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/csv_kb.py)


# CSV URL Knowledge Base



The **CSVUrlKnowledgeBase** reads **CSVs from urls**, converts them into vector embeddings and loads them to a vector database.

## Usage

<Note>
  We are using a local PgVector database for this example. [Make sure it's running](https://docs.agno.com/vectordb/pgvector)
</Note>

```python knowledge_base.py
from agno.knowledge.csv_url import CSVUrlKnowledgeBase
from agno.vectordb.pgvector import PgVector

knowledge_base = CSVUrlKnowledgeBase(
    urls=["csv_url"],
    # Table name: ai.csv_documents
    vector_db=PgVector(
        table_name="csv_documents",
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
    ),
)
```

Then use the `knowledge_base` with an Agent:

```python agent.py
from agno.agent import Agent
from knowledge_base import knowledge_base

agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
)
agent.knowledge.load(recreate=False)

agent.print_response("Ask me about something from the knowledge base")
```

## Params

| Parameter | Type           | Default          | Description                                                                                                    |
| --------- | -------------- | ---------------- | -------------------------------------------------------------------------------------------------------------- |
| `urls`    | `List[str]`    | -                | URLs for `PDF` files.                                                                                          |
| `reader`  | `CSVUrlReader` | `CSVUrlReader()` | A `CSVUrlReader` that reads the CSV file from the URL and converts it into `Documents` for the vector database |

`CSVUrlKnowledgeBase` is a subclass of the [AgentKnowledge](/reference/knowledge/base) class and has access to the same params.

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/csv_url_kb.py)


# Document Knowledge Base



The **DocumentKnowledgeBase** reads **local docs** files, converts them into vector embeddings and loads them to a vector database.

## Usage

<Note>
  We are using a local PgVector database for this example. [Make sure it's running](https://docs.agno.com/vectordb/pgvector)
</Note>

```shell
pip install textract
```

```python
from agno.knowledge.document import DocumentKnowledgeBase
from agno.vectordb.pgvector import PgVector

knowledge_base = DocumentKnowledgeBase(
    path="data/docs",
    # Table name: ai.documents
    vector_db=PgVector(
        table_name="documents",
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
    ),
)
```

Then use the `knowledge_base` with an `Agent`:

```python
from agno.agent import Agent
from knowledge_base import knowledge_base

agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
)
agent.knowledge.load(recreate=False)

agent.print_response("Ask me about something from the knowledge base")
```

## Params

| Parameter   | Type             | Default | Description                                               |
| ----------- | ---------------- | ------- | --------------------------------------------------------- |
| `documents` | `List[Document]` | -       | List of Document objects to be used as the knowledge base |

`DocumentKnowledgeBase` is a subclass of the [AgentKnowledge](/reference/knowledge/base) class and has access to the same params.

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/doc_kb.py)


# Docx Knowledge Base



The **DocxKnowledgeBase** reads **local docx** files, converts them into vector embeddings and loads them to a vector database.

## Usage

<Note>
  We are using a local PgVector database for this example. [Make sure it's running](https://docs.agno.com/vectordb/pgvector)
</Note>

```shell
pip install textract
```

```python
from agno.knowledge.docx import DocxKnowledgeBase
from agno.vectordb.pgvector import PgVector

knowledge_base = DocxKnowledgeBase(
    path="data/docs",
    # Table name: ai.docx_documents
    vector_db=PgVector(
        table_name="docx_documents",
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
    ),
)
```

Then use the `knowledge_base` with an `Agent`:

```python
from agno.agent import Agent
from knowledge_base import knowledge_base

agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
)
agent.knowledge.load(recreate=False)

agent.print_response("Ask me about something from the knowledge base")
```

## Params

| Parameter | Type               | Default             | Description                                                                           |
| --------- | ------------------ | ------------------- | ------------------------------------------------------------------------------------- |
| `path`    | `Union[str, Path]` | -                   | Path to text files. Can point to a single docx file or a directory of docx files.     |
| `formats` | `List[str]`        | `[".doc", ".docx"]` | Formats accepted by this knowledge base.                                              |
| `reader`  | `DocxReader`       | `DocxReader()`      | A `DocxReader` that converts the docx files into `Documents` for the vector database. |

`DocxKnowledgeBase` is a subclass of the [AgentKnowledge](/reference/knowledge/base) class and has access to the same params.

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/docx_kb.py)


# Introduction



A **knowledge base** is a database of information that an agent can search to improve its responses. This information is stored in a vector database and provides agents with business context, helping them respond in a context-aware manner. The general syntax is:

```python
from agno.agent import Agent, AgentKnowledge

# Create a knowledge base for the Agent
knowledge_base = AgentKnowledge(vector_db=...)

# Add information to the knowledge base
knowledge_base.load_text("The sky is blue")

# Add the knowledge base to the Agent and
# give it a tool to search the knowledge base as needed
agent = Agent(knowledge=knowledge_base, search_knowledge=True)
```

## Vector Databases

While any type of storage can act as a knowledge base, vector databases offer the best solution for retrieving relevant results from dense information quickly. Here's how vector databases are used with Agents:

<Steps>
  <Step title="Chunk the information">
    Break down the knowledge into smaller chunks to ensure our search query
    returns only relevant results.
  </Step>

  <Step title="Load the knowledge base">
    Convert the chunks into embedding vectors and store them in a vector
    database.
  </Step>

  <Step title="Search the knowledge base">
    When the user sends a message, we convert the input message into an
    embedding and "search" for nearest neighbors in the vector database.
  </Step>
</Steps>

## Loading the Knowledge Base

Before you can use a knowledge base, it needs to be loaded with embeddings that will be used for retrieval. Use one of the following knowledge bases to simplify the chunking, loading, searching and optimization process:

* [ArXiv knowledge base](/knowledge/arxiv): Load ArXiv papers to a knowledge base
* [Combined knowledge base](/knowledge/combined): Combine multiple knowledge bases into 1
* [CSV knowledge base](/knowledge/csv): Load local CSV files to a knowledge base
* [CSV URL knowledge base](/knowledge/csv-url): Load CSV files from a URL to a knowledge base
* [Document knowledge base](/knowledge/document): Load local docx files to a knowledge base
* [JSON knowledge base](/knowledge/json): Load JSON files to a knowledge base
* [LangChain knowledge base](/knowledge/langchain): Use a Langchain retriever as a knowledge base
* [PDF knowledge base](/knowledge/pdf): Load local PDF files to a knowledge base
* [PDF URL knowledge base](/knowledge/pdf-url): Load PDF files from a URL to a knowledge base
* [S3 PDF knowledge base](/knowledge/s3_pdf): Load PDF files from S3 to a knowledge base
* [S3 Text knowledge base](/knowledge/s3_text): Load text files from S3 to a knowledge base
* [Text knowledge base](/knowledge/text): Load text/docx files to a knowledge base
* [Website knowledge base](/knowledge/website): Load website data to a knowledge base
* [Wikipedia knowledge base](/knowledge/wikipedia): Load wikipedia articles to a knowledge base


# JSON Knowledge Base



The **JSONKnowledgeBase** reads **local JSON** files, converts them into vector embeddings and loads them to a vector database.

## Usage

<Note>
  We are using a local PgVector database for this example. [Make sure it's running](https://docs.agno.com/vectordb/pgvector)
</Note>

```python knowledge_base.py
from agno.knowledge.json import JSONKnowledgeBase
from agno.vectordb.pgvector import PgVector

knowledge_base = JSONKnowledgeBase(
    path="data/json",
    # Table name: ai.json_documents
    vector_db=PgVector(
        table_name="json_documents",
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
    ),
)
```

Then use the `knowledge_base` with an `Agent`:

```python agent.py
from agno.agent import Agent
from knowledge_base import knowledge_base

agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
)
agent.knowledge.load(recreate=False)

agent.print_response("Ask me about something from the knowledge base")
```

## Params

| Parameter | Type               | Default        | Description                                                                              |
| --------- | ------------------ | -------------- | ---------------------------------------------------------------------------------------- |
| `path`    | `Union[str, Path]` | -              | Path to `JSON` files.<br />Can point to a single JSON file or a directory of JSON files. |
| `reader`  | `JSONReader`       | `JSONReader()` | A `JSONReader` that converts the `JSON` files into `Documents` for the vector database.  |

`JSONKnowledgeBase` is a subclass of the [AgentKnowledge](/reference/knowledge/base) class and has access to the same params.

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/json_kb.py)


# LangChain Knowledge Base



The **LangchainKnowledgeBase** allows us to use a LangChain retriever or vector store as a knowledge base.

## Usage

```shell
pip install langchain
```

```python langchain_kb.py
from agno.agent import Agent
from agno.knowledge.langchain import LangChainKnowledgeBase

from langchain.embeddings import OpenAIEmbeddings
from langchain.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import Chroma

chroma_db_dir = "./chroma_db"


def load_vector_store():
    state_of_the_union = ws_settings.ws_root.joinpath("data/demo/state_of_the_union.txt")
    # -*- Load the document
    raw_documents = TextLoader(str(state_of_the_union)).load()
    # -*- Split it into chunks
    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
    documents = text_splitter.split_documents(raw_documents)
    # -*- Embed each chunk and load it into the vector store
    Chroma.from_documents(documents, OpenAIEmbeddings(), persist_directory=str(chroma_db_dir))


# -*- Get the vectordb
db = Chroma(embedding_function=OpenAIEmbeddings(), persist_directory=str(chroma_db_dir))
# -*- Create a retriever from the vector store
retriever = db.as_retriever()

# -*- Create a knowledge base from the vector store
knowledge_base = LangChainKnowledgeBase(retriever=retriever)

agent = Agent(knowledge_base=knowledge_base, add_references_to_prompt=True)
conv.print_response("What did the president say about technology?")
```

## Params

| Parameter       | Type                 | Default | Description                                                               |
| --------------- | -------------------- | ------- | ------------------------------------------------------------------------- |
| `loader`        | `Optional[Callable]` | `None`  | LangChain loader.                                                         |
| `vectorstore`   | `Optional[Any]`      | `None`  | LangChain vector store used to create a retriever.                        |
| `search_kwargs` | `Optional[dict]`     | `None`  | Search kwargs when creating a retriever using the langchain vector store. |
| `retriever`     | `Optional[Any]`      | `None`  | LangChain retriever.                                                      |

`LangChainKnowledgeBase` is a subclass of the [AgentKnowledge](/reference/knowledge/base) class and has access to the same params.

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/langchain_kb.py)


# LlamaIndex Knowledge Base



The **LlamaIndexKnowledgeBase** allows us to use a LlamaIndex retriever or vector store as a knowledge base.

## Usage

```shell
pip install llama-index-core llama-index-readers-file llama-index-embeddings-openai
```

```python llamaindex_kb.py

from pathlib import Path
from shutil import rmtree

import httpx
from agno.agent import Agent
from agno.knowledge.llamaindex import LlamaIndexKnowledgeBase
from llama_index.core import (
    SimpleDirectoryReader,
    StorageContext,
    VectorStoreIndex,
)
from llama_index.core.retrievers import VectorIndexRetriever
from llama_index.core.node_parser import SentenceSplitter


data_dir = Path(__file__).parent.parent.parent.joinpath("wip", "data", "paul_graham")
if data_dir.is_dir():
    rmtree(path=data_dir, ignore_errors=True)
data_dir.mkdir(parents=True, exist_ok=True)

url = "https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt"
file_path = data_dir.joinpath("paul_graham_essay.txt")
response = httpx.get(url)
if response.status_code == 200:
    with open(file_path, "wb") as file:
        file.write(response.content)
    print(f"File downloaded and saved as {file_path}")
else:
    print("Failed to download the file")


documents = SimpleDirectoryReader(str(data_dir)).load_data()

splitter = SentenceSplitter(chunk_size=1024)

nodes = splitter.get_nodes_from_documents(documents)

storage_context = StorageContext.from_defaults()

index = VectorStoreIndex(nodes=nodes, storage_context=storage_context)

retriever = VectorIndexRetriever(index)

# Create a knowledge base from the vector store
knowledge_base = LlamaIndexKnowledgeBase(retriever=retriever)

# Create an agent with the knowledge base
agent = Agent(knowledge_base=knowledge_base, search_knowledge=True, debug_mode=True, show_tool_calls=True)

# Use the agent to ask a question and print a response.
agent.print_response("Explain what this text means: low end eats the high end", markdown=True)
```

## Params

| Parameter   | Type                 | Default | Description                                                           |
| ----------- | -------------------- | ------- | --------------------------------------------------------------------- |
| `retriever` | `BaseRetriever`      | `None`  | LlamaIndex retriever used for querying the knowledge base.            |
| `loader`    | `Optional[Callable]` | `None`  | Optional callable function to load documents into the knowledge base. |

`LlamaIndexKnowledgeBase` is a subclass of the [AgentKnowledge](/reference/knowledge/base) class and has access to the same params.

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/llamaindex_kb.py)


# PDF Knowledge Base



The **PDFKnowledgeBase** reads **local PDF** files, converts them into vector embeddings and loads them to a vector database.

## Usage

<Note>
  We are using a local PgVector database for this example. [Make sure it's running](https://docs.agno.com/vectordb/pgvector)
</Note>

```shell
pip install pypdf
```

```python knowledge_base.py
from agno.knowledge.pdf import PDFKnowledgeBase, PDFReader
from agno.vectordb.pgvector import PgVector

pdf_knowledge_base = PDFKnowledgeBase(
    path="data/pdfs",
    # Table name: ai.pdf_documents
    vector_db=PgVector(
        table_name="pdf_documents",
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
    ),
    reader=PDFReader(chunk=True),
)
```

Then use the `knowledge_base` with an Agent:

```python agent.py
from agno.agent import Agent
from knowledge_base import knowledge_base

agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
)
agent.knowledge.load(recreate=False)

agent.print_response("Ask me about something from the knowledge base")
```

## Params

| Parameter | Type                               | Default       | Description                                                                                          |
| --------- | ---------------------------------- | ------------- | ---------------------------------------------------------------------------------------------------- |
| `path`    | `Union[str, Path]`                 | -             | Path to `PDF` files. Can point to a single PDF file or a directory of PDF files.                     |
| `reader`  | `Union[PDFReader, PDFImageReader]` | `PDFReader()` | A `PDFReader` or `PDFImageReader` that converts the `PDFs` into `Documents` for the vector database. |

`PDFKnowledgeBase` is a subclass of the [AgentKnowledge](/reference/knowledge/base) class and has access to the same params.

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/pdf_kb.py)


# PDF URL Knowledge Base



The **PDFUrlKnowledgeBase** reads **PDFs from urls**, converts them into vector embeddings and loads them to a vector database.

## Usage

<Note>
  We are using a local PgVector database for this example. [Make sure it's running](https://docs.agno.com/vectordb/pgvector)
</Note>

```shell
pip install pypdf
```

```python knowledge_base.py
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.pgvector import PgVector

knowledge_base = PDFUrlKnowledgeBase(
    urls=["pdf_url"],
    # Table name: ai.pdf_documents
    vector_db=PgVector(
        table_name="pdf_documents",
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
    ),
)
```

Then use the `knowledge_base` with an Agent:

```python agent.py
from agno.agent import Agent
from knowledge_base import knowledge_base

agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
)
agent.knowledge.load(recreate=False)

agent.print_response("Ask me about something from the knowledge base")
```

## Params

| Parameter | Type           | Default | Description                                                                         |
| --------- | -------------- | ------- | ----------------------------------------------------------------------------------- |
| `urls`    | `List[str]`    | -       | URLs for `PDF` files.                                                               |
| `reader`  | `PDFUrlReader` | -       | A `PDFUrlReader` that converts the `PDFs` into `Documents` for the vector database. |

`PDFUrlKnowledgeBase` is a subclass of the [AgentKnowledge](/reference/knowledge/base) class and has access to the same params.

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/pdf_url_kb.py)


# S3 PDF Knowledge Base



The **S3PDFKnowledgeBase** reads **PDF** files from an S3 bucket, converts them into vector embeddings and loads them to a vector database.

## Usage

<Note>
  We are using a local PgVector database for this example. [Make sure it's running](https://docs.agno.com/vectordb/pgvector)
</Note>

```python
from agno.knowledge.s3.pdf import S3PDFKnowledgeBase
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = S3PDFKnowledgeBase(
    bucket_name="agno-public",
    key="recipes/ThaiRecipes.pdf",
    vector_db=PgVector(table_name="recipes", db_url=db_url),
)
```

Then use the `knowledge_base` with an `Agent`:

```python
from agno.agent import Agent
from knowledge_base import knowledge_base

agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
)
agent.knowledge.load(recreate=False)

agent.print_response("How to make Thai curry?")
```

## Params

| Parameter     | Type          | Default         | Description                                                                        |
| ------------- | ------------- | --------------- | ---------------------------------------------------------------------------------- |
| `bucket_name` | `str`         | `None`          | The name of the S3 Bucket where the PDFs are.                                      |
| `key`         | `str`         | `None`          | The key of the PDF file in the bucket.                                             |
| `reader`      | `S3PDFReader` | `S3PDFReader()` | A `S3PDFReader` that converts the `PDFs` into `Documents` for the vector database. |

`S3PDFKnowledgeBase` is a subclass of the [AgentKnowledge](/reference/knowledge/base) class and has access to the same params.

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/s3_pdf_kb.py)


# S3 Text Knowledge Base



The **S3TextKnowledgeBase** reads **text** files from an S3 bucket, converts them into vector embeddings and loads them to a vector database.

## Usage

<Note>
  We are using a local PgVector database for this example. [Make sure it's running](https://docs.agno.com/vectordb/pgvector)
</Note>

```shell
pip install textract
```

```python
from agno.knowledge.s3.text import S3TextKnowledgeBase
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = S3TextKnowledgeBase(
    bucket_name="agno-public",
    key="recipes/recipes.docx",
    vector_db=PgVector(table_name="recipes", db_url=db_url),
)
```

Then use the `knowledge_base` with an `Agent`:

```python
from agno.agent import Agent
from knowledge_base import knowledge_base

agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
)
agent.knowledge.load(recreate=False)

agent.print_response("How to make Hummus?")
```

## Params

| Parameter     | Type           | Default             | Description                                                                               |
| ------------- | -------------- | ------------------- | ----------------------------------------------------------------------------------------- |
| `bucket_name` | `str`          | `None`              | The name of the S3 Bucket where the files are.                                            |
| `key`         | `str`          | `None`              | The key of the file in the bucket.                                                        |
| `formats`     | `List[str]`    | `[".doc", ".docx"]` | Formats accepted by this knowledge base.                                                  |
| `reader`      | `S3TextReader` | `S3TextReader()`    | A `S3TextReader` that converts the `Text` files into `Documents` for the vector database. |

`S3TextKnowledgeBase` is a subclass of the [AgentKnowledge](/reference/knowledge/base) class and has access to the same params.

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/s3_text_kb.py)


# Text Knowledge Base



The **TextKnowledgeBase** reads **local txt** files, converts them into vector embeddings and loads them to a vector database.

## Usage

<Note>
  We are using a local PgVector database for this example. [Make sure it's running](https://docs.agno.com/vectordb/pgvector)
</Note>

```python knowledge_base.py
from agno.knowledge.text import TextKnowledgeBase
from agno.vectordb.pgvector import PgVector

knowledge_base = TextKnowledgeBase(
    path="data/txt_files",
    # Table name: ai.text_documents
    vector_db=PgVector(
        table_name="text_documents",
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
    ),
)
```

Then use the `knowledge_base` with an Agent:

```python agent.py
from agno.agent import Agent
from knowledge_base import knowledge_base

agent = Agent(
    knowledge_base=knowledge_base,
    search_knowledge=True,
)
agent.knowledge.load(recreate=False)

agent.print_response("Ask me about something from the knowledge base")
```

## Params

| Parameter | Type               | Default        | Description                                                                           |
| --------- | ------------------ | -------------- | ------------------------------------------------------------------------------------- |
| `path`    | `Union[str, Path]` | -              | Path to text files. Can point to a single text file or a directory of text files.     |
| `formats` | `List[str]`        | `[".txt"]`     | Formats accepted by this knowledge base.                                              |
| `reader`  | `TextReader`       | `TextReader()` | A `TextReader` that converts the text files into `Documents` for the vector database. |

`TextKnowledgeBase` is a subclass of the [AgentKnowledge](/reference/knowledge/base) class and has access to the same params.

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/text_kb.py)


# Website Knowledge Base



The **WebsiteKnowledgeBase** reads websites, converts them into vector embeddings and loads them to a `vector_db`.

## Usage

<Note>
  We are using a local PgVector database for this example. [Make sure it's running](https://docs.agno.com/vectordb/pgvector)
</Note>

```shell
pip install bs4
```

```python knowledge_base.py
from agno.knowledge.website import WebsiteKnowledgeBase
from agno.vectordb.pgvector import PgVector

knowledge_base = WebsiteKnowledgeBase(
    urls=["https://docs.agno.com/introduction"],
    # Number of links to follow from the seed URLs
    max_links=10,
    # Table name: ai.website_documents
    vector_db=PgVector(
        table_name="website_documents",
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
    ),
)
```

Then use the `knowledge_base` with an `Agent`:

```python agent.py
from agno.agent import Agent
from knowledge_base import knowledge_base

agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
)
agent.knowledge.load(recreate=False)

agent.print_response("Ask me about something from the knowledge base")
```

## Params

| Parameter   | Type                      | Default | Description                                                                                       |
| ----------- | ------------------------- | ------- | ------------------------------------------------------------------------------------------------- |
| `urls`      | `List[str]`               | `[]`    | URLs to read                                                                                      |
| `reader`    | `Optional[WebsiteReader]` | `None`  | A `WebsiteReader` that reads the urls and converts them into `Documents` for the vector database. |
| `max_depth` | `int`                     | `3`     | Maximum depth to crawl.                                                                           |
| `max_links` | `int`                     | `10`    | Number of links to crawl.                                                                         |

`WebsiteKnowledgeBase` is a subclass of the [AgentKnowledge](/reference/knowledge/base) class and has access to the same params.

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/website_kb.py)


# Wikipedia KnowledgeBase



The **WikipediaKnowledgeBase** reads wikipedia topics, converts them into vector embeddings and loads them to a vector database.

## Usage

<Note>
  We are using a local PgVector database for this example. [Make sure it's running](http://localhost:3333/vectordb/pgvector)
</Note>

```shell
pip install wikipedia
```

```python knowledge_base.py
from agno.knowledge.wikipedia import WikipediaKnowledgeBase
from agno.vectordb.pgvector import PgVector

knowledge_base = WikipediaKnowledgeBase(
    topics=["Manchester United", "Real Madrid"],
    # Table name: ai.wikipedia_documents
    vector_db=PgVector(
        table_name="wikipedia_documents",
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
    ),
)
```

Then use the `knowledge_base` with an Agent:

```python agent.py
from agno.agent import Agent
from knowledge_base import knowledge_base

agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
)
agent.knowledge.load(recreate=False)

agent.print_response("Ask me about something from the knowledge base")
```

## Params

| Parameter | Type        | Default | Description    |
| --------- | ----------- | ------- | -------------- |
| `topics`  | `List[str]` | \[]     | Topics to read |

`WikipediaKnowledgeBase` is a subclass of the [AgentKnowledge](/reference/knowledge/base) class and has access to the same params.

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/wikipedia_kb.py)


# Youtube KnowledgeBase



The **YouTubeKnowledgeBase** iterates over a list of Youtube URLs, extracts the video transcripts, converts them into vector embeddings and loads them to a vector database.

## Usage

<Note>
  We are using a local PgVector database for this example. [Make sure it's running](http://localhost:3333/vectordb/pgvector)
</Note>

```shell
pip install bs4
```

```python knowledge_base.py
from agno.knowledge.youtube import YouTubeKnowledgeBase
from agno.vectordb.pgvector import PgVector

knowledge_base = YouTubeKnowledgeBase(
    urls=["https://www.youtube.com/watch?v=CDC3GOuJyZ0"],
    # Table name: ai.website_documents
    vector_db=PgVector(
        table_name="youtube_documents",
        db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
    ),
)
```

Then use the `knowledge_base` with an `Agent`:

```python agent.py
from agno.agent import Agent
from knowledge_base import knowledge_base

agent = Agent(
    knowledge=knowledge_base,
    search_knowledge=True,
)
agent.knowledge.load(recreate=False)

agent.print_response("Ask me about something from the knowledge base")
```

## Params

| Parameter | Type                      | Default | Description                                                                                                                    |
| --------- | ------------------------- | ------- | ------------------------------------------------------------------------------------------------------------------------------ |
| `urls`    | `List[str]`               | `[]`    | URLs of the videos to read                                                                                                     |
| `reader`  | `Optional[YouTubeReader]` | `None`  | A `YouTubeReader` that reads transcripts of the videos at the urls and converts them into `Documents` for the vector database. |

`YouTubeKnowledgeBase` is a subclass of the [AgentKnowledge](/reference/knowledge/base) class and has access to the same params.

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/youtube_kb.py)


# Anthropic Claude



Claude is a family of foundational AI models by Anthropic that can be used in a variety of applications.
See their model comparisons [here](https://docs.anthropic.com/en/docs/about-claude/models#model-comparison-table).

We recommend experimenting to find the best-suited model for your use-case. Here are some general recommendations:

* `claude-3-5-sonnet-20241022` model is good for most use-cases and supports image input.
* `claude-3-5-haiku-20241022` model is their fastest model.

Anthropic has rate limits on their APIs. See the [docs](https://docs.anthropic.com/en/api/rate-limits#response-headers) for more information.

## Authentication

Set your `ANTHROPIC_API_KEY` environment. You can get one [from Anthropic here](https://console.anthropic.com/settings/keys).

<CodeGroup>
  ```bash Mac
  export ANTHROPIC_API_KEY=***
  ```

  ```bash Windows
  setx ANTHROPIC_API_KEY ***
  ```
</CodeGroup>

## Example

Use `Claude` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent, RunResponse
  from agno.models.anthropic import Claude

  agent = Agent(
      model=Claude(id="claude-3-5-sonnet-20240620"),
      markdown=True
  )

  # Print the response on the terminal
  agent.print_response("Share a 2 sentence horror story.")
  ```
</CodeGroup>

<Note> View more examples [here](../examples/models/anthropic). </Note>

## Params

<Snippet file="model-claude-params.mdx" />

`Claude` is a subclass of the [Model](/reference/models/model) class and has access to the same params.


# AWS Bedrock Claude



Use AWS Bedrock to access the Claude models. Manage your access to models [here](https://us-west-2.console.aws.amazon.com/bedrock/home?region=us-west-2#/models).

See all the AWS Bedrock foundational models [here](https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html).

* For an Anthropic Claude model with generally good performance, look at `anthropic.claude-3-5-sonnet-20241022-v2:0`.
* For an open-source Meta model, consider `meta.llama3-70b-instruct-v1:0`.

## Authentication

Set your `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY` and `AWS_DEFAULT_REGION` environment variables.

Get your keys from [here](https://us-east-1.console.aws.amazon.com/iam/home?region=us-east-1#/home).

<CodeGroup>
  ```bash Mac
  export AWS_ACCESS_KEY_ID=***
  export AWS_SECRET_ACCESS_KEY=***
  export AWS_DEFAULT_REGION=***
  ```

  ```bash Windows
  setx AWS_ACCESS_KEY_ID ***
  setx AWS_SECRET_ACCESS_KEY ***
  setx AWS_DEFAULT_REGION ***
  ```
</CodeGroup>

## Example

Use `AWS BedrockClaude` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent, RunResponse
  from agno.models.aws.claude import Claude

  agent = Agent(
      model=Claude(id="anthropic.claude-3-5-sonnet-20240620-v1:0"),
      markdown=True
  )

  # Print the response on the terminal
  agent.print_response("Share a 2 sentence horror story.")
  ```
</CodeGroup>

<Note> View more examples [here](../examples/models/aws/bedrock-claude). </Note>

## Params

<Snippet file="model-aws-params.mdx" />

`AwsBedrock` is a subclass of the [Model](/reference/models/model) class and has access to the same params.


# Azure OpenAI



Use the best in class GPT models using Azure's OpenAI API. Learn more [here](https://learn.microsoft.com/azure/ai-services/openai/overview).

<Note>At the moment we only support OpenAI models via Azure.</Note>

## Authentication

Navigate to the AzureOpenAI on the [Azure Portal](https://portal.azure.com/) and create a service. Then, using the Azure AI Foundry portal, create a deployment and set your environment variables.

<CodeGroup>
  ```bash Mac
  export AZURE_OPENAI_API_KEY=***
  export AZURE_OPENAI_ENDPOINT=***
  export AZURE_OPENAI_MODEL_NAME=***
  export AZURE_OPENAI_DEPLOYMENT=***
  # Optional:
  # export AZURE_OPENAI_API_VERSION=***
  ```

  ```bash Windows
  setx AZURE_OPENAI_API_KEY ***
  setx AZURE_OPENAI_ENDPOINT ***
  setx AZURE_OPENAI_MODEL_NAME ***
  setx AZURE_OPENAI_DEPLOYMENT ***
  # Optional:
  # setx AZURE_OPENAI_API_VERSION ***
  ```
</CodeGroup>

## Example

Use `AzureOpenAI` with your `Agent`:

<CodeGroup>
  ```python agent.py
  import os
  from typing import Iterator

  from agno.agent import Agent, RunResponse
  from agno.models.azure import AzureOpenAI

  azure_model = AzureOpenAI(
      id=os.getenv("AZURE_OPENAI_MODEL_NAME"),
      api_key=os.getenv("AZURE_OPENAI_API_KEY"),
      azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
      azure_deployment=os.getenv("AZURE_OPENAI_DEPLOYMENT"),
  )

  agent = Agent(
      model=azure_model,
      markdown=True
  )

  # Print the response on the terminal
  agent.print_response("Share a 2 sentence horror story.")
  ```
</CodeGroup>

<Note> View more examples [here](/examples/models/azure/openai). </Note>

## Params

<Snippet file="model-azure-params.mdx" />

`AzureOpenAI` also supports the params of [OpenAI](/reference/models/openai).


# Cohere



Leverage Cohere's powerful command models and more.

[Cohere](https://cohere.com) has a wide range of models and is really good for fine-tuning. See their library of models [here](https://docs.cohere.com/v2/docs/models).

We recommend experimenting to find the best-suited model for your use-case. Here are some general recommendations:

* `command` model is good for most basic use-cases.
* `command-light` model is good for smaller tasks and faster inference.
* `command-r7b-12-2024` model is good with RAG tasks, complex reasoning and multi-step tasks.

Cohere also supports fine-tuning models. Here is a [guide](https://docs.cohere.com/v2/docs/fine-tuning) on how to do it.

Cohere has tier-based rate limits. See the [docs](https://docs.cohere.com/v2/docs/rate-limits) for more information.

## Authentication

Set your `CO_API_KEY` environment variable. Get your key from [here](https://dashboard.cohere.com/api-keys).

<CodeGroup>
  ```bash Mac
  export CO_API_KEY=***
  ```

  ```bash Windows
  setx CO_API_KEY ***
  ```
</CodeGroup>

## Example

Use `Cohere` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent, RunResponse
  from agno.models.cohere import Cohere

  agent = Agent(
      model=Cohere(id="command-r-08-2024"),
      markdown=True
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")

  ```
</CodeGroup>

<Note> View more examples [here](../examples/models/cohere). </Note>

## Params

<Snippet file="model-cohere-params.mdx" />

`Cohere` is a subclass of the [Model](/reference/models/model) class and has access to the same params.


# Compatibility



<Snippet file="compatibility-matrix.mdx" />


# DeepSeek



DeepSeek is a platform for providing endpoints for Large Language models.
See their library of models [here](https://api-docs.deepseek.com/quick_start/pricing).

We recommend experimenting to find the best-suited model for your use-case. Here are some general recommendations:

* `deepseek-chat` model is good for most basic use-cases.
* `deepseek-reasoner` model is good for complex reasoning and multi-step tasks.

DeepSeek does not have rate limits. See their [docs](https://api-docs.deepseek.com/quick_start/rate_limit) for information about how to deal with slower responses during high traffic.

## Authentication

Set your `DEEPSEEK_API_KEY` environment variable. Get your key from [here](https://platform.deepseek.com/api_keys).

<CodeGroup>
  ```bash Mac
  export DEEPSEEK_API_KEY=***
  ```

  ```bash Windows
  setx DEEPSEEK_API_KEY ***
  ```
</CodeGroup>

## Example

Use `DeepSeek` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent, RunResponse
  from agno.models.deepseek import DeepSeek

  agent = Agent(model=DeepSeek(), markdown=True)

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")

  ```
</CodeGroup>

<Note> View more examples [here](../examples/models/deepseek). </Note>

## Params

<Snippet file="model-deepseek-params.mdx" />

`DeepSeek` also supports the params of [OpenAI](/reference/models/openai).


# Fireworks



Fireworks is a platform for providing endpoints for Large Language models.

## Authentication

Set your `FIREWORKS_API_KEY` environment variable. Get your key from [here](https://fireworks.ai/account/api-keys).

<CodeGroup>
  ```bash Mac
  export FIREWORKS_API_KEY=***
  ```

  ```bash Windows
  setx FIREWORKS_API_KEY ***
  ```
</CodeGroup>

## Example

Use `Fireworks` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent, RunResponse
  from agno.models.fireworks import Fireworks

  agent = Agent(
      model=Fireworks(id="accounts/fireworks/models/firefunction-v2"),
      markdown=True
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")

  ```
</CodeGroup>

<Note> View more examples [here](../examples/models/fireworks). </Note>

## Params

<Snippet file="model-fireworks-params.mdx" />

`Fireworks` also supports the params of [OpenAI](/reference/models/openai).


# Gemini - AI Studio



Gemini is a platform for providing endpoints for Large Language models. See more information [here](https://ai.google.dev/aistudio).

We recommend experimenting to find the best-suited model for your use-case. Here are some general recommendations:

* `gemini-1.5-flash` is good for most use-cases.
* `gemini-1.5-flash-8b` is their most cost-effective model.
* `gemini-2.0-flash-exp` is their strongest multi-modal model.

## Authentication

Set your `GOOGLE_API_KEY` environment variable. You can get one [from Google here](https://ai.google.dev/aistudio).

<CodeGroup>
  ```bash Mac
  export GOOGLE_API_KEY=***
  ```

  ```bash Windows
  setx GOOGLE_API_KEY ***
  ```
</CodeGroup>

## Example

Use `Gemini` with your `Agent`:

<CodeGroup>
  ```python agent.py

  from agno.agent import Agent, RunResponse
  from agno.models.google import Gemini

  agent = Agent(
      model=Gemini(id="gemini-1.5-flash"),
      markdown=True,
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")
  ```
</CodeGroup>

<Note> View more examples [here](../examples/models/gemini). </Note>

## Params

<Snippet file="model-google-params.mdx" />

`Gemini` is a subclass of the [Model](/reference/models/model) class and has access to the same params.


# Groq



Groq offers blazing-fast API endpoints for large language models.

See all the Groq supported models [here](https://console.groq.com/docs/models).

* We recommend using `llama-3.3-70b-versatile` for general use
* We recommend `llama-3.1-8b-instant` for a faster result.
* We recommend using `llama-3.2-90b-vision-preview` for image understanding.

#### Multimodal Support

With Groq we support `Image` as input

## Authentication

Set your `GROQ_API_KEY` environment variable. Get your key from [here](https://console.groq.com/keys).

<CodeGroup>
  ```bash Mac
  export GROQ_API_KEY=***
  ```

  ```bash Windows
  setx GROQ_API_KEY ***
  ```
</CodeGroup>

## Example

Use `Groq` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent, RunResponse
  from agno.models.groq import Groq

  agent = Agent(
      model=Groq(id="llama-3.3-70b-versatile"),
      markdown=True
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")

  ```
</CodeGroup>

<Note> View more examples [here](../examples/models/groq). </Note>

## Params

<Snippet file="model-groq-params.mdx" />

`Groq` is a subclass of the [Model](/reference/models/model) class and has access to the same params.


# HuggingFace



Hugging Face provides a wide range of state-of-the-art language models tailored to diverse NLP tasks,
including text generation, summarization, translation, and question answering.
These models are available through the Hugging Face Transformers library and are widely
adopted due to their ease of use, flexibility, and comprehensive documentation.

Explore HuggingFace’s language models [here](https://huggingface.co/docs/text-generation-inference/en/supported_models).

## Authentication

Set your `HF_TOKEN` environment. You can get one [from HuggingFace here](https://huggingface.co/settings/tokens).

<CodeGroup>
  ```bash Mac
  export HF_TOKEN=***
  ```

  ```bash Windows
  setx HF_TOKEN ***
  ```
</CodeGroup>

## Example

Use `HuggingFace` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent, RunResponse
  from agno.models.huggingface import HuggingFace

  agent = Agent(
      model=HuggingFace(
          id="meta-llama/Meta-Llama-3-8B-Instruct",
          max_tokens=4096,
      ),
      markdown=True
  )

  # Print the response on the terminal
  agent.print_response("Share a 2 sentence horror story.")
  ```
</CodeGroup>

<Note> View more examples [here](../examples/models/huggingface). </Note>

## Params

<Snippet file="model-hf-params.mdx" />

`HuggingFace` is a subclass of the [Model](/reference/models/model) class and has access to the same params.


# Introduction



Language Models are machine-learning programs that are trained to understand natural language and code. They provide reasoning and planning capabilities to Agents.

Use any `model` with an Agent like:

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    description="Share 15 minute healthy recipes.",
    markdown=True,
)
agent.print_response("Share a breakfast recipe.", stream=True)
```

## Supported Models

Agno supports the following model providers:

* [OpenAI](/models/openai)
* [Anthropic](/models/anthropic)
* [AWS Bedrock](/models/aws-bedrock)
* [Azure](/models/azure)
* [Cohere](/models/cohere)
* [DeepSeek](/models/deepseek)
* [Fireworks](/models/fireworks)
* [Google](/models/google)
* [Groq](/models/groq)
* [Mistral](/models/mistral)
* [Ollama](/models/ollama)
* [OpenAI Like](/models/openai-like)
* [OpenRouter](/models/openrouter)
* [Sambanova](/models/sambanova)
* [Together](/models/together)
* [VertexAI](/models/vertexai)


# Mistral



Mistral is a platform for providing endpoints for Large Language models.
See their library of models [here](https://docs.mistral.ai/getting-started/models/models_overview/).

We recommend experimenting to find the best-suited model for your use-case. Here are some general recommendations:

* `codestral` model is good for code generation and editing.
* `mistral-large-latest` model is good for most use-cases.
* `open-mistral-nemo` is a free model that is good for most use-cases.
* `pixtral-12b-2409` is a vision model that is good for OCR, transcribing documents, and image comparison. It is not always capable at tool calling.

Mistral has tier-based rate limits. See the [docs](https://docs.mistral.ai/deployment/laplateforme/tier/) for more information.

## Authentication

Set your `MISTRAL_API_KEY` environment variable. Get your key from [here](https://console.mistral.ai/api-keys/).

<CodeGroup>
  ```bash Mac
  export MISTRAL_API_KEY=***
  ```

  ```bash Windows
  setx MISTRAL_API_KEY ***
  ```
</CodeGroup>

## Example

Use `Mistral` with your `Agent`:

<CodeGroup>
  ```python agent.py
  import os

  from agno.agent import Agent, RunResponse
  from agno.models.mistral import MistralChat

  mistral_api_key = os.getenv("MISTRAL_API_KEY")

  agent = Agent(
      model=MistralChat(
          id="mistral-large-latest",
          api_key=mistral_api_key,
      ),
      markdown=True
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")

  ```
</CodeGroup>

<Note> View more examples [here](../examples/models/mistral). </Note>

## Params

<Snippet file="model-mistral-params.mdx" />

`MistralChat` is a subclass of the [Model](/reference/models/model) class and has access to the same params.


# Nvidia



NVIDIA offers a suite of high-performance language models optimized for advanced NLP tasks.
These models are part of the NeMo framework, which provides tools for training, fine-tuning
and deploying state-of-the-art models efficiently. NVIDIA’s language models are designed to
handle large-scale workloads with GPU acceleration for faster inference and training.
We recommend experimenting with NVIDIA’s models to find the best fit for your application.

Explore NVIDIA’s models [here](https://build.nvidia.com/models).

## Authentication

Set your `NVIDIA_API_KEY` environment variable. Get your key [from Nvidia here](https://build.nvidia.com/explore/discover).

<CodeGroup>
  ```bash Mac
  export NVIDIA_API_KEY=***
  ```

  ```bash Windows
  setx NVIDIA_API_KEY ***
  ```
</CodeGroup>

## Example

Use `Nvidia` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent, RunResponse
  from agno.models.nvidia import Nvidia

  agent = Agent(model=Nvidia(), markdown=True)

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story")

  ```
</CodeGroup>

<Note> View more examples [here](../examples/models/nvidia). </Note>

## Params

<Snippet file="model-nvda-params.mdx" />

`Nvidia` also supports the params of [OpenAI](/reference/models/openai).


# Ollama



Run Large Language Models locally with Ollama

[Ollama](https://ollama.com) is a fantastic tool for running models locally.

Ollama supports multiple open-source models. See the library [here](https://ollama.com/library).

We recommend experimenting to find the best-suited model for your use-case. Here are some general recommendations:

* `llama3.3` models are good for most basic use-cases.
* `qwen` models perform specifically well with tool use.
* `deepseek-r1` models have strong reasoning capabilities.
* `phi4` models are powerful, while being really small in size.

## Set up a model

Install [ollama](https://ollama.com) and run a model using

```bash run model
ollama run llama3.1
```

This gives you an interactive session with the model.

Alternatively, to download the model to be used in an Agno agent

```bash pull model
ollama pull llama3.1
```

## Example

After you have the model locally, use the `Ollama` model class to access it

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent, RunResponse
  from agno.models.ollama import Ollama

  agent = Agent(
      model=Ollama(id="llama3.1"),
      markdown=True
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")
  ```
</CodeGroup>

<Note> View more examples [here](../examples/models/ollama). </Note>

## Params

<Snippet file="model-ollama-params.mdx" />

`Ollama` is a subclass of the [Model](/reference/models/model) class and has access to the same params.


# OpenAI



The GPT models are the best in class LLMs and used as the default LLM by **Agents**.

OpenAI supports a variety of world-class models. See their models [here](https://platform.openai.com/docs/models).

We recommend experimenting to find the best-suited model for your use-case. Here are some general recommendations:

* `gpt-4o` is good for most general use-cases.
* `gpt-4o-mini` model is good for smaller tasks and faster inference.
* `o1` models are good for complex reasoning and multi-step tasks.
* `o3-mini` is a strong reasoning model with support for tool-calling and structured outputs, but at a much lower cost.

OpenAI have tier based rate limits. See the [docs](https://platform.openai.com/docs/guides/rate-limits/usage-tiers) for more information.

## Authentication

Set your `OPENAI_API_KEY` environment variable. You can get one [from OpenAI here](https://platform.openai.com/account/api-keys).

<CodeGroup>
  ```bash Mac
  export OPENAI_API_KEY=sk-***
  ```

  ```bash Windows
  setx OPENAI_API_KEY sk-***
  ```
</CodeGroup>

## Example

Use `OpenAIChat` with your `Agent`:

<CodeGroup>
  ```python agent.py

  from agno.agent import Agent, RunResponse
  from agno.models.openai import OpenAIChat

  agent = Agent(
      model=OpenAIChat(id="gpt-4o"),
      markdown=True
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")

  ```
</CodeGroup>

<Note> View more examples [here](../examples/models/openai). </Note>

## Params

For more information, please refer to the [OpenAI docs](https://platform.openai.com/docs/api-reference/chat/create) as well.

<Snippet file="model-openai-params.mdx" />

`OpenAIChat` is a subclass of the [Model](/reference/models/model) class and has access to the same params.


# OpenAI Like



Many providers like Together, Groq, Sambanova, etc support the OpenAI API format. Use the `OpenAILike` model to access them by replacing the `base_url`.

## Example

<CodeGroup>
  ```python agent.py
  from os import getenv
  from agno.agent import Agent, RunResponse
  from agno.models.openai.like import OpenAILike

  agent = Agent(
      model=OpenAILike(
          id="mistralai/Mixtral-8x7B-Instruct-v0.1",
          api_key=getenv("TOGETHER_API_KEY"),
          base_url="https://api.together.xyz/v1",
      )
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")
  ```
</CodeGroup>

## Params

<Snippet file="model-openai-like-reference.mdx" />

`OpenAILike` also support all the params of [OpenAIChat](/reference/models/openai)


# OpenRouter



OpenRouter is a platform for providing endpoints for Large Language models.

## Authentication

Set your `OPENROUTER_API_KEY` environment variable. Get your key from [here](https://openrouter.ai/settings/keys).

<CodeGroup>
  ```bash Mac
  export OPENROUTER_API_KEY=***
  ```

  ```bash Windows
  setx OPENROUTER_API_KEY ***
  ```
</CodeGroup>

## Example

Use `OpenRouter` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent, RunResponse
  from agno.models.openrouter import OpenRouter

  agent = Agent(
      model=OpenRouter(id="gpt-4o"),
      markdown=True
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")

  ```
</CodeGroup>

## Params

<Snippet file="model-openrouter-params.mdx" />

`OpenRouter` also supports the params of [OpenAI](/reference/models/openai).


# Sambanova



Sambanova is a platform for providing endpoints for Large Language models. Note that Sambanova currently does not support function calling.

## Authentication

Set your `SAMBANOVA_API_KEY` environment variable. Get your key from [here](https://cloud.sambanova.ai/apis).

<CodeGroup>
  ```bash Mac
  export SAMBANOVA_API_KEY=***
  ```

  ```bash Windows
  setx SAMBANOVA_API_KEY ***
  ```
</CodeGroup>

## Example

Use `Sambanova` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent, RunResponse
  from agno.models.sambanova import Sambanova

  agent = Agent(model=Sambanova(), markdown=True)

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")

  ```
</CodeGroup>

## Params

<Snippet file="model-sambanova-params.mdx" />

`Sambanova` also supports the params of [OpenAI](/reference/models/openai).


# Together



Together is a platform for providing endpoints for Large Language models.
See their library of models [here](https://www.together.ai/models).

We recommend experimenting to find the best-suited model for your use-case.

## Authentication

Set your `TOGETHER_API_KEY` environment variable. Get your key [from Together here](https://api.together.xyz/settings/api-keys).

<CodeGroup>
  ```bash Mac
  export TOGETHER_API_KEY=***
  ```

  ```bash Windows
  setx TOGETHER_API_KEY ***
  ```
</CodeGroup>

## Example

Use `Together` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent, RunResponse
  from agno.models.together import Together

  agent = Agent(
      model=Together(id="meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo"),
      markdown=True
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")
  ```
</CodeGroup>

<Note> View more examples [here](../examples/models/together). </Note>

## Params

<Snippet file="model-together-params.mdx" />

`Together` also supports the params of [OpenAI](/reference/models/openai).


# Gemini - VertexAI



`VertexAI` is Google's cloud platform for building, training, and deploying machine learning models.

We recommend experimenting to find the best-suited model for your use-case. Here are some general recommendations:

* `gemini-1.5-flash` is good for most use-cases.
* `gemini-2.0-flash-exp` is their strongest model.

## Authentication

[Authenticate with Gcloud](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal)

## Example

Use `Gemini` with your `Agent`:

<CodeGroup>
  ```python agent.py
  from agno.agent import Agent, RunResponse
  from agno.models.vertexai import Gemini

  agent = Agent(
      model=Gemini(id="gemini-1.5-flash"),
      markdown=True
  )

  # Print the response on the terminal
  agent.print_response("Share a 2 sentence horror story.")
  ```
</CodeGroup>

<Note> View more examples [here](../examples/models/vertexai). </Note>

## Params

<Snippet file="model-vertexai-params.mdx" />

`Gemini` is a subclass of the [Model](/reference/models/model) class and has access to the same params.


# xAI



xAI is a platform for providing endpoints for Large Language models.
See their list of models [here](https://docs.x.ai/docs/models).

We recommend experimenting to find the best-suited model for your use-case. `grok-beta` model is good for most use-cases.

xAI has rate limits on their APIs. See the [docs](https://docs.x.ai/docs/usage-tiers-and-rate-limits) for more information.

## Authentication

Set your `XAI_API_KEY` environment variable. You can get one [from xAI here](https://console.x.ai/).

<CodeGroup>
  ```bash Mac
  export XAI_API_KEY=sk-***
  ```

  ```bash Windows
  setx XAI_API_KEY sk-***
  ```
</CodeGroup>

## Example

Use `xAI` with your `Agent`:

<CodeGroup>
  ```python agent.py

  from agno.agent import Agent, RunResponse
  from agno.models.xai import xAI

  agent = Agent(
      model=xAI(id="grok-beta"),
      markdown=True
  )

  # Print the response in the terminal
  agent.print_response("Share a 2 sentence horror story.")

  ```
</CodeGroup>

<Note> View more examples [here](../examples/models/xai). </Note>

## Params

For more information, please refer to the [xAI docs](https://docs.x.ai/docs) as well.

## Params

<Snippet file="model-xai-params.mdx" />

`xAI` also supports the params of [OpenAI](/reference/models/openai).


# Agent



<Snippet file="agent-reference.mdx" />


# AgentSession



Coming Soon...


# Agentic Chunking



Agentic chunking is an intelligent method of splitting documents into smaller chunks by using a model to determine natural breakpoints in the text.
Rather than splitting text at fixed character counts, it analyzes the content to find semantically meaningful boundaries like paragraph breaks and topic transitions.

<Snippet file="chunking-agentic.mdx" />


# Document Chunking



Document chunking is a method of splitting documents into smaller chunks based on document structure like paragraphs and sections.
It analyzes natural document boundaries rather than splitting at fixed character counts. This is useful when you want to process large documents while preserving semantic meaning and context.

<Snippet file="chunking-document.mdx" />


# Fixed Size Chunking



Fixed size chunking is a method of splitting documents into smaller chunks of a specified size, with optional overlap between chunks.
This is useful when you want to process large documents in smaller, manageable pieces.

<Snippet file="chunking-fixed-size.mdx" />


# Recursive Chunking



Recursive chunking is a method of splitting documents into smaller chunks by recursively applying a chunking strategy.
This is useful when you want to process large documents in smaller, manageable pieces.

<Snippet file="chunking-recursive.mdx" />


# Semantic Chunking



Semantic chunking is a method of splitting documents into smaller chunks by analyzing semantic similarity between text segments using embeddings.
It uses the chonkie library to identify natural breakpoints where the semantic meaning changes significantly, based on a configurable similarity threshold.
This helps preserve context and meaning better than fixed-size chunking by ensuring semantically related content stays together in the same chunk, while splitting occurs at meaningful topic transitions.

<Snippet file="chunking-semantic.mdx" />


# Arxiv Reader



ArxivReader is a reader class that allows you to read papers from the Arxiv API.

<Snippet file="arxiv-reader-reference.mdx" />


# Reader



Reader is the base class for all reader classes in Agno.

<Snippet file="base-reader-reference.mdx" />


# CSV Reader



CSVReader is a reader class that allows you to read data from CSV files.

<Snippet file="csv-reader-reference.mdx" />


# CSV URL Reader



CSVUrlReader is a reader class that allows you to read data from CSV files stored in URLs.

<Snippet file="csv-url-reader-reference.mdx" />


# Docx Reader



DocxReader is a reader class that allows you to read data from Docx files.

<Snippet file="docx-reader-reference.mdx" />


# FireCrawl Reader



FireCrawlReader is a reader class that allows you to read data from websites using Firecrawl.

<Snippet file="firecrawl-reader-reference.mdx" />


# JSON Reader



JSONReader is a reader class that allows you to read data from JSON files.

<Snippet file="json-reader-reference.mdx" />


# PDF Reader



PDFReader is a reader class that allows you to read data from PDF files.

<Snippet file="pdf-reader-reference.mdx" />


# PDF Image Reader



PDFImageReader is a reader class that allows you to read data from PDF files with images.

<Snippet file="pdf-image-reader-reference.mdx" />


# PDF Image URL Reader



PDFImageUrlReader is a reader class that allows you to read data from PDF files with images stored in URLs.

<Snippet file="pdf-image-url-reader-reference.mdx" />


# PDF URL Reader



PDFUrlReader is a reader class that allows you to read data from PDF files stored in URLs.

<Snippet file="pdf-url-reader-reference.mdx" />


# Text Reader



TextReader is a reader class that allows you to read data from text files.

<Snippet file="text-reader-reference.mdx" />


# Website Reader



WebsiteReader is a reader class that allows you to read data from websites.

<Snippet file="website-reader-reference.mdx" />


# YouTube Reader



YouTubeReader is a reader class that allows you to read transcript from YouTube videos.

<Snippet file="youtube-reader-reference.mdx" />


# Arxiv Knowledge Base



ArxivKnowledge is a knowledge base class that allows you to load and query papers from the Arxiv API.

<Snippet file="kb-arxiv-reference.mdx" />


# AgentKnowledge



AgentKnolwedge is the base class for all knowledge base classes in Agno. It provides common functionality and parameters that are inherited by all other knowledge base classes.

<Snippet file="kb-base-reference.mdx" />


# Combined Knowledge Base



CombinedKnowledge is a knowledge base class that allows you to load and query multiple knowledge bases at once.

<Snippet file="kb-combined-reference.mdx" />


# CSV Knowledge Base



CSVKnowledge is a knowledge base class that allows you to load and query data from CSV files.

<Snippet file="kb-csv-reference.mdx" />


# CSV URL Knowledge Base



CSVUrlKnowledge is a knowledge base class that allows you to load and query data from CSV files stored in URLs.

<Snippet file="kb-csv-url-reference.mdx" />


# Docx Knowledge Base



DocxKnowledge is a knowledge base class that allows you to load and query data from Docx files.

<Snippet file="kb-docx-reference.mdx" />


# JSON Knowledge Base



JSONKnowledge is a knowledge base class that allows you to load and query data from JSON files.

<Snippet file="kb-json-reference.mdx" />


# Langchain Knowledge Base



LangChainKnowledge is a knowledge base class that allows you to load and query data from Langchain supported knowledge bases.

<Snippet file="kb-langchain-reference.mdx" />


# LlamaIndex Knowledge Base



LlamaIndexKnowledge is a knowledge base class that allows you to load and query data from LlamaIndex supported knowledge bases.

<Snippet file="kb-llamaindex-reference.mdx" />


# PDF Knowledge Base



PDFKnowledge is a knowledge base class that allows you to load and query data from PDF files.

<Snippet file="kb-pdf-reference.mdx" />


# PDF URL Knowledge Base



PDFUrlKnowledge is a knowledge base class that allows you to load and query data from PDF files stored in URLs.

<Snippet file="kb-pdf-url-reference.mdx" />


# Text Knowledge Base



TextKnowledge is a knowledge base class that allows you to load and query data from text files.

<Snippet file="kb-txt-reference.mdx" />


# Website Knowledge Base



WebsiteKnowledge is a knowledge base class that allows you to load and query data from websites.

<Snippet file="kb-website-reference.mdx" />


# Wikipedia Knowledge Base



WikipediaKnowledge is a knowledge base class that allows you to load and query data from Wikipedia articles.

<Snippet file="kb-wikipedia-reference.mdx" />


# YouTube Knowledge Base



YouTubeKnowledge is a knowledge base class that allows you to load and query data from YouTube videos.

<Snippet file="kb-youtube-reference.mdx" />


# Claude



The Claude model provides access to Anthropic's Claude models.

<Snippet file="model-claude-params.mdx" />


# Azure OpenAI



The AzureOpenAI model provides access to Azure-hosted OpenAI models.

<Snippet file="model-azure-params.mdx" />


# AWS Bedrock Claude



The AWS Bedrock Claude model provides access to Anthropic's Claude models hosted on AWS Bedrock.

<Snippet file="model-aws-params.mdx" />


# Cohere



The Cohere model provides access to Cohere's language models.

<Snippet file="model-cohere-params.mdx" />


# DeepSeek



The DeepSeek model provides access to DeepSeek's language models.

<Snippet file="model-deepseek-params.mdx" />


# Fireworks



The Fireworks model provides access to Fireworks' language models.

<Snippet file="model-fireworks-params.mdx" />


# Gemini



The Gemini model provides access to Google's Gemini models.

<Snippet file="model-google-params.mdx" />


# Gemini OpenAI



The Gemini OpenAI model provides access to Google's Gemini models that are OpenAI Like.

<Snippet file="model-google-openai-params.mdx" />


# Groq



The Groq model provides access to Groq's high-performance language models.

<Snippet file="model-groq-params.mdx" />


# HuggingFace



The HuggingFace model provides access to models hosted on the HuggingFace Hub.

<Snippet file="model-hf-params.mdx" />


# InternLM



The InternLM model provides access to the InternLM model.

<Snippet file="model-internlm-params.mdx" />


# Mistral



The Mistral model provides access to Mistral's language models.

<Snippet file="model-mistral-params.mdx" />


# Model



The Model class is the base class for all models in Agno. It provides common functionality and parameters that are inherited by specific model implementations like OpenAIChat, Claude, etc.

<Snippet file="model-base-params.mdx" />


# Nvidia



The Nvidia model provides access to Nvidia's language models.

<Snippet file="model-nvidia-params.mdx" />


# Ollama



The Ollama model provides access to locally-hosted open source models.

<Snippet file="model-ollama-params.mdx" />


# Ollama Hermes



The Ollama Hermes model provides access to the Ollama Hermes model.

<Snippet file="model-ollama-hermes-params.mdx" />


# Ollama Tools



The Ollama Tools model provides access to the Ollama models and passes tools in XML format to the model.

<Snippet file="model-ollama-tools-params.mdx" />


# OpenAI



The OpenAIChat model provides access to OpenAI models like GPT-4o.

<Snippet file="model-openai-params.mdx" />


# OpenAI Like



The OpenAI Like model works as a wrapper for the OpenAILike models.

<Snippet file="model-openai-like-params.mdx" />


# OpenRouter



The OpenRouter model provides unified access to various language models through OpenRouter.

<Snippet file="model-openrouter-params.mdx" />


# Sambanova



The Sambanova model provides access to Sambanova's language models.

<Snippet file="model-sambanova-params.mdx" />


# Together



The Together model provides access to Together's language models.

<Snippet file="model-together-params.mdx" />


# Vertex Gemini



The VertexGemini model provides access to Google's Gemini models hosted on Vertex AI.

<Snippet file="model-vertexai-params.mdx" />


# xAI



The xAI model provides access to xAI's language models.

<Snippet file="model-xai-params.mdx" />


# Cohere Reranker



<Snippet file="reranker-cohere-params.mdx" />


# Cassandra



<Snippet file="vector-db-cassandra-reference.mdx" />


# ChromaDb



<Snippet file="vector-db-chromadb-reference.mdx" />


# Clickhouse



<Snippet file="vector-db-clickhouse-reference.mdx" />


# LanceDb



<Snippet file="vector-db-lancedb-reference.mdx" />


# Milvus



<Snippet file="vector-db-milvus-reference.mdx" />


# MongoDb



<Snippet file="vector-db-mongodb-reference.mdx" />


# PgVector



<Snippet file="vector-db-pgvector-reference.mdx" />


# Pinecone



<Snippet file="vector-db-pinecone-reference.mdx" />


# Qdrant



<Snippet file="vector-db-qdrant-reference.mdx" />


# SingleStore



<Snippet file="vector-db-singlestore-reference.mdx" />


# Workflow



<Snippet file="workflow-reference.mdx" />


# DynamoDB Agent Storage



Agno supports using DynamoDB as a storage backend for Agents using the `DynamoDbAgentStorage` class.

## Usage

You need to provide `aws_access_key_id` and `aws_secret_access_key` parameters to the `DynamoDbAgentStorage` class.

```python storage.py
from agno.storage.agent.dynamodb import DynamoDbAgentStorage

# AWS Credentials
AWS_ACCESS_KEY_ID = getenv("AWS_ACCESS_KEY_ID")
AWS_SECRET_ACCESS_KEY = getenv("AWS_SECRET_ACCESS_KEY")

storage = DynamoDbAgentStorage(
    # store sessions in the ai.sessions table
    table_name="agent_sessions",
    # region_name: DynamoDB region name
    region_name="us-east-1",
    # aws_access_key_id: AWS access key id
    aws_access_key_id=AWS_ACCESS_KEY_ID,
    # aws_secret_access_key: AWS secret access key
    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,
)

# Add storage to the Agent
agent = Agent(storage=storage)
```

## Params

<Snippet file="storage-dynamodb-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/storage/dynamodb_storage.py)


# Introduction



Agents come with built-in memory but it only lasts while the session is active. To continue conversations across sessions, we store Agent sessions in a database like PostgreSQL.

Storage is a necessary component when building user facing AI products as any production application will require users to be able to "continue" their conversation with the Agent.

The general syntax for adding storage to an Agent looks like:

```python storage.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.storage.agent.postgres import PostgresAgentStorage

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    storage=PostgresAgentStorage(table_name="agent_sessions", db_url="postgresql+psycopg://ai:ai@localhost:5532/ai"),
    tools=[DuckDuckGoTools()],
    show_tool_calls=True,
    add_history_to_messages=True,
)
agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
agent.print_response("Which country are we speaking about?")
```

The following databases are supported as a storage backend:

* [PostgreSQL](/storage/postgres)
* [Sqlite](/storage/sqlite)
* [SingleStore](/storage/singlestore)
* [DynamoDB](/storage/dynamodb)
* [MongoDB](/storage/mongodb)


# JSON Agent Storage



Agno supports using local JSON files as a storage backend for Agents using the `JsonFileAgentStorage` class.

## Usage

```python storage.py
from agno.agent import Agent
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.storage.agent.json import JsonFileAgentStorage

agent = Agent(
    storage=JsonFileAgentStorage(path="tmp/agent_sessions_json"),
    tools=[DuckDuckGoTools()],
    add_history_to_messages=True,
)

agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Params

<Snippet file="storage-json-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/storage/json_storage.py)


# Postgres Agent Storage



Agno supports using PostgreSQL as a storage backend for Agents using the `PostgresAgentStorage` class.

## Usage

### Run PgVector

Install [docker desktop](https://docs.docker.com/desktop/install/mac-install/) and run **PgVector** on port **5532** using:

```bash
docker run -d \
  -e POSTGRES_DB=ai \
  -e POSTGRES_USER=ai \
  -e POSTGRES_PASSWORD=ai \
  -e PGDATA=/var/lib/postgresql/data/pgdata \
  -v pgvolume:/var/lib/postgresql/data \
  -p 5532:5432 \
  --name pgvector \
  agno/pgvector:16
```

```python storage.py
from agno.storage.agent.postgres import PostgresAgentStorage

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

# Create a storage backend using the Postgres database
storage = PostgresAgentStorage(
    # store sessions in the ai.sessions table
    table_name="agent_sessions",
    # db_url: Postgres database URL
    db_url=db_url,
)

# Add storage to the Agent
agent = Agent(storage=storage)
```

## Params

<Snippet file="storage-postgres-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/storage/postgres_storage.py)


# Singlestore Agent Storage



Agno supports using Singlestore as a storage backend for Agents using the `SingleStoreAgentStorage` class.

## Usage

Obtain the credentials for Singlestore from [here](https://portal.singlestore.com/)

```python storage.py
from os import getenv

from sqlalchemy.engine import create_engine

from agno.agent import Agent
from agno.storage.agent.singlestore import SingleStoreAgentStorage

# SingleStore Configuration
USERNAME = getenv("SINGLESTORE_USERNAME")
PASSWORD = getenv("SINGLESTORE_PASSWORD")
HOST = getenv("SINGLESTORE_HOST")
PORT = getenv("SINGLESTORE_PORT")
DATABASE = getenv("SINGLESTORE_DATABASE")
SSL_CERT = getenv("SINGLESTORE_SSL_CERT", None)

# SingleStore DB URL
db_url = f"mysql+pymysql://{USERNAME}:{PASSWORD}@{HOST}:{PORT}/{DATABASE}?charset=utf8mb4"
if SSL_CERT:
    db_url += f"&ssl_ca={SSL_CERT}&ssl_verify_cert=true"

# Create a database engine
db_engine = create_engine(db_url)

# Create a storage backend using the Singlestore database
storage = SingleStoreAgentStorage(
    # store sessions in the ai.sessions table
    table_name="agent_sessions",
    # db_engine: Singlestore database engine
    db_engine=db_engine,
    # schema: Singlestore schema
    schema=DATABASE,
)

# Add storage to the Agent
agent = Agent(storage=storage)
```

## Params

<Snippet file="storage-s2-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/storage/singlestore_storage.py)


# Sqlite Agent Storage



Agno supports using Sqlite as a storage backend for Agents using the `SqliteAgentStorage` class.

## Usage

You need to provide either `db_url`, `db_file` or `db_engine`. The following example uses `db_file`.

```python storage.py
from agno.storage.agent.sqlite import SqliteAgentStorage

# Create a storage backend using the Sqlite database
storage = SqliteAgentStorage(
    # store sessions in the ai.sessions table
    table_name="agent_sessions",
    # db_file: Sqlite database file
    db_file="tmp/data.db",
)

# Add storage to the Agent
agent = Agent(storage=storage)
```

## Params

<Snippet file="storage-sqlite-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/storage/sqlite_storage.py)


# YAML Agent Storage



Agno supports using local YAML files as a storage backend for Agents using the `YamlFileAgentStorage` class.

## Usage

```python storage.py
from agno.agent import Agent
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.storage.agent.yaml import YamlFileAgentStorage

agent = Agent(
    storage=YamlFileAgentStorage(path="tmp/agent_sessions_yaml"),
    tools=[DuckDuckGoTools()],
    add_history_to_messages=True,
)

agent.print_response("How many people live in Canada?")
agent.print_response("What is their national anthem called?")
```

## Params

<Snippet file="storage-yaml-params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/storage/yaml_storage.py)


# Writing your own Toolkit



Many advanced use-cases will require writing custom Toolkits. Here's the general flow:

1. Create a class inheriting the `agno.tools.Toolkit` class.
2. Add your functions to the class.
3. **Important:** Register the functions using `self.register(function_name)`

Now your Toolkit is ready to use with an Agent. For example:

```python shell_toolkit.py
from typing import List

from agno.agent import Agent
from agno.tools import Toolkit
from agno.utils.log import logger

class ShellTools(Toolkit):
    def __init__(self):
        super().__init__(name="shell_tools")
        self.register(self.run_shell_command)

    def run_shell_command(self, args: List[str], tail: int = 100) -> str:
        """
        Runs a shell command and returns the output or error.

        Args:
            args (List[str]): The command to run as a list of strings.
            tail (int): The number of lines to return from the output.
        Returns:
            str: The output of the command.
        """
        import subprocess

        logger.info(f"Running shell command: {args}")
        try:
            logger.info(f"Running shell command: {args}")
            result = subprocess.run(args, capture_output=True, text=True)
            logger.debug(f"Result: {result}")
            logger.debug(f"Return code: {result.returncode}")
            if result.returncode != 0:
                return f"Error: {result.stderr}"
            # return only the last n lines of the output
            return "\n".join(result.stdout.split("\n")[-tail:])
        except Exception as e:
            logger.warning(f"Failed to run shell command: {e}")
            return f"Error: {e}"

agent = Agent(tools=[ShellTools()], show_tool_calls=True, markdown=True)
agent.print_response("List all the files in my home directory.")
```


# Python Functions



Any python function can be used as a tool by an Agent. **We highly recommend** creating functions specific to your workflow and adding them to your Agents.

For example, here's how to use a `get_top_hackernews_stories` function as a tool:

```python hn_agent.py
import json
import httpx

from agno.agent import Agent

def get_top_hackernews_stories(num_stories: int = 10) -> str:
    """
    Use this function to get top stories from Hacker News.

    Args:
        num_stories (int): Number of stories to return. Defaults to 10.

    Returns:
        str: JSON string of top stories.
    """

    # Fetch top story IDs
    response = httpx.get('https://hacker-news.firebaseio.com/v0/topstories.json')
    story_ids = response.json()

    # Fetch story details
    stories = []
    for story_id in story_ids[:num_stories]:
        story_response = httpx.get(f'https://hacker-news.firebaseio.com/v0/item/{story_id}.json')
        story = story_response.json()
        if "text" in story:
            story.pop("text", None)
        stories.append(story)
    return json.dumps(stories)

agent = Agent(tools=[get_top_hackernews_stories], show_tool_calls=True, markdown=True)
agent.print_response("Summarize the top 5 stories on hackernews?", stream=True)
```


# Introduction



Tools are **functions** that an Agent can run like searching the web, running SQL, sending an email or calling APIs. Use tools integrate Agents with external systems.
You can use any python function as a tool or use a pre-built **toolkit**. The general syntax is:

```python
from agno.agent import Agent

agent = Agent(
    # Add functions or Toolkits
    tools=[...],
    # Show tool calls in the Agent response
    show_tool_calls=True
)
```

Read more about:

* [Available Toolkits](/tools/toolkits)
* [Using functions as tools](/tools/functions)


# Airflow



## Example

The following agent will use Airflow to save and read a DAG file.

```python cookbook/tools/airflow_tools.py
from agno.agent import Agent
from agno.tools.airflow import AirflowTools

agent = Agent(
    tools=[AirflowTools(dags_dir="dags", save_dag=True, read_dag=True)], show_tool_calls=True, markdown=True
)

dag_content = """
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}
# Using 'schedule' instead of deprecated 'schedule_interval'
with DAG(
    'example_dag',
    default_args=default_args,
    description='A simple example DAG',
    schedule='@daily',  # Changed from schedule_interval
    catchup=False
) as dag:
    def print_hello():
        print("Hello from Airflow!")
        return "Hello task completed"
    task = PythonOperator(
        task_id='hello_task',
        python_callable=print_hello,
        dag=dag,
    )
"""

agent.run(f"Save this DAG file as 'example_dag.py': {dag_content}")

agent.print_response("Read the contents of 'example_dag.py'")
```

## Toolkit Params

| Parameter  | Type            | Default          | Description                                      |
| ---------- | --------------- | ---------------- | ------------------------------------------------ |
| `dags_dir` | `Path` or `str` | `Path.cwd()`     | Directory for DAG files                          |
| `save_dag` | `bool`          | `True`           | Whether to register the save\_dag\_file function |
| `read_dag` | `bool`          | `True`           | Whether to register the read\_dag\_file function |
| `name`     | `str`           | `"AirflowTools"` | The name of the tool                             |

## Toolkit Functions

| Function        | Description                                        |
| --------------- | -------------------------------------------------- |
| `save_dag_file` | Saves python code for an Airflow DAG to a file     |
| `read_dag_file` | Reads an Airflow DAG file and returns the contents |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/airflow.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/airflow_tools.py)


# Apify



**ApifyTools** enable an Agent to access the Apify API and run actors.

## Prerequisites

The following example requires the `apify-client` library and an API token which can be obtained from [Apify](https://apify.com/).

```shell
pip install -U apify-client
```

```shell
export MY_APIFY_TOKEN=***
```

## Example

The following agent will use Apify to crawl the webpage: [https://docs.agno.com/introduction](https://docs.agno.com/introduction) and summarize it.

```python cookbook/tools/apify_tools.py
from agno.agent import Agent
from agno.tools.apify import ApifyTools

agent = Agent(tools=[ApifyTools()], show_tool_calls=True)
agent.print_response("Tell me about https://docs.agno.com/introduction", markdown=True)
```

## Toolkit Params

| Parameter                 | Type   | Default | Description                                                                       |
| ------------------------- | ------ | ------- | --------------------------------------------------------------------------------- |
| `api_key`                 | `str`  | -       | API key for authentication purposes.                                              |
| `website_content_crawler` | `bool` | `True`  | Enables the functionality to crawl a website using website-content-crawler actor. |
| `web_scraper`             | `bool` | `False` | Enables the functionality to crawl a website using web\_scraper actor.            |

## Toolkit Functions

| Function                  | Description                                                   |
| ------------------------- | ------------------------------------------------------------- |
| `website_content_crawler` | Crawls a website using Apify's website-content-crawler actor. |
| `web_scrapper`            | Scrapes a website using Apify's web-scraper actor.            |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/apify.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/apify_tools.py)


# Arxiv



**ArxivTools** enable an Agent to search for publications on Arxiv.

## Prerequisites

The following example requires the `arxiv` and `pypdf` libraries.

```shell
pip install -U arxiv pypdf
```

## Example

The following agent will run seach arXiv for "language models" and print the response.

```python cookbook/tools/arxiv_tools.py
from agno.agent import Agent
from agno.tools.arxiv import ArxivTools

agent = Agent(tools=[ArxivTools()], show_tool_calls=True)
agent.print_response("Search arxiv for 'language models'", markdown=True)
```

## Toolkit Params

| Parameter           | Type   | Default | Description                                                        |
| ------------------- | ------ | ------- | ------------------------------------------------------------------ |
| `search_arxiv`      | `bool` | `True`  | Enables the functionality to search the arXiv database.            |
| `read_arxiv_papers` | `bool` | `True`  | Allows reading of arXiv papers directly.                           |
| `download_dir`      | `Path` | -       | Specifies the directory path where downloaded files will be saved. |

## Toolkit Functions

| Function                                 | Description                                                                                        |
| ---------------------------------------- | -------------------------------------------------------------------------------------------------- |
| `search_arxiv_and_update_knowledge_base` | This function searches arXiv for a topic, adds the results to the knowledge base and returns them. |
| `search_arxiv`                           | Searches arXiv for a query.                                                                        |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/arxiv.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/arxiv_tools.py)


# AWS Lambda



## Prerequisites

The following example requires the `boto3` library.

```shell
pip install openai boto3
```

## Example

The following agent will use AWS Lambda to list all Lambda functions in our AWS account and invoke a specific Lambda function.

```python cookbook/tools/aws_lambda_tools.py

from agno.agent import Agent
from agno.tools.aws_lambda import AWSLambdaTools


# Create an Agent with the AWSLambdaTool
agent = Agent(
    tools=[AWSLambdaTools(region_name="us-east-1")],
    name="AWS Lambda Agent",
    show_tool_calls=True,
)

# Example 1: List all Lambda functions
agent.print_response("List all Lambda functions in our AWS account", markdown=True)

# Example 2: Invoke a specific Lambda function
agent.print_response("Invoke the 'hello-world' Lambda function with an empty payload", markdown=True)
```

## Toolkit Params

| Parameter     | Type  | Default       | Description                                         |
| ------------- | ----- | ------------- | --------------------------------------------------- |
| `region_name` | `str` | `"us-east-1"` | AWS region name where Lambda functions are located. |

## Toolkit Functions

| Function          | Description                                                                                                           |
| ----------------- | --------------------------------------------------------------------------------------------------------------------- |
| `list_functions`  | Lists all Lambda functions available in the AWS account.                                                              |
| `invoke_function` | Invokes a specific Lambda function with an optional payload. Takes `function_name` and optional `payload` parameters. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/aws_lambda.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/aws_lambda_tools.py)


# BaiduSearch



**BaiduSearch** enables an Agent to search the web for information using the Baidu search engine.

## Prerequisites

The following example requires the `baidusearch` library. To install BaiduSearch, run the following command:

```shell
pip install -U baidusearch
```

## Example

```python cookbook/tools/baidusearch_tools.py
from agno.agent import Agent
from agno.tools.baidusearch import BaiduSearchTools

agent = Agent(
    tools=[BaiduSearchTools()],
    description="You are a search agent that helps users find the most relevant information using Baidu.",
    instructions=[
        "Given a topic by the user, respond with the 3 most relevant search results about that topic.",
        "Search for 5 results and select the top 3 unique items.",
        "Search in both English and Chinese.",
    ],
    show_tool_calls=True,
)

agent.print_response("What are the latest advancements in AI?", markdown=True)
```

## Toolkit Params

| Parameter           | Type  | Default | Description                                                                                          |
| ------------------- | ----- | ------- | ---------------------------------------------------------------------------------------------------- |
| `fixed_max_results` | `int` | -       | Sets a fixed number of maximum results to return. No default is provided, must be specified if used. |
| `fixed_language`    | `str` | -       | Set the fixed language for the results.                                                              |
| `headers`           | `Any` | -       | Headers to be used in the search request.                                                            |
| `proxy`             | `str` | -       | Specifies a single proxy address as a string to be used for the HTTP requests.                       |
| `timeout`           | `int` | `10`    | Sets the timeout for HTTP requests, in seconds.                                                      |

## Toolkit Functions

| Function       | Description                                    |
| -------------- | ---------------------------------------------- |
| `baidu_search` | Use this function to search Baidu for a query. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/baidusearch.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/baidusearch_tools.py)


# Cal.com



## Prerequisites

The following example requires the `pytz` and `requests` libraries.

```shell
pip install requests pytz
```

```shell
export CALCOM_API_KEY="your_api_key"
export CALCOM_EVENT_TYPE_ID="your_event_type_id"
```

## Example

The following agent will use Cal.com to list all events in your Cal.com account for tomorrow.

```python cookbook/tools/calcom_tools.py

agent = Agent(
    name="Calendar Assistant",
    instructions=[
        f"You're scheduing assistant. Today is {datetime.now()}.",
        "You can help users by:",
        "- Finding available time slots",
        "- Creating new bookings",
        "- Managing existing bookings (view, reschedule, cancel) ",
        "- Getting booking details",
        "- IMPORTANT: In case of rescheduling or cancelling booking, call the get_upcoming_bookings function to get the booking uid. check available slots before making a booking for given time",
        "Always confirm important details before making bookings or changes.",
    ],
    model=OpenAIChat(id="gpt-4"),
    tools=[CalComTools(user_timezone="America/New_York")],
    show_tool_calls=True,
    markdown=True,
)

agent.print_response("What are my bookings for tomorrow?")
```

## Toolkit Params

| Parameter               | Type   | Default | Description                                |
| ----------------------- | ------ | ------- | ------------------------------------------ |
| `api_key`               | `str`  | `None`  | Cal.com API key                            |
| `event_type_id`         | `int`  | `None`  | Event type ID for scheduling               |
| `user_timezone`         | `str`  | `None`  | User's timezone (e.g. "America/New\_York") |
| `get_available_slots`   | `bool` | `True`  | Enable getting available time slots        |
| `create_booking`        | `bool` | `True`  | Enable creating new bookings               |
| `get_upcoming_bookings` | `bool` | `True`  | Enable getting upcoming bookings           |
| `reschedule_booking`    | `bool` | `True`  | Enable rescheduling bookings               |
| `cancel_booking`        | `bool` | `True`  | Enable canceling bookings                  |

## Toolkit Functions

| Function                | Description                                      |
| ----------------------- | ------------------------------------------------ |
| `get_available_slots`   | Gets available time slots for a given date range |
| `create_booking`        | Creates a new booking with provided details      |
| `get_upcoming_bookings` | Gets list of upcoming bookings                   |
| `get_booking_details`   | Gets details for a specific booking              |
| `reschedule_booking`    | Reschedules an existing booking                  |
| `cancel_booking`        | Cancels an existing booking                      |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/calcom.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/calcom_tools.py)


# Calculator



**Calculator** enables an Agent to perform mathematical calculations.

## Example

The following agent will calculate the result of `10*5` and then raise it to the power of `2`:

```python cookbook/tools/calculator_tools.py
from agno.agent import Agent
from agno.tools.calculator import CalculatorTools

agent = Agent(
    tools=[
        CalculatorTools(
            add=True,
            subtract=True,
            multiply=True,
            divide=True,
            exponentiate=True,
            factorial=True,
            is_prime=True,
            square_root=True,
        )
    ],
    show_tool_calls=True,
    markdown=True,
)

agent.print_response("What is 10*5 then to the power of 2, do it step by step")
```

## Toolkit Params

| Parameter      | Type   | Default | Description                                                         |
| -------------- | ------ | ------- | ------------------------------------------------------------------- |
| `add`          | `bool` | `True`  | Enables the functionality to perform addition.                      |
| `subtract`     | `bool` | `True`  | Enables the functionality to perform subtraction.                   |
| `multiply`     | `bool` | `True`  | Enables the functionality to perform multiplication.                |
| `divide`       | `bool` | `True`  | Enables the functionality to perform division.                      |
| `exponentiate` | `bool` | `False` | Enables the functionality to perform exponentiation.                |
| `factorial`    | `bool` | `False` | Enables the functionality to calculate the factorial of a number.   |
| `is_prime`     | `bool` | `False` | Enables the functionality to check if a number is prime.            |
| `square_root`  | `bool` | `False` | Enables the functionality to calculate the square root of a number. |

## Toolkit Functions

| Function       | Description                                                                              |
| -------------- | ---------------------------------------------------------------------------------------- |
| `add`          | Adds two numbers and returns the result.                                                 |
| `subtract`     | Subtracts the second number from the first and returns the result.                       |
| `multiply`     | Multiplies two numbers and returns the result.                                           |
| `divide`       | Divides the first number by the second and returns the result. Handles division by zero. |
| `exponentiate` | Raises the first number to the power of the second number and returns the result.        |
| `factorial`    | Calculates the factorial of a number and returns the result. Handles negative numbers.   |
| `is_prime`     | Checks if a number is prime and returns the result.                                      |
| `square_root`  | Calculates the square root of a number and returns the result. Handles negative numbers. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/calculator.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/calculator_tools.py)


# Composio



[**ComposioTools**](https://docs.composio.dev/framework/phidata) enable an Agent to work with tools like Gmail, Salesforce, Github, etc.

## Prerequisites

The following example requires the `composio-agno` library.

```shell
pip install composio-agno
composio add github # Login into Github
```

## Example

The following agent will use Github Tool from Composio Toolkit to star a repo.

```python cookbook/tools/composio_tools.py
from agno.agent import Agent
from composio_agno import Action, ComposioToolSet


toolset = ComposioToolSet()
composio_tools = toolset.get_tools(
  actions=[Action.GITHUB_STAR_A_REPOSITORY_FOR_THE_AUTHENTICATED_USER]
)

agent = Agent(tools=composio_tools, show_tool_calls=True)
agent.print_response("Can you star agno-agi/agno repo?")
```

## Toolkit Params

The following parameters are used when calling the GitHub star repository action:

| Parameter | Type  | Default | Description                          |
| --------- | ----- | ------- | ------------------------------------ |
| `owner`   | `str` | -       | The owner of the repository to star. |
| `repo`    | `str` | -       | The name of the repository to star.  |

## Toolkit Functions

Composio Toolkit provides 1000+ functions to connect to different software tools.
Open this [link](https://composio.dev/tools) to view the complete list of functions.


# Confluence



**ConfluenceTools** enable an Agent to retrieve, create, and update pages in Confluence. They also allow you to explore spaces and page details.

## Prerequisites

The following example requires the `atlassian-python-api` library and Confluence credentials. You can obtain an API token by going [here](https://id.atlassian.com/manage-profile/security).

```shell
pip install atlassian-python-api
```

```shell
export CONFLUENCE_URL="https://your-confluence-instance"
export CONFLUENCE_USERNAME="your-username"
export CONFLUENCE_PASSWORD="your-password"
# or
export CONFLUENCE_API_KEY="your-api-key"
```

## Example

The following agent will retrieve the number of spaces and their names.

```python
from agno.agent import Agent
from agno.tools.confluence import ConfluenceTools

agent = Agent(
    name="Confluence agent",
    tools=[ConfluenceTools()],
    show_tool_calls=True,
    markdown=True,
)

agent.print_response("How many spaces are there and what are their names?")
```

## Toolkit Functions

| Parameter  | Type  | Default | Description                                                                                                             |
| ---------- | ----- | ------- | ----------------------------------------------------------------------------------------------------------------------- |
| `username` | `str` | -       | Confluence username. Can also be set via environment variable CONFLUENCE\_USERNAME.                                     |
| `password` | `str` | -       | Confluence password or API key. Can also be set via environment variables CONFLUENCE\_API\_KEY or CONFLUENCE\_PASSWORD. |
| `url`      | `str` | -       | Confluence instance URL. Can also be set via environment variable CONFLUENCE\_URL.                                      |
| `api_key`  | `str` | -       | Confluence API key (alternative to password).                                                                           |

## Toolkit Functions

| Function                  | Description                                                     |
| ------------------------- | --------------------------------------------------------------- |
| `get_page_content`        | Gets the content of a specific page.                            |
| `get_all_space_detail`    | Gets details about all Confluence spaces.                       |
| `get_space_key`           | Gets the Confluence key for the specified space.                |
| `get_all_page_from_space` | Gets details of all pages from the specified space.             |
| `create_page`             | Creates a new Confluence page with the provided title and body. |
| `update_page`             | Updates an existing Confluence page.                            |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/confluence.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/confluence.py)


# Crawl4AI



**Crawl4aiTools** enable an Agent to perform web crawling and scraping tasks using the Crawl4ai library.

## Prerequisites

The following example requires the `crawl4ai` library.

```shell
pip install -U crawl4ai
```

## Example

The following agent will scrape the content from the [https://github.com/agno-agi/agno](https://github.com/agno-agi/agno) webpage:

```python cookbook/tools/crawl4ai_tools.py
from agno.agent import Agent
from agno.tools.crawl4ai import Crawl4aiTools

agent = Agent(tools=[Crawl4aiTools(max_length=None)], show_tool_calls=True)
agent.print_response("Tell me about https://github.com/agno-agi/agno.")
```

## Toolkit Params

| Parameter    | Type  | Default | Description                                                               |
| ------------ | ----- | ------- | ------------------------------------------------------------------------- |
| `max_length` | `int` | `1000`  | Specifies the maximum length of the text from the webpage to be returned. |

## Toolkit Functions

| Function      | Description                                                                                                                                                                                                      |
| ------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `web_crawler` | Crawls a website using crawl4ai's WebCrawler. Parameters include 'url' for the URL to crawl and an optional 'max\_length' to limit the length of extracted content. The default value for 'max\_length' is 1000. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/crawl4ai.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/crawl4ai_tools.py)


# CSV



**CsvTools** enable an Agent to read and write CSV files.

## Example

The following agent will download the IMDB csv file and allow the user to query it using a CLI app.

```python cookbook/tools/csv_tools.py
import httpx
from pathlib import Path
from agno.agent import Agent
from agno.tools.csv import CsvTools

url = "https://agno-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv"
response = httpx.get(url)

imdb_csv = Path(__file__).parent.joinpath("wip").joinpath("imdb.csv")
imdb_csv.parent.mkdir(parents=True, exist_ok=True)
imdb_csv.write_bytes(response.content)

agent = Agent(
    tools=[CsvTools(csvs=[imdb_csv])],
    markdown=True,
    show_tool_calls=True,
    instructions=[
        "First always get the list of files",
        "Then check the columns in the file",
        "Then run the query to answer the question",
        "Always wrap column names with double quotes if they contain spaces or special characters",
        "Remember to escape the quotes in the JSON string (use \")",
        "Use single quotes for string values"
    ],
)

agent.cli_app(stream=False)
```

## Toolkit Params

| Parameter           | Type                     | Default | Description                                                            |
| ------------------- | ------------------------ | ------- | ---------------------------------------------------------------------- |
| `csvs`              | `List[Union[str, Path]]` | -       | A list of CSV files or paths to be processed or read.                  |
| `row_limit`         | `int`                    | -       | The maximum number of rows to process from each CSV file.              |
| `read_csvs`         | `bool`                   | `True`  | Enables the functionality to read data from specified CSV files.       |
| `list_csvs`         | `bool`                   | `True`  | Enables the functionality to list all available CSV files.             |
| `query_csvs`        | `bool`                   | `True`  | Enables the functionality to execute queries on data within CSV files. |
| `read_column_names` | `bool`                   | `True`  | Enables the functionality to read the column names from the CSV files. |
| `duckdb_connection` | `Any`                    | -       | Specifies a connection instance for DuckDB database operations.        |
| `duckdb_kwargs`     | `Dict[str, Any]`         | -       | A dictionary of keyword arguments for configuring DuckDB operations.   |

## Toolkit Functions

| Function         | Description                                      |
| ---------------- | ------------------------------------------------ |
| `list_csv_files` | Lists all available CSV files.                   |
| `read_csv_file`  | This function reads the contents of a csv file   |
| `get_columns`    | This function returns the columns of a csv file  |
| `query_csv_file` | This function queries the contents of a csv file |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/csv.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/csv_tools.py)


# Dalle



## Prerequisites

You need to install the `openai` library.

```bash
pip install openai
```

Set the `OPENAI_API_KEY` environment variable.

```bash
export OPENAI_API_KEY=****
```

## Example

The following agent will use DALL-E to generate an image based on a text prompt.

```python cookbook/tools/dalle_tools.py
from agno.agent import Agent
from agno.tools.dalle import DalleTools

# Create an Agent with the DALL-E tool
agent = Agent(tools=[DalleTools()], name="DALL-E Image Generator")

# Example 1: Generate a basic image with default settings
agent.print_response("Generate an image of a futuristic city with flying cars and tall skyscrapers", markdown=True)

# Example 2: Generate an image with custom settings
custom_dalle = Dalle(model="dall-e-3", size="1792x1024", quality="hd", style="natural")

agent_custom = Agent(
    tools=[custom_dalle],
    name="Custom DALL-E Generator",
    show_tool_calls=True,
)

agent_custom.print_response("Create a panoramic nature scene showing a peaceful mountain lake at sunset", markdown=True)
```

## Toolkit Params

| Parameter | Type  | Default       | Description                                                       |
| --------- | ----- | ------------- | ----------------------------------------------------------------- |
| `model`   | `str` | `"dall-e-3"`  | The DALL-E model to use                                           |
| `n`       | `int` | `1`           | Number of images to generate                                      |
| `size`    | `str` | `"1024x1024"` | Image size (256x256, 512x512, 1024x1024, 1792x1024, or 1024x1792) |
| `quality` | `str` | `"standard"`  | Image quality (standard or hd)                                    |
| `style`   | `str` | `"vivid"`     | Image style (vivid or natural)                                    |
| `api_key` | `str` | `None`        | The OpenAI API key for authentication                             |

## Toolkit Functions

| Function         | Description                               |
| ---------------- | ----------------------------------------- |
| `generate_image` | Generates an image based on a text prompt |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/dalle.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/dalle_tools.py)


# Discord



**DiscordTools** enable an agent to send messages, read message history, manage channels, and delete messages in Discord.

## Prerequisites

The following example requires a Discord bot token which can be obtained from [here](https://discord.com/developers/applications).

```shell
export DISCORD_BOT_TOKEN=***
```

## Example

```python cookbook/tools/discord.py
from agno.agent import Agent
from agno.tools.discord import DiscordTools

agent = Agent(
    tools=[DiscordTools()],
    show_tool_calls=True,
    markdown=True,
)

agent.print_response("Send 'Hello World!' to channel 1234567890", markdown=True)
```

## Toolkit Params

| Parameter                   | Type   | Default | Description                                                   |
| --------------------------- | ------ | ------- | ------------------------------------------------------------- |
| `bot_token`                 | `str`  | -       | Discord bot token for authentication.                         |
| `enable_messaging`          | `bool` | `True`  | Whether to enable sending messages to channels.               |
| `enable_history`            | `bool` | `True`  | Whether to enable retrieving message history from channels.   |
| `enable_channel_management` | `bool` | `True`  | Whether to enable fetching channel info and listing channels. |
| `enable_message_management` | `bool` | `True`  | Whether to enable deleting messages from channels.            |

## Toolkit Functions

| Function               | Description                                                                                   |
| ---------------------- | --------------------------------------------------------------------------------------------- |
| `send_message`         | Send a message to a specified channel. Returns a success or error message.                    |
| `get_channel_info`     | Retrieve information about a specified channel. Returns the channel info as a JSON string.    |
| `list_channels`        | List all channels in a specified server (guild). Returns the list of channels as JSON.        |
| `get_channel_messages` | Retrieve message history from a specified channel. Returns messages as a JSON string.         |
| `delete_message`       | Delete a specific message by ID from a specified channel. Returns a success or error message. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/discord.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/discord.py)


# DuckDb



**DuckDbTools** enable an Agent to run SQL and analyze data using DuckDb.

## Prerequisites

The following example requires DuckDB library. To install DuckDB, run the following command:

```shell
pip install duckdb
```

For more installation options, please refer to [DuckDB documentation](https://duckdb.org/docs/installation).

## Example

The following agent will analyze the movies file using SQL and return the result.

```python cookbook/tools/duckdb_tools.py
from agno.agent import Agent
from agno.tools.duckdb import DuckDbTools

agent = Agent(
    tools=[DuckDbTools()],
    show_tool_calls=True,
    system_prompt="Use this file for Movies data: https://agno-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv",
)

agent.print_response("What is the average rating of movies?", markdown=True, stream=False)
```

## Toolkit Params

| Parameter          | Type                 | Default | Description                                                       |
| ------------------ | -------------------- | ------- | ----------------------------------------------------------------- |
| `db_path`          | `str`                | -       | Specifies the path to the database file.                          |
| `connection`       | `DuckDBPyConnection` | -       | Provides an existing DuckDB connection object.                    |
| `init_commands`    | `List`               | -       | A list of initial SQL commands to run on database connection.     |
| `read_only`        | `bool`               | `False` | Configures the database connection to be read-only.               |
| `config`           | `dict`               | -       | Configuration options for the database connection.                |
| `run_queries`      | `bool`               | `True`  | Determines whether to run SQL queries during the operation.       |
| `inspect_queries`  | `bool`               | `False` | Enables inspection of SQL queries without executing them.         |
| `create_tables`    | `bool`               | `True`  | Allows creation of tables in the database during the operation.   |
| `summarize_tables` | `bool`               | `True`  | Enables summarization of table data during the operation.         |
| `export_tables`    | `bool`               | `False` | Allows exporting tables to external formats during the operation. |

## Toolkit Functions

| Function                   | Description                                                                                                                                                                                                                                    |
| -------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `show_tables`              | Function to show tables in the database                                                                                                                                                                                                        |
| `describe_table`           | Function to describe a table                                                                                                                                                                                                                   |
| `inspect_query`            | Function to inspect a query and return the query plan. Always inspect your query before running them.                                                                                                                                          |
| `run_query`                | Function that runs a query and returns the result.                                                                                                                                                                                             |
| `summarize_table`          | Function to compute a number of aggregates over a table. The function launches a query that computes a number of aggregates over all columns, including min, max, avg, std and approx\_unique.                                                 |
| `get_table_name_from_path` | Get the table name from a path                                                                                                                                                                                                                 |
| `create_table_from_path`   | Creates a table from a path                                                                                                                                                                                                                    |
| `export_table_to_path`     | Save a table in a desired format (default: parquet). If the path is provided, the table will be saved under that path. Eg: If path is /tmp, the table will be saved as /tmp/table.parquet. Otherwise it will be saved in the current directory |
| `load_local_path_to_table` | Load a local file into duckdb                                                                                                                                                                                                                  |
| `load_local_csv_to_table`  | Load a local CSV file into duckdb                                                                                                                                                                                                              |
| `load_s3_path_to_table`    | Load a file from S3 into duckdb                                                                                                                                                                                                                |
| `load_s3_csv_to_table`     | Load a CSV file from S3 into duckdb                                                                                                                                                                                                            |
| `create_fts_index`         | Create a full text search index on a table                                                                                                                                                                                                     |
| `full_text_search`         | Full text Search in a table column for a specific text/keyword                                                                                                                                                                                 |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/duckdb.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/duckdb_tools.py)


# DuckDuckGo



**DuckDuckGo** enables an Agent to search the web for information.

## Prerequisites

The following example requires the `duckduckgo-search` library. To install DuckDuckGo, run the following command:

```shell
pip install -U duckduckgo-search
```

## Example

```python cookbook/tools/duckduckgo.py
from agno.agent import Agent
from agno.tools.duckduckgo import DuckDuckGoTools

agent = Agent(tools=[DuckDuckGoTools()], show_tool_calls=True)
agent.print_response("Whats happening in France?", markdown=True)
```

## Toolkit Params

| Parameter           | Type   | Default | Description                                                                                          |
| ------------------- | ------ | ------- | ---------------------------------------------------------------------------------------------------- |
| `search`            | `bool` | `True`  | Enables the use of the `duckduckgo_search` function to search DuckDuckGo for a query.                |
| `news`              | `bool` | `True`  | Enables the use of the `duckduckgo_news` function to fetch the latest news via DuckDuckGo.           |
| `fixed_max_results` | `int`  | -       | Sets a fixed number of maximum results to return. No default is provided, must be specified if used. |
| `headers`           | `Any`  | -       | Accepts any type of header values to be sent with HTTP requests.                                     |
| `proxy`             | `str`  | -       | Specifies a single proxy address as a string to be used for the HTTP requests.                       |
| `proxies`           | `Any`  | -       | Accepts a dictionary of proxies to be used for HTTP requests.                                        |
| `timeout`           | `int`  | `10`    | Sets the timeout for HTTP requests, in seconds.                                                      |

## Toolkit Functions

| Function            | Description                                               |
| ------------------- | --------------------------------------------------------- |
| `duckduckgo_search` | Use this function to search DuckDuckGo for a query.       |
| `duckduckgo_news`   | Use this function to get the latest news from DuckDuckGo. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/duckduckgo.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/duckduckgo_tools.py)


# Email



**EmailTools** enable an Agent to send an email to a user. The Agent can send an email to a user with a specific subject and body.

## Example

```python cookbook/tools/email_tools.py
from agno.agent import Agent
from agno.tools.email import EmailTools

receiver_email = "<receiver_email>"
sender_email = "<sender_email>"
sender_name = "<sender_name>"
sender_passkey = "<sender_passkey>"

agent = Agent(
    tools=[
        EmailTools(
            receiver_email=receiver_email,
            sender_email=sender_email,
            sender_name=sender_name,
            sender_passkey=sender_passkey,
        )
    ]
)

agent.print_response("send an email to <receiver_email>")
```

## Toolkit Params

| Parameter        | Type  | Default | Description                         |
| ---------------- | ----- | ------- | ----------------------------------- |
| `receiver_email` | `str` | -       | The email address of the receiver.  |
| `sender_name`    | `str` | -       | The name of the sender.             |
| `sender_email`   | `str` | -       | The email address of the sender.    |
| `sender_passkey` | `str` | -       | The passkey for the sender's email. |

## Toolkit Functions

| Function     | Description                                                                  |
| ------------ | ---------------------------------------------------------------------------- |
| `email_user` | Emails the user with the given subject and body. Currently works with Gmail. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/email.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/email_tools.py)


# Exa



**ExaTools** enable an Agent to search the web using Exa.

## Prerequisites

The following examples requires the `exa-client` library and an API key which can be obtained from [Exa](https://exa.ai).

```shell
pip install -U exa-client
```

```shell
export EXA_API_KEY=***
```

## Example

The following agent will run seach exa for AAPL news and print the response.

```python cookbook/tools/exa_tools.py
from agno.agent import Agent
from agno.tools.exa import ExaTools

agent = Agent(tools=[ExaTools(include_domains=["cnbc.com", "reuters.com", "bloomberg.com"])], show_tool_calls=True)
agent.print_response("Search for AAPL news", markdown=True)
```

## Toolkit Params

| Parameter              | Type   | Default | Description                                                  |
| ---------------------- | ------ | ------- | ------------------------------------------------------------ |
| `api_key`              | `str`  | -       | API key for authentication purposes.                         |
| `search`               | `bool` | `False` | Determines whether to enable search functionality.           |
| `search_with_contents` | `bool` | `True`  | Indicates whether to include contents in the search results. |
| `show_results`         | `bool` | `False` | Controls whether to display search results directly.         |

## Toolkit Functions

| Function                   | Description                                                                |
| -------------------------- | -------------------------------------------------------------------------- |
| `search_exa`               | Searches Exa for a query.                                                  |
| `search_exa_with_contents` | Searches Exa for a query and returns the contents from the search results. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/exa.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/exa_tools.py)


# Fal



**FalTools** enable an Agent to perform media generation tasks.

## Prerequisites

The following example requires the `fal_client` library and an API key which can be obtained from [Fal](https://fal.ai/).

```shell
pip install -U fal_client
```

```shell
export FAL_KEY=***
```

## Example

The following agent will use FAL to generate any video requested by the user.

```python cookbook/tools/fal_tools.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.fal import FalTools

fal_agent = Agent(
    name="Fal Video Generator Agent",
    model=OpenAIChat(id="gpt-4o"),
    tools=[FalTools("fal-ai/hunyuan-video")],
    description="You are an AI agent that can generate videos using the Fal API.",
    instructions=[
        "When the user asks you to create a video, use the `generate_media` tool to create the video.",
        "Return the URL as raw to the user.",
        "Don't convert video URL to markdown or anything else.",
    ],
    markdown=True,
    debug_mode=True,
    show_tool_calls=True,
)

fal_agent.print_response("Generate video of balloon in the ocean")
```

## Toolkit Params

| Parameter | Type  | Default | Description                                |
| --------- | ----- | ------- | ------------------------------------------ |
| `api_key` | `str` | `None`  | API key for authentication purposes.       |
| `model`   | `str` | `None`  | The model to use for the media generation. |

## Toolkit Functions

| Function         | Description                                                    |
| ---------------- | -------------------------------------------------------------- |
| `generate_media` | Generate either images or videos depending on the user prompt. |
| `image_to_image` | Transform an input image based on a text prompt.               |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/fal.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/fal_tools.py)


# Firecrawl



**FirecrawlTools** enable an Agent to perform web crawling and scraping tasks.

## Prerequisites

The following example requires the `firecrawl-py` library and an API key which can be obtained from [Firecrawl](https://firecrawl.dev).

```shell
pip install -U firecrawl-py
```

```shell
export FIRECRAWL_API_KEY=***
```

## Example

The following agent will scrape the content from [https://finance.yahoo.com/](https://finance.yahoo.com/) and return a summary of the content:

```python cookbook/tools/firecrawl_tools.py
from agno.agent import Agent
from agno.tools.firecrawl import FirecrawlTools

agent = Agent(tools=[FirecrawlTools(scrape=False, crawl=True)], show_tool_calls=True, markdown=True)
agent.print_response("Summarize this https://finance.yahoo.com/")
```

## Toolkit Params

| Parameter | Type        | Default | Description                                                   |
| --------- | ----------- | ------- | ------------------------------------------------------------- |
| `api_key` | `str`       | `None`  | Optional API key for authentication purposes.                 |
| `formats` | `List[str]` | `None`  | Optional list of formats to be used for the operation.        |
| `limit`   | `int`       | `10`    | Maximum number of items to retrieve. The default value is 10. |
| `scrape`  | `bool`      | `True`  | Enables the scraping functionality. Default is True.          |
| `crawl`   | `bool`      | `False` | Enables the crawling functionality. Default is False.         |

## Toolkit Functions

| Function         | Description                                                                                                                                                                                                                                             |
| ---------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `scrape_website` | Scrapes a website using Firecrawl. Parameters include `url` to specify the URL to scrape. The function supports optional formats if specified. Returns the results of the scraping in JSON format.                                                      |
| `crawl_website`  | Crawls a website using Firecrawl. Parameters include `url` to specify the URL to crawl, and an optional `limit` to define the maximum number of pages to crawl. The function supports optional formats and returns the crawling results in JSON format. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/firecrawl.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/firecrawl_tools.py)


# Giphy



**GiphyTools** enables an Agent to search for GIFs on GIPHY.

## Prerequisites

```shell
export GIPHY_API_KEY=***
```

## Example

The following agent will search GIPHY for a GIF appropriate for a birthday message.

```python
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.giphy import GiphyTools


gif_agent = Agent(
    name="Gif Generator Agent",
    model=OpenAIChat(id="gpt-4o"),
    tools=[GiphyTools()],
    description="You are an AI agent that can generate gifs using Giphy.",
)

gif_agent.print_response("I want a gif to send to a friend for their birthday.")
```

## Toolkit Params

| Parameter | Type  | Default | Description                                       |
| --------- | ----- | ------- | ------------------------------------------------- |
| `api_key` | `str` | `None`  | If you want to manually supply the GIPHY API key. |
| `limit`   | `int` | `1`     | The number of GIFs to return in a search.         |

## Toolkit Functions

| Function      | Description                                         |
| ------------- | --------------------------------------------------- |
| `search_gifs` | Searches GIPHY for a GIF based on the query string. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/giphy.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/giphy_tools.py)


# Github



**GithubTools** enables an Agent to access Github repositories and perform tasks such as listing open pull requests, issues and more.

## Prerequisites

The following examples requires the `PyGithub` library and a Github access token which can be obtained from [here](https://github.com/settings/tokens).

```shell
pip install -U PyGithub
```

```shell
export GITHUB_ACCESS_TOKEN=***
```

## Example

The following agent will search Google for the latest news about "Mistral AI":

```python cookbook/tools/github_tools.py
from agno.agent import Agent
from agno.tools.github import GithubTools

agent = Agent(
    instructions=[
        "Use your tools to answer questions about the repo: agno-agi/agno",
        "Do not create any issues or pull requests unless explicitly asked to do so",
    ],
    tools=[GithubTools()],
    show_tool_calls=True,
)

agent.print_response("List open pull requests", markdown=True)
```

## Toolkit Params

| Parameter                  | Type   | Default | Description                                                                                                   |
| -------------------------- | ------ | ------- | ------------------------------------------------------------------------------------------------------------- |
| `access_token`             | `str`  | `None`  | Github access token for authentication. If not provided, will use GITHUB\_ACCESS\_TOKEN environment variable. |
| `base_url`                 | `str`  | `None`  | Optional base URL for Github Enterprise installations.                                                        |
| `search_repositories`      | `bool` | `True`  | Enable searching Github repositories.                                                                         |
| `list_repositories`        | `bool` | `True`  | Enable listing repositories for a user/organization.                                                          |
| `get_repository`           | `bool` | `True`  | Enable getting repository details.                                                                            |
| `list_pull_requests`       | `bool` | `True`  | Enable listing pull requests for a repository.                                                                |
| `get_pull_request`         | `bool` | `True`  | Enable getting pull request details.                                                                          |
| `get_pull_request_changes` | `bool` | `True`  | Enable getting pull request file changes.                                                                     |
| `create_issue`             | `bool` | `True`  | Enable creating issues in repositories.                                                                       |

## Toolkit Functions

| Function                   | Description                                          |
| -------------------------- | ---------------------------------------------------- |
| `search_repositories`      | Searches Github repositories based on a query.       |
| `list_repositories`        | Lists repositories for a given user or organization. |
| `get_repository`           | Gets details about a specific repository.            |
| `list_pull_requests`       | Lists pull requests for a repository.                |
| `get_pull_request`         | Gets details about a specific pull request.          |
| `get_pull_request_changes` | Gets the file changes in a pull request.             |
| `create_issue`             | Creates a new issue in a repository.                 |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/github.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/github_tools.py)


# Gmail



**Gmail** enables an Agent to interact with Gmail, allowing it to read, search, send, and manage emails.

## Prerequisites

The Gmail toolkit requires Google API client libraries and proper authentication setup. Install the required dependencies:

```shell
pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib
```

You'll also need to set up Google Cloud credentials:

1. Go to [Google Cloud Console](https://console.cloud.google.com)
2. Create a project or select an existing one
3. Enable the Gmail API
4. Create OAuth 2.0 credentials
5. Set up environment variables:

```shell
export GOOGLE_CLIENT_ID=your_client_id_here
export GOOGLE_CLIENT_SECRET=your_client_secret_here
export GOOGLE_PROJECT_ID=your_project_id_here
export GOOGLE_REDIRECT_URI=http://localhost  # Default value
```

## Example

```python cookbook/tools/gmail_tools.py
from agno.agent import Agent
from agno.tools.gmail import GmailTools

agent = Agent(tools=[GmailTools()], show_tool_calls=True)
agent.print_response("Show me my latest 5 unread emails", markdown=True)
```

## Toolkit Params

| Parameter               | Type   | Default | Description                                 |
| ----------------------- | ------ | ------- | ------------------------------------------- |
| `get_latest_emails`     | `bool` | `True`  | Enable retrieving latest emails from inbox  |
| `get_emails_from_user`  | `bool` | `True`  | Enable getting emails from specific senders |
| `get_unread_emails`     | `bool` | `True`  | Enable fetching unread emails               |
| `get_starred_emails`    | `bool` | `True`  | Enable retrieving starred emails            |
| `get_emails_by_context` | `bool` | `True`  | Enable searching emails by context          |
| `get_emails_by_date`    | `bool` | `True`  | Enable retrieving emails within date ranges |
| `create_draft_email`    | `bool` | `True`  | Enable creating email drafts                |
| `send_email`            | `bool` | `True`  | Enable sending emails                       |
| `search_emails`         | `bool` | `True`  | Enable searching emails                     |

## Toolkit Functions

| Function                | Description                                        |
| ----------------------- | -------------------------------------------------- |
| `get_latest_emails`     | Get the latest X emails from the user's inbox      |
| `get_emails_from_user`  | Get X number of emails from a specific sender      |
| `get_unread_emails`     | Get the latest X unread emails                     |
| `get_starred_emails`    | Get X number of starred emails                     |
| `get_emails_by_context` | Get X number of emails matching a specific context |
| `get_emails_by_date`    | Get emails within a specific date range            |
| `create_draft_email`    | Create and save an email draft                     |
| `send_email`            | Send an email immediately                          |
| `search_emails`         | Search emails using natural language queries       |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/gmail.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/gmail_tools.py)


# Google Maps

Tools for interacting with Google Maps services including place search, directions, geocoding, and more

**GoogleMapTools** enable an Agent to interact with various Google Maps services for location-based operations including place search, directions, geocoding, and more.

## Prerequisites

The following example requires the `googlemaps` library and an API key which can be obtained from the [Google Cloud Console](https://console.cloud.google.com/projectselector2/google/maps-apis/credentials).

```shell
pip install googlemaps
```

```shell
export GOOGLE_MAPS_API_KEY=your_api_key_here
```

You'll need to enable the following APIs in your Google Cloud Console:

* Places API
* Directions API
* Geocoding API
* Address Validation API
* Distance Matrix API
* Elevation API
* Time Zone API

## Example

Basic usage of the Google Maps toolkit:

```python
from agno.agent import Agent
from agno.tools.google_maps import GoogleMapTools

agent = Agent(tools=[GoogleMapTools()], show_tool_calls=True)
agent.print_response("Find coffee shops in San Francisco")
```

For more examples, see the [Google Maps Tools Examples](/examples/concepts/tools/google_maps).

## Toolkit Params

| Parameter             | Type            | Default | Description                                                                         |
| --------------------- | --------------- | ------- | ----------------------------------------------------------------------------------- |
| `key`                 | `Optional[str]` | `None`  | Optional API key. If not provided, uses GOOGLE\_MAPS\_API\_KEY environment variable |
| `search_places`       | `bool`          | `True`  | Enable places search functionality                                                  |
| `get_directions`      | `bool`          | `True`  | Enable directions functionality                                                     |
| `validate_address`    | `bool`          | `True`  | Enable address validation functionality                                             |
| `geocode_address`     | `bool`          | `True`  | Enable geocoding functionality                                                      |
| `reverse_geocode`     | `bool`          | `True`  | Enable reverse geocoding functionality                                              |
| `get_distance_matrix` | `bool`          | `True`  | Enable distance matrix functionality                                                |
| `get_elevation`       | `bool`          | `True`  | Enable elevation functionality                                                      |
| `get_timezone`        | `bool`          | `True`  | Enable timezone functionality                                                       |

## Toolkit Functions

| Function              | Description                                                                                                                                                                                               |
| --------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `search_places`       | Search for places using Google Maps Places API. Parameters: `query` (str) for the search query. Returns stringified JSON with place details including name, address, phone, website, rating, and hours.   |
| `get_directions`      | Get directions between locations. Parameters: `origin` (str), `destination` (str), optional `mode` (str) for travel mode, optional `avoid` (List\[str]) for features to avoid. Returns route information. |
| `validate_address`    | Validate an address. Parameters: `address` (str), optional `region_code` (str), optional `locality` (str). Returns address validation results.                                                            |
| `geocode_address`     | Convert address to coordinates. Parameters: `address` (str), optional `region` (str). Returns location information with coordinates.                                                                      |
| `reverse_geocode`     | Convert coordinates to address. Parameters: `lat` (float), `lng` (float), optional `result_type` and `location_type` (List\[str]). Returns address information.                                           |
| `get_distance_matrix` | Calculate distances between locations. Parameters: `origins` (List\[str]), `destinations` (List\[str]), optional `mode` (str) and `avoid` (List\[str]). Returns distance and duration matrix.             |
| `get_elevation`       | Get elevation for a location. Parameters: `lat` (float), `lng` (float). Returns elevation data.                                                                                                           |
| `get_timezone`        | Get timezone for a location. Parameters: `lat` (float), `lng` (float), optional `timestamp` (datetime). Returns timezone information.                                                                     |

## Rate Limits

Google Maps APIs have usage limits and quotas that vary by service and billing plan. Please refer to the [Google Maps Platform pricing](https://cloud.google.com/maps-platform/pricing) for details.

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/google_maps.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/google_maps_tools.py)


# Google Calendar



Enable an Agent to work with Google Calendar to view and schedule meetings.

## Prerequisites

### Install dependencies

```shell
pip install tzlocal
```

### Setup Google Project and OAuth

Reference: [https://developers.google.com/calendar/api/quickstart/python](https://developers.google.com/calendar/api/quickstart/python)

1. Enable Google Calender API

   * Go to [Google Cloud Console](https://console.cloud.google.com/apis/enableflow?apiid=calendar-json.googleapis.com).
   * Select Project and Enable.

2. Go To API & Service -> OAuth Consent Screen

3. Select User Type

   * If you are a Google Workspace user, select Internal.
   * Otherwise, select External.

4. Fill in the app details (App name, logo, support email, etc).

5. Select Scope

   * Click on Add or Remove Scope.
   * Search for Google Calender API (Make sure you've enabled Google calender API otherwise scopes wont be visible).
   * Select scopes accordingly
     * From the dropdown check on `/auth/calendar` scope
   * Save and continue.

6. Adding Test User

   * Click Add Users and enter the email addresses of the users you want to allow during testing.
   * NOTE : Only these users can access the app's OAuth functionality when the app is in "Testing" mode.
     Any other users will receive access denied errors.
   * To make the app available to all users, you'll need to move the app's status to "In Production".
     Before doing so, ensure the app is fully verified by Google if it uses sensitive or restricted scopes.
   * Click on Go back to Dashboard.

7. Generate OAuth 2.0 Client ID

   * Go to Credentials.
   * Click on Create Credentials -> OAuth Client ID
   * Select Application Type as Desktop app.
   * Download JSON.

8. Using Google Calender Tool
   * Pass the path of downloaded credentials as credentials\_path to Google Calender tool.
   * Optional: Set the `token_path` parameter to specify where the tool should create the `token.json` file.
   * The `token.json` file is used to store the user's access and refresh tokens and is automatically created during the authorization flow if it doesn't already exist.
   * If `token_path` is not explicitly provided, the file will be created in the default location which is your current working directory.
   * If you choose to specify `token_path`, please ensure that the directory you provide has write access, as the application needs to create or update this file during the authentication process.

## Example

The following agent will use GoogleCalendarTools to find today's events.

```python cookbook/tools/googlecalendar_tools.py
from agno.agent import Agent
from agno.tools.googlecalendar import GoogleCalendarTools
import datetime
import os
from tzlocal import get_localzone_name

agent = Agent(
    tools=[GoogleCalendarTools(credentials_path="<PATH_TO_YOUR_CREDENTIALS_FILE>")],
    show_tool_calls=True,
    instructions=[
        f"""
        You are scheduling assistant . Today is {datetime.datetime.now()} and the users timezone is {get_localzone_name()}.
        You should help users to perform these actions in their Google calendar:
            - get their scheduled events from a certain date and time
            - create events based on provided details
        """
    ],
    add_datetime_to_instructions=True,
)

agent.print_response("Give me the list of todays events", markdown=True)
```

## Toolkit Params

| Parameter          | Type  | Default | Description                                                                    |
| ------------------ | ----- | ------- | ------------------------------------------------------------------------------ |
| `credentials_path` | `str` | `None`  | Path of the file credentials.json file which contains OAuth 2.0 Client ID.     |
| `token_path`       | `str` | `None`  | Path of the file token.json which stores the user's access and refresh tokens. |

## Toolkit Functions

| Function       | Description                                        |
| -------------- | -------------------------------------------------- |
| `list_events`  | List events from the user's primary calendar.      |
| `create_event` | Create a new event in the user's primary calendar. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/googlecalendar.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/googlecalendar_tools.py)


# Google Search



**GoogleSearch** enables an Agent to perform web crawling and scraping tasks.

## Prerequisites

The following examples requires the `googlesearch` and `pycountry` libraries.

```shell
pip install -U googlesearch-python pycountry
```

## Example

The following agent will search Google for the latest news about "Mistral AI":

```python cookbook/tools/googlesearch_tools.py
from agno.agent import Agent
from agno.tools.googlesearch import GoogleSearchTools

agent = Agent(
    tools=[GoogleSearchTools()],
    description="You are a news agent that helps users find the latest news.",
    instructions=[
        "Given a topic by the user, respond with 4 latest news items about that topic.",
        "Search for 10 news items and select the top 4 unique items.",
        "Search in English and in French.",
    ],
    show_tool_calls=True,
    debug_mode=True,
)

agent.print_response("Mistral AI", markdown=True)
```

## Toolkit Params

| Parameter           | Type  | Default | Description                                         |
| ------------------- | ----- | ------- | --------------------------------------------------- |
| `fixed_max_results` | `int` | `None`  | Optional fixed maximum number of results to return. |
| `fixed_language`    | `str` | `None`  | Optional fixed language for the requests.           |
| `headers`           | `Any` | `None`  | Optional headers to include in the requests.        |
| `proxy`             | `str` | `None`  | Optional proxy to be used for the requests.         |
| `timeout`           | `int` | `None`  | Optional timeout for the requests, in seconds.      |

## Toolkit Functions

| Function        | Description                                                                                                                                                                                                                                                                            |
| --------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `google_search` | Searches Google for a specified query. Parameters include `query` for the search term, `max_results` for the maximum number of results (default is 5), and `language` for the language of the search results (default is "en"). Returns the search results as a JSON formatted string. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/googlesearch.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/googlesearch_tools.py)


# Hacker News



**HackerNews** enables an Agent to search Hacker News website.

## Example

The following agent will write an engaging summary of the users with the top 2 stories on hackernews along with the stories.

```python cookbook/tools/hackernews.py
from agno.agent import Agent
from agno.tools.hackernews import HackerNewsTools

agent = Agent(
    name="Hackernews Team",
    tools=[HackerNewsTools()],
    show_tool_calls=True,
    markdown=True,
)

agent.print_response(
    "Write an engaging summary of the "
    "users with the top 2 stories on hackernews. "
    "Please mention the stories as well.",
)
```

## Toolkit Params

| Parameter          | Type   | Default | Description                    |
| ------------------ | ------ | ------- | ------------------------------ |
| `get_top_stories`  | `bool` | `True`  | Enables fetching top stories.  |
| `get_user_details` | `bool` | `True`  | Enables fetching user details. |

## Toolkit Functions

| Function                     | Description                                                                                                                                                                      |
| ---------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `get_top_hackernews_stories` | Retrieves the top stories from Hacker News. Parameters include `num_stories` to specify the number of stories to return (default is 10). Returns the top stories in JSON format. |
| `get_user_details`           | Retrieves the details of a Hacker News user by their username. Parameters include `username` to specify the user. Returns the user details in JSON format.                       |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/hackernews.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/hackernews_tools.py)


# Jina Reader



**JinaReaderTools** enable an Agent to perform web search tasks using Jina.

## Prerequisites

The following example requires the `jina` library.

```shell
pip install -U jina
```

## Example

The following agent will use Jina API to summarize the content of [https://github.com/AgnoAgi](https://github.com/AgnoAgi)

```python cookbook/tools/jinareader.py
from agno.agent import Agent
from agno.tools.jina import JinaReaderTools

agent = Agent(tools=[JinaReaderTools()])
agent.print_response("Summarize: https://github.com/AgnoAgi")
```

## Toolkit Params

| Parameter            | Type  | Default | Description                                                                |
| -------------------- | ----- | ------- | -------------------------------------------------------------------------- |
| `api_key`            | `str` | -       | The API key for authentication purposes, retrieved from the configuration. |
| `base_url`           | `str` | -       | The base URL of the API, retrieved from the configuration.                 |
| `search_url`         | `str` | -       | The URL used for search queries, retrieved from the configuration.         |
| `max_content_length` | `int` | -       | The maximum length of content allowed, retrieved from the configuration.   |

## Toolkit Functions

| Function       | Description                                                                                                                                                                                            |
| -------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `read_url`     | Reads the content of a specified URL using Jina Reader API. Parameters include `url` for the URL to read. Returns the truncated content or an error message if the request fails.                      |
| `search_query` | Performs a web search using Jina Reader API based on a specified query. Parameters include `query` for the search term. Returns the truncated search results or an error message if the request fails. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/jina_reader.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/jina_reader_tools.py)


# Jira



**JiraTools** enable an Agent to perform Jira tasks.

## Prerequisites

The following example requires the `jira` library and auth credentials.

```shell
pip install -U jira
```

```shell
export JIRA_SERVER_URL="YOUR_JIRA_SERVER_URL"
export JIRA_USERNAME="YOUR_USERNAME"
export JIRA_API_TOKEN="YOUR_API_TOKEN"
```

## Example

The following agent will use Jira API to search for issues in a project.

```python cookbook/tools/jira_tools.py
from agno.agent import Agent
from agno.tools.jira import JiraTools

agent = Agent(tools=[JiraTools()])
agent.print_response("Find all issues in project PROJ", markdown=True)
```

## Toolkit Params

| Parameter    | Type  | Default | Description                                                                                                                   |
| ------------ | ----- | ------- | ----------------------------------------------------------------------------------------------------------------------------- |
| `server_url` | `str` | `""`    | The URL of the JIRA server, retrieved from the environment variable `JIRA_SERVER_URL`. Default is an empty string if not set. |
| `username`   | `str` | `None`  | The JIRA username for authentication, retrieved from the environment variable `JIRA_USERNAME`. Default is None if not set.    |
| `password`   | `str` | `None`  | The JIRA password for authentication, retrieved from the environment variable `JIRA_PASSWORD`. Default is None if not set.    |
| `token`      | `str` | `None`  | The JIRA API token for authentication, retrieved from the environment variable `JIRA_TOKEN`. Default is None if not set.      |

## Toolkit Functions

| Function        | Description                                                                                                                                                                                                                                                                                                                                |
| --------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `get_issue`     | Retrieves issue details from JIRA. Parameters include:<br />- `issue_key`: the key of the issue to retrieve<br />Returns a JSON string containing issue details or an error message.                                                                                                                                                       |
| `create_issue`  | Creates a new issue in JIRA. Parameters include:<br />- `project_key`: the project in which to create the issue<br />- `summary`: the issue summary<br />- `description`: the issue description<br />- `issuetype`: the type of issue (default is "Task")<br />Returns a JSON string with the new issue's key and URL or an error message. |
| `search_issues` | Searches for issues using a JQL query in JIRA. Parameters include:<br />- `jql_str`: the JQL query string<br />- `max_results`: the maximum number of results to return (default is 50)<br />Returns a JSON string containing a list of dictionaries with issue details or an error message.                                               |
| `add_comment`   | Adds a comment to an issue in JIRA. Parameters include:<br />- `issue_key`: the key of the issue<br />- `comment`: the comment text<br />Returns a JSON string indicating success or an error message.                                                                                                                                     |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/jira.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/jira_tools.py)


# Linear



**LinearTool** enable an Agent to perform [Linear](https://linear.app/) tasks.

## Prerequisites

```shell
export LINEAR_API_KEY="LINEAR_API_KEY"
```

## Example

The following agent will use Linear API to search for issues in a project for a specific user.

```python cookbook/tools/linear_tools.py
from agno.agent import Agent
from agno.tools.linear import LinearTools

agent = Agent(
    name="Linear Tool Agent",
    tools=[LinearTools()],
    show_tool_calls=True,
    markdown=True,
)

agent.print_response("Show all the issues assigned to user id: 12021")
```

## Toolkit Params

| Parameter                  | Type   | Default | Description                             |
| -------------------------- | ------ | ------- | --------------------------------------- |
| `get_user_details`         | `bool` | `True`  | Enable `get_user_details` tool.         |
| `get_issue_details`        | `bool` | `True`  | Enable `get_issue_details` tool.        |
| `create_issue`             | `bool` | `True`  | Enable `create_issue` tool.             |
| `update_issue`             | `bool` | `True`  | Enable `update_issue` tool.             |
| `get_user_assigned_issues` | `bool` | `True`  | Enable `get_user_assigned_issues` tool. |
| `get_workflow_issues`      | `bool` | `True`  | Enable `get_workflow_issues` tool.      |
| `get_high_priority_issues` | `bool` | `True`  | Enable `get_high_priority_issues` tool. |

## Toolkit Functions

| Function                   | Description                                                      |
| -------------------------- | ---------------------------------------------------------------- |
| `get_user_details`         | Fetch authenticated user details.                                |
| `get_issue_details`        | Retrieve details of a specific issue by issue ID.                |
| `create_issue`             | Create a new issue within a specific project and team.           |
| `update_issue`             | Update the title or state of a specific issue by issue ID.       |
| `get_user_assigned_issues` | Retrieve issues assigned to a specific user by user ID.          |
| `get_workflow_issues`      | Retrieve issues within a specific workflow state by workflow ID. |
| `get_high_priority_issues` | Retrieve issues with a high priority (priority `<=` 2).          |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/linear.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/linear_tools.py)


# Lumalabs



**LumaLabTools** enables an Agent to generate media using the [Lumalabs platform](https://lumalabs.ai/dream-machine).

## Prerequisites

```shell
export LUMAAI_API_KEY=***
```

The following example requires the `lumaai` library. To install the Lumalabs client, run the following command:

```shell
pip install -U lumaai
```

## Example

The following agent will use Lumalabs to generate any video requested by the user.

```python cookbook/tools/lumalabs_tool.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.lumalab import LumaLabTools

luma_agent = Agent(
    name="Luma Video Agent",
    model=OpenAIChat(id="gpt-4o"),
    tools=[LumaLabTools()],  # Using the LumaLab tool we created
    markdown=True,
    debug_mode=True,
    show_tool_calls=True,
    instructions=[
        "You are an agent designed to generate videos using the Luma AI API.",
        "You can generate videos in two ways:",
        "1. Text-to-Video Generation:",
        "2. Image-to-Video Generation:",
        "Choose the appropriate function based on whether the user provides image URLs or just a text prompt.",
        "The video will be displayed in the UI automatically below your response, so you don't need to show the video URL in your response.",
    ],
    system_message=(
        "Use generate_video for text-to-video requests and image_to_video for image-based "
        "generation. Don't modify default parameters unless specifically requested. "
        "Always provide clear feedback about the video generation status."
    ),
)

luma_agent.run("Generate a video of a car in a sky")
```

## Toolkit Params

| Parameter | Type  | Default | Description                                          |
| --------- | ----- | ------- | ---------------------------------------------------- |
| `api_key` | `str` | `None`  | If you want to manually supply the Lumalabs API key. |

## Toolkit Functions

| Function         | Description                                                           |
| ---------------- | --------------------------------------------------------------------- |
| `generate_video` | Generate a video from a prompt.                                       |
| `image_to_video` | Generate a video from a prompt, a starting image and an ending image. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/lumalabs.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/lumalabs_tools.py)


# MLX Transcribe



**MLX Transcribe** is a tool for transcribing audio files using MLX Whisper.

## Prerequisites

1. **Install ffmpeg**

   * macOS: `brew install ffmpeg`
   * Ubuntu: `sudo apt-get install ffmpeg`
   * Windows: Download from [https://ffmpeg.org/download.html](https://ffmpeg.org/download.html)

2. **Install mlx-whisper library**

   ```shell
   pip install mlx-whisper
   ```

3. **Prepare audio files**

   * Create a 'storage/audio' directory
   * Place your audio files in this directory
   * Supported formats: mp3, mp4, wav, etc.

4. **Download sample audio** (optional)
   * Visit the [audio-samples](https://audio-samples.github.io/) (as an example) and save the audio file to the `storage/audio` directory.

## Example

The following agent will use MLX Transcribe to transcribe audio files.

```python cookbook/tools/mlx_transcribe_tools.py

from pathlib import Path
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.mlx_transcribe import MLXTranscribeTools

# Get audio files from storage/audio directory
agno_root_dir = Path(__file__).parent.parent.parent.resolve()
audio_storage_dir = agno_root_dir.joinpath("storage/audio")
if not audio_storage_dir.exists():
    audio_storage_dir.mkdir(exist_ok=True, parents=True)

agent = Agent(
    name="Transcription Agent",
    model=OpenAIChat(id="gpt-4o"),
    tools=[MLXTranscribeTools(base_dir=audio_storage_dir)],
    instructions=[
        "To transcribe an audio file, use the `transcribe` tool with the name of the audio file as the argument.",
        "You can find all available audio files using the `read_files` tool.",
    ],
    markdown=True,
)

agent.print_response("Summarize the reid hoffman ted talk, split into sections", stream=True)
```

## Toolkit Params

| Parameter                         | Type                           | Default                                  | Description                                  |
| --------------------------------- | ------------------------------ | ---------------------------------------- | -------------------------------------------- |
| `base_dir`                        | `Path`                         | `Path.cwd()`                             | Base directory for audio files               |
| `read_files_in_base_dir`          | `bool`                         | `True`                                   | Whether to register the read\_files function |
| `path_or_hf_repo`                 | `str`                          | `"mlx-community/whisper-large-v3-turbo"` | Path or HuggingFace repo for the model       |
| `verbose`                         | `bool`                         | `None`                                   | Enable verbose output                        |
| `temperature`                     | `float` or `Tuple[float, ...]` | `None`                                   | Temperature for sampling                     |
| `compression_ratio_threshold`     | `float`                        | `None`                                   | Compression ratio threshold                  |
| `logprob_threshold`               | `float`                        | `None`                                   | Log probability threshold                    |
| `no_speech_threshold`             | `float`                        | `None`                                   | No speech threshold                          |
| `condition_on_previous_text`      | `bool`                         | `None`                                   | Whether to condition on previous text        |
| `initial_prompt`                  | `str`                          | `None`                                   | Initial prompt for transcription             |
| `word_timestamps`                 | `bool`                         | `None`                                   | Enable word-level timestamps                 |
| `prepend_punctuations`            | `str`                          | `None`                                   | Punctuations to prepend                      |
| `append_punctuations`             | `str`                          | `None`                                   | Punctuations to append                       |
| `clip_timestamps`                 | `str` or `List[float]`         | `None`                                   | Clip timestamps                              |
| `hallucination_silence_threshold` | `float`                        | `None`                                   | Hallucination silence threshold              |
| `decode_options`                  | `dict`                         | `None`                                   | Additional decoding options                  |

## Toolkit Functions

| Function     | Description                                 |
| ------------ | ------------------------------------------- |
| `transcribe` | Transcribes an audio file using MLX Whisper |
| `read_files` | Lists all audio files in the base directory |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/mlx_transcribe.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/mlx_transcribe_tools.py)


# ModelsLabs



## Prerequisites

You need to install the `requests` library.

```bash
pip install requests
```

Set the `MODELS_LAB_API_KEY` environment variable.

```bash
export MODELS_LAB_API_KEY=****
```

## Example

The following agent will use ModelsLabs to generate a video based on a text prompt.

```python cookbook/tools/models_labs_tools.py
from agno.agent import Agent
from agno.tools.models_labs import ModelsLabsTools

# Create an Agent with the ModelsLabs tool
agent = Agent(tools=[ModelsLabsTools()], name="ModelsLabs Agent")

agent.print_response("Generate a video of a beautiful sunset over the ocean", markdown=True)
```

## Toolkit Params

| Parameter             | Type   | Default                                           | Description                                                                |
| --------------------- | ------ | ------------------------------------------------- | -------------------------------------------------------------------------- |
| `api_key`             | `str`  | `None`                                            | The ModelsLab API key for authentication                                   |
| `url`                 | `str`  | `"https://modelslab.com/api/v6/video/text2video"` | The API endpoint URL                                                       |
| `fetch_url`           | `str`  | `https://modelslab.com/api/v6/video/fetch`        | The URL to fetch the video status from                                     |
| `wait_for_completion` | `bool` | `False`                                           | Whether to wait for the video to be ready                                  |
| `add_to_eta`          | `int`  | `15`                                              | Time to add to the ETA to account for the time it takes to fetch the video |
| `max_wait_time`       | `int`  | `60`                                              | Maximum time to wait for the video to be ready                             |
| `file_type`           | `str`  | `"mp4"`                                           | The type of file to generate                                               |

## Toolkit Functions

| Function         | Description                                     |
| ---------------- | ----------------------------------------------- |
| `generate_media` | Generates a video or gif based on a text prompt |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/models_labs.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/models_labs_tools.py)


# Newspaper



**NewspaperTools** enable an Agent to read news articles using the Newspaper4k library.

## Prerequisites

The following example requires the `newspaper3k` library.

```shell
pip install -U newspaper3k
```

## Example

The following agent will summarize the wikipedia article on language models.

```python cookbook/tools/newspaper_tools.py
from agno.agent import Agent
from agno.tools.newspaper import NewspaperTools

agent = Agent(tools=[NewspaperTools()])
agent.print_response("Please summarize https://en.wikipedia.org/wiki/Language_model")
```

## Toolkit Params

| Parameter          | Type   | Default | Description                                                   |
| ------------------ | ------ | ------- | ------------------------------------------------------------- |
| `get_article_text` | `bool` | `True`  | Enables the functionality to retrieve the text of an article. |

## Toolkit Functions

| Function           | Description                                                                                                                                                                             |
| ------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `get_article_text` | Retrieves the text of an article from a specified URL. Parameters include `url` for the URL of the article. Returns the text of the article or an error message if the retrieval fails. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/newspaper.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/newspaper_tools.py)


# Newspaper4k



**Newspaper4k** enables an Agent to read news articles using the Newspaper4k library.

## Prerequisites

The following example requires the `newspaper4k` and `lxml_html_clean` libraries.

```shell
pip install -U newspaper4k lxml_html_clean
```

## Example

The following agent will summarize the article: [https://www.rockymountaineer.com/blog/experience-icefields-parkway-scenic-drive-lifetime](https://www.rockymountaineer.com/blog/experience-icefields-parkway-scenic-drive-lifetime).

```python cookbook/tools/newspaper4k_tools.py
from agno.agent import Agent
from agno.tools.newspaper4k import Newspaper4kTools

agent = Agent(tools=[Newspaper4kTools()], debug_mode=True, show_tool_calls=True)
agent.print_response("Please summarize https://www.rockymountaineer.com/blog/experience-icefields-parkway-scenic-drive-lifetime")
```

## Toolkit Params

| Parameter         | Type   | Default | Description                                                                        |
| ----------------- | ------ | ------- | ---------------------------------------------------------------------------------- |
| `read_article`    | `bool` | `True`  | Enables the functionality to read the full content of an article.                  |
| `include_summary` | `bool` | `False` | Specifies whether to include a summary of the article along with the full content. |
| `article_length`  | `int`  | -       | The maximum length of the article or its summary to be processed or returned.      |

## Toolkit Functions

| Function           | Description                                                  |
| ------------------ | ------------------------------------------------------------ |
| `get_article_data` | This function reads the full content and data of an article. |
| `read_article`     | This function reads the full content of an article.          |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/newspaper4k.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/newspaper4k_tools.py)


# OpenBB



**OpenBBTools** enable an Agent to provide information about stocks and companies.

```python cookbook/tools/openbb_tools.py
from agno.agent import Agent
from agno.tools.openbb import OpenBBTools


agent = Agent(tools=[OpenBBTools()], debug_mode=True, show_tool_calls=True)

# Example usage showing stock analysis
agent.print_response(
    "Get me the current stock price and key information for Apple (AAPL)"
)

# Example showing market analysis
agent.print_response(
    "What are the top gainers in the market today?"
)

# Example showing economic indicators
agent.print_response(
    "Show me the latest GDP growth rate and inflation numbers for the US"
)
```

## Toolkit Params

| Parameter         | Type   | Default | Description                                                                        |
| ----------------- | ------ | ------- | ---------------------------------------------------------------------------------- |
| `read_article`    | `bool` | `True`  | Enables the functionality to read the full content of an article.                  |
| `include_summary` | `bool` | `False` | Specifies whether to include a summary of the article along with the full content. |
| `article_length`  | `int`  | -       | The maximum length of the article or its summary to be processed or returned.      |

## Toolkit Functions

| Function                | Description                                                                       |
| ----------------------- | --------------------------------------------------------------------------------- |
| `get_stock_price`       | This function gets the current stock price for a stock symbol or list of symbols. |
| `search_company_symbol` | This function searches for the stock symbol of a company.                         |
| `get_price_targets`     | This function gets the price targets for a stock symbol or list of symbols.       |
| `get_company_news`      | This function gets the latest news for a stock symbol or list of symbols.         |
| `get_company_profile`   | This function gets the company profile for a stock symbol or list of symbols.     |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/openbb.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/openbb_tools.py)


# Pandas



**PandasTools** enable an Agent to perform data manipulation tasks using the Pandas library.

```python cookbook/tools/pandas_tool.py
from agno.agent import Agent
from agno.tools.pandas import PandasTools

# Create an agent with PandasTools
agent = Agent(tools=[PandasTools()])

# Example: Create a dataframe with sample data and get the first 5 rows
agent.print_response("""
Please perform these tasks:
1. Create a pandas dataframe named 'sales_data' using DataFrame() with this sample data:
   {'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],
    'product': ['Widget A', 'Widget B', 'Widget A', 'Widget C', 'Widget B'],
    'quantity': [10, 15, 8, 12, 20],
    'price': [9.99, 15.99, 9.99, 12.99, 15.99]}
2. Show me the first 5 rows of the sales_data dataframe
""")
```

## Toolkit Params

| Parameter                 | Type                      | Default | Description                                                    |
| ------------------------- | ------------------------- | ------- | -------------------------------------------------------------- |
| `dataframes`              | `Dict[str, pd.DataFrame]` | `{}`    | A dictionary to store Pandas DataFrames, keyed by their names. |
| `create_pandas_dataframe` | `function`                | -       | Registers a function to create a Pandas DataFrame.             |
| `run_dataframe_operation` | `function`                | -       | Registers a function to run operations on a Pandas DataFrame.  |

## Toolkit Functions

| Function                  | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
| ------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `create_pandas_dataframe` | Creates a Pandas DataFrame named `dataframe_name` by using the specified function `create_using_function` with parameters `function_parameters`. Parameters include 'dataframe\_name' for the name of the DataFrame, 'create\_using\_function' for the function to create it (e.g., 'read\_csv'), and 'function\_parameters' for the arguments required by the function. Returns the name of the created DataFrame if successful, otherwise returns an error message. |
| `run_dataframe_operation` | Runs a specified operation `operation` on a DataFrame `dataframe_name` with the parameters `operation_parameters`. Parameters include 'dataframe\_name' for the DataFrame to operate on, 'operation' for the operation to perform (e.g., 'head', 'tail'), and 'operation\_parameters' for the arguments required by the operation. Returns the result of the operation if successful, otherwise returns an error message.                                             |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/pandas.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/pandas_tools.py)


# Postgres



**PostgresTools** enable an Agent to interact with a PostgreSQL database.

## Prerequisites

The following example requires the `psycopg2` library.

```shell
pip install -U psycopg2
```

You will also need a database. The following example uses a Postgres database running in a Docker container.

```shell
docker run -d \
  -e POSTGRES_DB=ai \
  -e POSTGRES_USER=ai \
  -e POSTGRES_PASSWORD=ai \
  -e PGDATA=/var/lib/postgresql/data/pgdata \
  -v pgvolume:/var/lib/postgresql/data \
  -p 5532:5432 \
  --name pgvector \
  agno/pgvector:16
```

## Example

The following agent will list all tables in the database.

```python cookbook/tools/postgres.py
from agno.agent import Agent
from agno.tools.postgres import PostgresTools

# Initialize PostgresTools with connection details
postgres_tools = PostgresTools(
    host="localhost",
    port=5532,
    db_name="ai",
    user="ai",
    password="ai"
)

# Create an agent with the PostgresTools
agent = Agent(tools=[postgres_tools])

# Example: Ask the agent to run a SQL query
agent.print_response("""
Please run a SQL query to get all users from the users table
who signed up in the last 30 days
""")
```

## Toolkit Params

| Name               | Type                             | Default | Description                                      |
| ------------------ | -------------------------------- | ------- | ------------------------------------------------ |
| `connection`       | `psycopg2.extensions.connection` | `None`  | Optional database connection object.             |
| `db_name`          | `str`                            | `None`  | Optional name of the database to connect to.     |
| `user`             | `str`                            | `None`  | Optional username for database authentication.   |
| `password`         | `str`                            | `None`  | Optional password for database authentication.   |
| `host`             | `str`                            | `None`  | Optional host for the database connection.       |
| `port`             | `int`                            | `None`  | Optional port for the database connection.       |
| `run_queries`      | `bool`                           | `True`  | Enables running SQL queries.                     |
| `inspect_queries`  | `bool`                           | `False` | Enables inspecting SQL queries before execution. |
| `summarize_tables` | `bool`                           | `True`  | Enables summarizing table structures.            |
| `export_tables`    | `bool`                           | `False` | Enables exporting tables from the database.      |

## Toolkit Functions

| Function               | Description                                                                                                                                                                                                                                                                                             |
| ---------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `show_tables`          | Retrieves and displays a list of tables in the database. Returns the list of tables.                                                                                                                                                                                                                    |
| `describe_table`       | Describes the structure of a specified table by returning its columns, data types, and maximum character length. Parameters include 'table' to specify the table name. Returns the table description.                                                                                                   |
| `summarize_table`      | Summarizes a table by computing aggregates such as min, max, average, standard deviation, and non-null counts for numeric columns. Parameters include 'table' to specify the table name, and an optional 'table\_schema' to specify the schema (default is "public"). Returns the summary of the table. |
| `inspect_query`        | Inspects an SQL query by returning the query plan. Parameters include 'query' to specify the SQL query. Returns the query plan.                                                                                                                                                                         |
| `export_table_to_path` | Exports a specified table in CSV format to a given path. Parameters include 'table' to specify the table name and an optional 'path' to specify where to save the file (default is the current directory). Returns the result of the export operation.                                                  |
| `run_query`            | Executes an SQL query and returns the result. Parameters include 'query' to specify the SQL query. Returns the result of the query execution.                                                                                                                                                           |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/postgres.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/postgres_tools.py)


# Pubmed



**PubmedTools** enable an Agent to search for Pubmed for articles.

## Example

The following agent will search Pubmed for articles related to "ulcerative colitis".

```python cookbook/tools/pubmed.py
from agno.agent import Agent
from agno.tools.pubmed import PubmedTools

agent = Agent(tools=[PubmedTools()], show_tool_calls=True)
agent.print_response("Tell me about ulcerative colitis.")
```

## Toolkit Params

| Parameter     | Type  | Default                    | Description                                                            |
| ------------- | ----- | -------------------------- | ---------------------------------------------------------------------- |
| `email`       | `str` | `"your_email@example.com"` | Specifies the email address to use.                                    |
| `max_results` | `int` | `None`                     | Optional parameter to specify the maximum number of results to return. |

## Toolkit Functions

| Function        | Description                                                                                                                                                                                                                                                                                 |
| --------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `search_pubmed` | Searches PubMed for articles based on a specified query. Parameters include `query` for the search term and `max_results` for the maximum number of results to return (default is 10). Returns a JSON string containing the search results, including publication date, title, and summary. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/pubmed.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/pubmed_tools.py)


# Python



**PythonTools** enable an Agent to write and run python code.

## Example

The following agent will write a python script that creates the fibonacci series, save it to a file, run it and return the result.

```python cookbook/tools/python_tools.py
from agno.agent import Agent
from agno.tools.python import PythonTools

agent = Agent(tools=[PythonTools()], show_tool_calls=True)
agent.print_response("Write a python script for fibonacci series and display the result till the 10th number")
```

## Toolkit Params

| Parameter      | Type   | Default | Description                                                                                             |
| -------------- | ------ | ------- | ------------------------------------------------------------------------------------------------------- |
| `base_dir`     | `Path` | `None`  | Specifies the base directory for operations. Default is None, indicating the current working directory. |
| `save_and_run` | `bool` | `True`  | If True, saves and runs the code. Useful for execution of scripts after saving.                         |
| `pip_install`  | `bool` | `False` | Enables pip installation of required packages before running the code.                                  |
| `run_code`     | `bool` | `False` | Determines whether the code should be executed.                                                         |
| `list_files`   | `bool` | `False` | If True, lists all files in the specified base directory.                                               |
| `run_files`    | `bool` | `False` | If True, runs the Python files found in the specified directory.                                        |
| `read_files`   | `bool` | `False` | If True, reads the contents of the files in the specified directory.                                    |
| `safe_globals` | `dict` | -       | Specifies a dictionary of global variables that are considered safe to use during the execution.        |
| `safe_locals`  | `dict` | -       | Specifies a dictionary of local variables that are considered safe to use during the execution.         |

## Toolkit Functions

| Function                          | Description                                                                                                                                                                                                                                                            |
| --------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `save_to_file_and_run`            | This function saves Python code to a file called `file_name` and then runs it. If successful, returns the value of `variable_to_return` if provided otherwise returns a success message. If failed, returns an error message. Make sure the file\_name ends with `.py` |
| `run_python_file_return_variable` | This function runs code in a Python file. If successful, returns the value of `variable_to_return` if provided otherwise returns a success message. If failed, returns an error message.                                                                               |
| `read_file`                       | Reads the contents of the file `file_name` and returns the contents if successful.                                                                                                                                                                                     |
| `list_files`                      | Returns a list of files in the base directory                                                                                                                                                                                                                          |
| `run_python_code`                 | This function runs Python code in the current environment. If successful, returns the value of `variable_to_return` if provided otherwise returns a success message. If failed, returns an error message.                                                              |
| `pip_install_package`             | This function installs a package using pip in the current environment. If successful, returns a success message. If failed, returns an error message.                                                                                                                  |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/python.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/python_tools.py)


# Replicate



**ReplicateTools** enables an Agent to generate media using the [Replicate platform](https://replicate.com/).

## Prerequisites

```shell
export REPLICATE_API_TOKEN=***
```

The following example requires the `replicate` library. To install the Replicate client, run the following command:

```shell
pip install -U replicate
```

## Example

The following agent will use Replicate to generate images or videos requested by the user.

```python cookbook/tools/replicate_tool.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.replicate import ReplicateTools

"""Create an agent specialized for Replicate AI content generation"""

image_agent = Agent(
    name="Image Generator Agent",
    model=OpenAIChat(id="gpt-4o"),
    tools=[ReplicateTools(model="luma/photon-flash")],
    description="You are an AI agent that can generate images using the Replicate API.",
    instructions=[
        "When the user asks you to create an image, use the `generate_media` tool to create the image.",
        "Return the URL as raw to the user.",
        "Don't convert image URL to markdown or anything else.",
    ],
    markdown=True,
    debug_mode=True,
    show_tool_calls=True,
)

image_agent.print_response("Generate an image of a horse in the dessert.")
```

## Toolkit Params

| Parameter | Type  | Default            | Description                                                          |
| --------- | ----- | ------------------ | -------------------------------------------------------------------- |
| `api_key` | `str` | `None`             | If you want to manually supply the Replicate API key.                |
| `model`   | `str` | `minimax/video-01` | The replicate model to use. Find out more on the Replicate platform. |

## Toolkit Functions

| Function         | Description                                                                         |
| ---------------- | ----------------------------------------------------------------------------------- |
| `generate_media` | Generate either an image or a video from a prompt. The output depends on the model. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/replicate.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/replicate_tools.py)


# Resend



**ResendTools** enable an Agent to send emails using Resend

## Prerequisites

The following example requires the `resend` library and an API key from [Resend](https://resend.com/).

```shell
pip install -U resend
```

```shell
export RESEND_API_KEY=***
```

## Example

The following agent will send an email using Resend

```python cookbook/tools/resend_tools.py
from agno.agent import Agent
from agno.tools.resend import ResendTools

from_email = "<enter_from_email>"
to_email = "<enter_to_email>"

agent = Agent(tools=[ResendTools(from_email=from_email)], show_tool_calls=True)
agent.print_response(f"Send an email to {to_email} greeting them with hello world")
```

## Toolkit Params

| Parameter    | Type  | Default | Description                                                   |
| ------------ | ----- | ------- | ------------------------------------------------------------- |
| `api_key`    | `str` | -       | API key for authentication purposes.                          |
| `from_email` | `str` | -       | The email address used as the sender in email communications. |

## Toolkit Functions

| Function     | Description                         |
| ------------ | ----------------------------------- |
| `send_email` | Send an email using the Resend API. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/resend.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/resend_tools.py)


# Searxng



## Example

**Searxng** enables an Agent to search the web for a query, scrape a website, or crawl a website.

```python cookbook/tools/searxng_tools.py
from agno.agent import Agent
from agno.tools.searxng import SearxngTools

# Initialize Searxng with your Searxng instance URL
searxng = SearxngTools(
    host="http://localhost:53153",
    engines=[],
    fixed_max_results=5,
    news=True,
    science=True
)

# Create an agent with Searxng
agent = Agent(tools=[searxng])

# Example: Ask the agent to search using Searxng
agent.print_response("""
Please search for information about artificial intelligence
and summarize the key points from the top results
""")
```

## Toolkit Params

| Parameter           | Type        | Default | Description                                                        |
| ------------------- | ----------- | ------- | ------------------------------------------------------------------ |
| `host`              | `str`       | -       | The host for the connection.                                       |
| `engines`           | `List[str]` | `[]`    | A list of search engines to use.                                   |
| `fixed_max_results` | `int`       | `None`  | Optional parameter to specify the fixed maximum number of results. |
| `images`            | `bool`      | `False` | Enables searching for images.                                      |
| `it`                | `bool`      | `False` | Enables searching for IT-related content.                          |
| `map`               | `bool`      | `False` | Enables searching for maps.                                        |
| `music`             | `bool`      | `False` | Enables searching for music.                                       |
| `news`              | `bool`      | `False` | Enables searching for news.                                        |
| `science`           | `bool`      | `False` | Enables searching for science-related content.                     |
| `videos`            | `bool`      | `False` | Enables searching for videos.                                      |

## Toolkit Functions

| Function         | Description                                                                                                                                                                                                                         |
| ---------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `search`         | Performs a general web search using the specified query. Parameters include `query` for the search term and `max_results` for the maximum number of results (default is 5). Returns the search results.                             |
| `image_search`   | Performs an image search using the specified query. Parameters include `query` for the search term and `max_results` for the maximum number of results (default is 5). Returns the image search results.                            |
| `it_search`      | Performs a search for IT-related information using the specified query. Parameters include `query` for the search term and `max_results` for the maximum number of results (default is 5). Returns the IT-related search results.   |
| `map_search`     | Performs a search for maps using the specified query. Parameters include `query` for the search term and `max_results` for the maximum number of results (default is 5). Returns the map search results.                            |
| `music_search`   | Performs a search for music-related information using the specified query. Parameters include `query` for the search term and `max_results` for the maximum number of results (default is 5). Returns the music search results.     |
| `news_search`    | Performs a search for news using the specified query. Parameters include `query` for the search term and `max_results` for the maximum number of results (default is 5). Returns the news search results.                           |
| `science_search` | Performs a search for science-related information using the specified query. Parameters include `query` for the search term and `max_results` for the maximum number of results (default is 5). Returns the science search results. |
| `video_search`   | Performs a search for videos using the specified query. Parameters include `query` for the search term and `max_results` for the maximum number of results (default is 5). Returns the video search results.                        |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/searxng.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/searxng_tools.py)


# Serpapi



**SerpApiTools** enable an Agent to search Google and YouTube for a query.

## Prerequisites

The following example requires the `google-search-results` library and an API key from [SerpApi](https://serpapi.com/).

```shell
pip install -U google-search-results
```

```shell
export SERPAPI_API_KEY=***
```

## Example

The following agent will search Google for the query: "Whats happening in the USA" and share results.

```python cookbook/tools/serpapi_tools.py
from agno.agent import Agent
from agno.tools.serpapi import SerpApiTools

agent = Agent(tools=[SerpApiTools()])
agent.print_response("Whats happening in the USA?", markdown=True)
```

## Toolkit Params

| Parameter        | Type   | Default | Description                                                 |
| ---------------- | ------ | ------- | ----------------------------------------------------------- |
| `api_key`        | `str`  | -       | API key for authentication purposes.                        |
| `search_youtube` | `bool` | `False` | Enables the functionality to search for content on YouTube. |

## Toolkit Functions

| Function         | Description                                |
| ---------------- | ------------------------------------------ |
| `search_google`  | This function searches Google for a query. |
| `search_youtube` | Searches YouTube for a query.              |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/serpapi.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/serpapi_tools.py)


# Shell



**ShellTools** enable an Agent to interact with the shell to run commands.

## Example

The following agent will run a shell command and show contents of the current directory.

<Note>
  Mention your OS to the agent to make sure it runs the correct command.
</Note>

```python cookbook/tools/shell_tools.py
from agno.agent import Agent
from agno.tools.shell import ShellTools

agent = Agent(tools=[ShellTools()], show_tool_calls=True)
agent.print_response("Show me the contents of the current directory", markdown=True)
```

## Functions in Toolkit

| Function            | Description                                           |
| ------------------- | ----------------------------------------------------- |
| `run_shell_command` | Runs a shell command and returns the output or error. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/shell.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/shell_tools.py)


# Slack



## Prerequisites

The following example requires the `slack-sdk` library.

```shell
pip install openai slack-sdk
```

Get a Slack token from [here](https://api.slack.com/tutorials/tracks/getting-a-token).

```shell
export SLACK_TOKEN=***
```

## Example

The following agent will use Slack to send a message to a channel, list all channels, and get the message history of a specific channel.

```python cookbook/tools/slack_tools.py
import os

from agno.agent import Agent
from agno.tools.slack import SlackTools

slack_tools = SlackTools()

agent = Agent(tools=[slack_tools], show_tool_calls=True)

# Example 1: Send a message to a Slack channel
agent.print_response("Send a message 'Hello from Agno!' to the channel #general", markdown=True)

# Example 2: List all channels in the Slack workspace
agent.print_response("List all channels in our Slack workspace", markdown=True)

# Example 3: Get the message history of a specific channel by channel ID
agent.print_response("Get the last 10 messages from the channel 1231241", markdown=True)

```

## Toolkit Params

| Parameter             | Type   | Default | Description                                                         |
| --------------------- | ------ | ------- | ------------------------------------------------------------------- |
| `token`               | `str`  | -       | Slack API token for authentication                                  |
| `send_message`        | `bool` | `True`  | Enables the functionality to send messages to Slack channels        |
| `list_channels`       | `bool` | `True`  | Enables the functionality to list available Slack channels          |
| `get_channel_history` | `bool` | `True`  | Enables the functionality to retrieve message history from channels |

## Toolkit Functions

| Function              | Description                                         |
| --------------------- | --------------------------------------------------- |
| `send_message`        | Sends a message to a specified Slack channel        |
| `list_channels`       | Lists all available channels in the Slack workspace |
| `get_channel_history` | Retrieves message history from a specified channel  |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/slack.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/slack_tools.py)


# Sleep



## Example

The following agent will use the `sleep` tool to pause execution for a given number of seconds.

```python cookbook/tools/sleep_tools.py
from agno.agent import Agent
from agno.tools.sleep import SleepTools

# Create an Agent with the Sleep tool
agent = Agent(tools=[SleepTools()], name="Sleep Agent")

# Example 1: Sleep for 2 seconds
agent.print_response("Sleep for 2 seconds")

# Example 2: Sleep for a longer duration
agent.print_response("Sleep for 5 seconds")
```

## Toolkit Params

| Parameter | Type  | Default   | Description          |
| --------- | ----- | --------- | -------------------- |
| `name`    | `str` | `"sleep"` | The name of the tool |

## Toolkit Functions

| Function | Description                                        |
| -------- | -------------------------------------------------- |
| `sleep`  | Pauses execution for a specified number of seconds |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/sleep.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/sleep_tools.py)


# Spider



**SpiderTools** is an open source web Scraper & Crawler that returns LLM-ready data. To start using Spider, you need an API key from the [Spider dashboard](https://spider.cloud).

## Prerequisites

The following example requires the `spider-client` library.

```shell
pip install -U spider-client
```

## Example

The following agent will run a search query to get the latest news in USA and scrape the first search result. The agent will return the scraped data in markdown format.

```python cookbook/tools/spider_tools.py
from agno.agent import Agent
from agno.tools.spider import SpiderTools

agent = Agent(tools=[SpiderTools()])
agent.print_response('Can you scrape the first search result from a search on "news in USA"?', markdown=True)
```

## Toolkit Params

| Parameter     | Type  | Default | Description                                    |
| ------------- | ----- | ------- | ---------------------------------------------- |
| `max_results` | `int` | -       | The maximum number of search results to return |
| `url`         | `str` | -       | The url to be scraped or crawled               |

## Toolkit Functions

| Function | Description                           |
| -------- | ------------------------------------- |
| `search` | Searches the web for the given query. |
| `scrape` | Scrapes the given url.                |
| `crawl`  | Crawls the given url.                 |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/spider.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/spider_tools.py)


# SQL



**SQLTools** enable an Agent to run SQL queries and interact with databases.

## Prerequisites

The following example requires the `sqlalchemy` library and a database URL.

```shell
pip install -U sqlalchemy
```

You will also need a database. The following example uses a Postgres database running in a Docker container.

```shell
 docker run -d \
  -e POSTGRES_DB=ai \
  -e POSTGRES_USER=ai \
  -e POSTGRES_PASSWORD=ai \
  -e PGDATA=/var/lib/postgresql/data/pgdata \
  -v pgvolume:/var/lib/postgresql/data \
  -p 5532:5432 \
  --name pgvector \
  agno/pgvector:16
```

## Example

The following agent will run a SQL query to list all tables in the database and describe the contents of one of the tables.

```python cookbook/tools/sql_tools.py
from agno.agent import Agent
from agno.tools.sql import SQLTools

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

agent = Agent(tools=[SQLTools(db_url=db_url)])
agent.print_response("List the tables in the database. Tell me about contents of one of the tables", markdown=True)
```

## Toolkit Params

| Parameter        | Type             | Default | Description                                                                 |
| ---------------- | ---------------- | ------- | --------------------------------------------------------------------------- |
| `db_url`         | `str`            | -       | The URL for connecting to the database.                                     |
| `db_engine`      | `Engine`         | -       | The database engine used for connections and operations.                    |
| `user`           | `str`            | -       | The username for database authentication.                                   |
| `password`       | `str`            | -       | The password for database authentication.                                   |
| `host`           | `str`            | -       | The hostname or IP address of the database server.                          |
| `port`           | `int`            | -       | The port number on which the database server is listening.                  |
| `schema`         | `str`            | -       | The specific schema within the database to use.                             |
| `dialect`        | `str`            | -       | The SQL dialect used by the database.                                       |
| `tables`         | `Dict[str, Any]` | -       | A dictionary mapping table names to their respective metadata or structure. |
| `list_tables`    | `bool`           | `True`  | Enables the functionality to list all tables in the database.               |
| `describe_table` | `bool`           | `True`  | Enables the functionality to describe the schema of a specific table.       |
| `run_sql_query`  | `bool`           | `True`  | Enables the functionality to execute SQL queries directly.                  |

## Toolkit Functions

| Function         | Description                               |
| ---------------- | ----------------------------------------- |
| `list_tables`    | Lists all tables in the database.         |
| `describe_table` | Describes the schema of a specific table. |
| `run_sql_query`  | Executes SQL queries directly.            |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/sql.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/sql_tools.py)


# Tavily



**TavilyTools** enable an Agent to search the web using the Tavily API.

## Prerequisites

The following examples requires the `tavily-python` library and an API key from [Tavily](https://tavily.com/).

```shell
pip install -U tavily-python
```

```shell
export TAVILY_API_KEY=***
```

## Example

The following agent will run a search on Tavily for "language models" and print the response.

```python cookbook/tools/tavily_tools.py
from agno.agent import Agent
from agno.tools.tavily import TavilyTools

agent = Agent(tools=[TavilyTools()], show_tool_calls=True)
agent.print_response("Search tavily for 'language models'", markdown=True)
```

## Toolkit Params

| Parameter            | Type                           | Default      | Description                                                                                    |
| -------------------- | ------------------------------ | ------------ | ---------------------------------------------------------------------------------------------- |
| `api_key`            | `str`                          | -            | API key for authentication. If not provided, will check TAVILY\_API\_KEY environment variable. |
| `search`             | `bool`                         | `True`       | Enables search functionality.                                                                  |
| `max_tokens`         | `int`                          | `6000`       | Maximum number of tokens to use in search results.                                             |
| `include_answer`     | `bool`                         | `True`       | Whether to include an AI-generated answer summary in the response.                             |
| `search_depth`       | `Literal['basic', 'advanced']` | `'advanced'` | Depth of search - 'basic' for faster results or 'advanced' for more comprehensive search.      |
| `format`             | `Literal['json', 'markdown']`  | `'markdown'` | Output format - 'json' for raw data or 'markdown' for formatted text.                          |
| `use_search_context` | `bool`                         | `False`      | Whether to use Tavily's search context API instead of regular search.                          |

## Toolkit Functions

| Function                  | Description                                                                                                                                                                                               |
| ------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `web_search_using_tavily` | Searches the web for a query using Tavily API. Takes a query string and optional max\_results parameter (default 5). Returns results in specified format with titles, URLs, content and relevance scores. |
| `web_search_with_tavily`  | Alternative search function that uses Tavily's search context API. Takes a query string and returns contextualized search results. Only available if use\_search\_context is True.                        |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/tavily.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/tavily_tools.py)


# Todoist



**TodoistTools** enables an Agent to interact with [Todoist](https://www.todoist.com/).

## Prerequisites

The following example requires the `todoist-api-python` library. and a Todoist API token which can be obtained from the [Todoist Developer Portal](https://app.todoist.com/app/settings/integrations/developer).

```shell
pip install todoist-api-python
```

```shell
export TODOIST_API_TOKEN=***
```

## Example

The following agent will create a new task in Todoist.

```python cookbook/tools/todoist.py
"""
Example showing how to use the Todoist Tools with Agno

Requirements:
- Sign up/login to Todoist and get a Todoist API Token (get from https://app.todoist.com/app/settings/integrations/developer)
- pip install todoist-api-python

Usage:
- Set the following environment variables:
    export TODOIST_API_TOKEN="your_api_token"

- Or provide them when creating the TodoistTools instance
"""

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.todoist import TodoistTools

todoist_agent = Agent(
    name="Todoist Agent",
    role="Manage your todoist tasks",
    instructions=[
        "When given a task, create a todoist task for it.",
        "When given a list of tasks, create a todoist task for each one.",
        "When given a task to update, update the todoist task.",
        "When given a task to delete, delete the todoist task.",
        "When given a task to get, get the todoist task.",
    ],
    agent_id="todoist-agent",
    model=OpenAIChat(id="gpt-4o"),
    tools=[TodoistTools()],
    markdown=True,
    debug_mode=True,
    show_tool_calls=True,
)

# Example 1: Create a task
print("\n=== Create a task ===")
todoist_agent.print_response("Create a todoist task to buy groceries tomorrow at 10am")


# Example 2: Delete a task
print("\n=== Delete a task ===")
todoist_agent.print_response(
    "Delete the todoist task to buy groceries tomorrow at 10am"
)


# Example 3: Get all tasks
print("\n=== Get all tasks ===")
todoist_agent.print_response("Get all the todoist tasks")
```

## Toolkit Params

| Parameter   | Type  | Default | Description                                             |
| ----------- | ----- | ------- | ------------------------------------------------------- |
| `api_token` | `str` | `None`  | If you want to manually supply the TODOIST\_API\_TOKEN. |

## Toolkit Functions

| Function           | Description                                                                                     |
| ------------------ | ----------------------------------------------------------------------------------------------- |
| `create_task`      | Creates a new task in Todoist with optional project assignment, due date, priority, and labels. |
| `get_task`         | Fetches a specific task.                                                                        |
| `update_task`      | Updates an existing task with new properties such as content, due date, priority, etc.          |
| `close_task`       | Marks a task as completed.                                                                      |
| `delete_task`      | Deletes a specific task from Todoist.                                                           |
| `get_active_tasks` | Retrieves all active (non-completed) tasks.                                                     |
| `get_projects`     | Retrieves all projects in Todoist.                                                              |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/todoist.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/todoist_tool.py)


# Introduction



A **Toolkit** is a collection of functions that can be added to an Agent. The functions in a Toolkit are designed to work together, share internal state and provide a better development experience.

The following **Toolkits** are available to use

<CardGroup cols={3}>
  <Card title="Airflow" icon="wind" iconType="duotone" href="/tools/toolkits/airflow">
    Tools to manage Airflow DAGs.
  </Card>

  <Card title="Apify" icon="gear" iconType="duotone" href="/tools/toolkits/apify">
    Tools to use Apify Actors.
  </Card>

  <Card title="Arxiv" icon="book" iconType="duotone" href="/tools/toolkits/arxiv">
    Tools to read arXiv papers.
  </Card>

  <Card title="Calculator" icon="calculator" iconType="duotone" href="/tools/toolkits/calculator">
    Tools to perform calculations.
  </Card>

  <Card title="CalCom" icon="calendar" iconType="duotone" href="/tools/toolkits/calcom">
    Tools to interact with the Cal.com API.
  </Card>

  <Card title="Composio" icon="code-branch" iconType="duotone" href="/tools/toolkits/composio">
    Tools to compose complex workflows.
  </Card>

  <Card title="Confluence" icon="file" iconType="duotone" href="/tools/toolkits/confluence">
    Tools to manage Confluence pages.
  </Card>

  <Card title="Crawl4AI" icon="spider" iconType="duotone" href="/tools/toolkits/crawl4ai">
    Tools to crawl web data.
  </Card>

  <Card title="CSV" icon="file-csv" iconType="duotone" href="/tools/toolkits/csv">
    Tools to work with CSV files.
  </Card>

  <Card title="Dalle" icon="eye" iconType="duotone" href="/tools/toolkits/dalle">
    Tools to interact with Dalle.
  </Card>

  <Card title="Discord" icon="comment" iconType="duotone" href="/tools/toolkits/discord">
    Tools to interact with Discord.
  </Card>

  <Card title="DuckDb" icon="server" iconType="duotone" href="/tools/toolkits/duckdb">
    Tools to run SQL using DuckDb.
  </Card>

  <Card title="DuckDuckGo" icon="duck" iconType="duotone" href="/tools/toolkits/duckduckgo">
    Tools to search the web using DuckDuckGo.
  </Card>

  <Card title="Eleven Labs" icon="headphones" iconType="duotone" href="/tools/toolkits/eleven_labs">
    Tools to generate audio using Eleven Labs.
  </Card>

  <Card title="Email" icon="envelope" iconType="duotone" href="/tools/toolkits/email">
    Tools to send emails.
  </Card>

  <Card title="Exa" icon="magnifying-glass" iconType="duotone" href="/tools/toolkits/exa">
    Tools to search the web using Exa.
  </Card>

  <Card title="Fal" icon="video" iconType="duotone" href="/tools/toolkits/fal">
    Tools to generate media using Fal.
  </Card>

  <Card title="File" icon="file" iconType="duotone" href="/tools/toolkits/file">
    Tools to read and write files.
  </Card>

  <Card title="Firecrawl" icon="fire" iconType="duotone" href="/tools/toolkits/firecrawl">
    Tools to crawl the web using Firecrawl.
  </Card>

  <Card title="GitHub" icon="github" iconType="brands" href="/tools/toolkits/github">
    Tools to interact with GitHub.
  </Card>

  <Card title="Giphy" icon="image" iconType="duotone" href="/tools/toolkits/giphy">
    Tools to search for GIFs on Giphy.
  </Card>

  <Card title="Gmail" icon="envelope" iconType="duotone" href="/tools/toolkits/gmail">
    Tools to interact with Gmail.
  </Card>

  <Card title="Google Maps" icon="map" iconType="duotone" href="/tools/toolkits/google_maps">
    Tools to search for places on Google Maps.
  </Card>

  <Card title="Google Calendar" icon="calendar" iconType="duotone" href="/tools/toolkits/googlecalendar">
    Tools to manage Google Calendar events.
  </Card>

  <Card title="Google Search" icon="google" iconType="duotone" href="/tools/toolkits/googlesearch">
    Tools to search Google.
  </Card>

  <Card title="HackerNews" icon="newspaper" iconType="duotone" href="/tools/toolkits/hackernews">
    Tools to read Hacker News articles.
  </Card>

  <Card title="Jina Reader" icon="robot" iconType="duotone" href="/tools/toolkits/jina_reader">
    Tools for neural search and AI services using Jina.
  </Card>

  <Card title="Jira" icon="jira" iconType="brands" href="/tools/toolkits/jira">
    Tools to interact with Jira.
  </Card>

  <Card title="MLX Transcribe" icon="headphones" iconType="duotone" href="/tools/toolkits/mlx_transcribe">
    Tools to transcribe audio using MLX.
  </Card>

  <Card title="ModelsLabs" icon="video" iconType="duotone" href="/tools/toolkits/models_labs">
    Tools to generate videos using ModelsLabs.
  </Card>

  <Card title="Newspaper" icon="newspaper" iconType="duotone" href="/tools/toolkits/newspaper">
    Tools to read news articles.
  </Card>

  <Card title="Newspaper4k" icon="newspaper" iconType="duotone" href="/tools/toolkits/newspaper4k">
    Tools to read articles using Newspaper4k.
  </Card>

  <Card title="OpenBB" icon="chart-bar" iconType="duotone" href="/tools/toolkits/openbb">
    Tools to search for stock data using OpenBB.
  </Card>

  <Card title="Pandas" icon="table" iconType="duotone" href="/tools/toolkits/pandas">
    Tools to manipulate data using Pandas.
  </Card>

  <Card title="Postgres" icon="database" iconType="duotone" href="/tools/toolkits/postgres">
    Tools to interact with PostgreSQL databases.
  </Card>

  <Card title="Pubmed" icon="file-medical" iconType="duotone" href="/tools/toolkits/pubmed">
    Tools to search Pubmed.
  </Card>

  <Card title="Python" icon="code" iconType="duotone" href="/tools/toolkits/python">
    Tools to write and run Python code.
  </Card>

  <Card title="Resend" icon="paper-plane" iconType="duotone" href="/tools/toolkits/resend">
    Tools to send emails using Resend.
  </Card>

  <Card title="SearxNG" icon="magnifying-glass" iconType="duotone" href="/tools/toolkits/searxng">
    Tools to search the web using SearxNG.
  </Card>

  <Card title="Serpapi" icon="magnifying-glass" iconType="duotone" href="/tools/toolkits/serpapi">
    Tools to search Google, YouTube, and more using Serpapi.
  </Card>

  <Card title="Shell" icon="terminal" iconType="duotone" href="/tools/toolkits/shell">
    Tools to run shell commands.
  </Card>

  <Card title="Slack" icon="slack" iconType="duotone" href="/tools/toolkits/slack">
    Tools to interact with Slack.
  </Card>

  <Card title="Sleep" icon="bed" iconType="duotone" href="/tools/toolkits/sleep">
    Tools to pause execution for a given number of seconds.
  </Card>

  <Card title="Spider" icon="spider" iconType="duotone" href="/tools/toolkits/spider">
    Tools to crawl websites.
  </Card>

  <Card title="SQL" icon="database" iconType="duotone" href="/tools/toolkits/sql">
    Tools to run SQL queries.
  </Card>

  <Card title="Tavily" icon="magnifying-glass" iconType="duotone" href="/tools/toolkits/tavily">
    Tools to search the web using Tavily.
  </Card>

  <Card title="Todoist" icon="list" iconType="duotone" href="/tools/toolkits/todoist">
    Tools to interact with Todoist.
  </Card>

  <Card title="Twilio" icon="mobile-screen-button" iconType="duotone" href="/tools/toolkits/twilio">
    Tools to interact with Twilio services.
  </Card>

  <Card title="X (Twitter)" icon="x-twitter" iconType="brands" href="/tools/toolkits/x">
    Tools to interact with X.
  </Card>

  <Card title="Website" icon="globe" iconType="duotone" href="/tools/toolkits/website">
    Tools to scrape websites.
  </Card>

  <Card title="Wikipedia" icon="book" iconType="duotone" href="/tools/toolkits/wikipedia">
    Tools to search Wikipedia.
  </Card>

  <Card title="YFinance" icon="dollar-sign" iconType="duotone" href="/tools/toolkits/yfinance">
    Tools to search Yahoo Finance.
  </Card>

  <Card title="YouTube" icon="youtube" iconType="brands" href="/tools/toolkits/youtube">
    Tools to search YouTube.
  </Card>

  <Card title="Zendesk" icon="headphones" iconType="duotone" href="/tools/toolkits/zendesk">
    Tools to search Zendesk.
  </Card>

  <Card title="Zoom" icon="video" iconType="duotone" href="/tools/toolkits/zoom">
    Tools to interact with Zoom.
  </Card>
</CardGroup>


# Twilio



**TwilioTools** enables an Agent to interact with [Twilio](https://www.twilio.com/docs) services, such as sending SMS, retrieving call details, and listing messages.

## Prerequisites

The following examples require the `twilio` library and appropriate Twilio credentials, which can be obtained from [here](https://www.twilio.com/console).

```shell
pip install twilio
```

Set the following environment variables:

```shell
export TWILIO_ACCOUNT_SID=***
export TWILIO_AUTH_TOKEN=***
```

## Example

The following agent will send an SMS message using Twilio:

```python
from agno.agent import Agent
from agno.tools.twilio import TwilioTools

agent = Agent(
    instructions=[
        "Use your tools to send SMS using Twilio.",
    ],
    tools=[TwilioTools(debug=True)],
    show_tool_calls=True,
)

agent.print_response("Send an SMS to +1234567890", markdown=True)
```

## Toolkit Params

| Name          | Type            | Default | Description                                       |
| ------------- | --------------- | ------- | ------------------------------------------------- |
| `account_sid` | `Optional[str]` | `None`  | Twilio Account SID for authentication.            |
| `auth_token`  | `Optional[str]` | `None`  | Twilio Auth Token for authentication.             |
| `api_key`     | `Optional[str]` | `None`  | Twilio API Key for alternative authentication.    |
| `api_secret`  | `Optional[str]` | `None`  | Twilio API Secret for alternative authentication. |
| `region`      | `Optional[str]` | `None`  | Optional Twilio region (e.g., `au1`).             |
| `edge`        | `Optional[str]` | `None`  | Optional Twilio edge location (e.g., `sydney`).   |
| `debug`       | `bool`          | `False` | Enable debug logging for troubleshooting.         |

## Toolkit Functions

| Function           | Description                                                                                                                                                                 |
| ------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `send_sms`         | Sends an SMS to a recipient. Takes recipient phone number, sender number (Twilio), and message body. Returns message SID if successful or error message if failed.          |
| `get_call_details` | Retrieves details of a call using its SID. Takes the call SID and returns a dictionary with call details (e.g., status, duration).                                          |
| `list_messages`    | Lists recent SMS messages. Takes a limit for the number of messages to return (default 20). Returns a list of message details (e.g., SID, sender, recipient, body, status). |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/twilio.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/twilio_tools.py)


# Website



**WebsiteTools** enable an Agent to parse a website and add its contents to the knowledge base.

## Prerequisites

The following example requires the `beautifulsoup4` library.

```shell
pip install -U beautifulsoup4
```

## Example

The following agent will read the contents of a website and add it to the knowledge base.

```python cookbook/tools/website_tools.py
from agno.agent import Agent
from agno.tools.website import WebsiteTools

agent = Agent(tools=[WebsiteTools()], show_tool_calls=True)
agent.print_response("Search web page: 'https://docs.agno.com/introduction'", markdown=True)
```

## Toolkit Params

| Parameter        | Type                   | Default | Description                                                                                                            |
| ---------------- | ---------------------- | ------- | ---------------------------------------------------------------------------------------------------------------------- |
| `knowledge_base` | `WebsiteKnowledgeBase` | -       | The knowledge base associated with the website, containing various data and resources linked to the website's content. |

## Toolkit Functions

| Function                        | Description                                                                                                                                                                                                          |
| ------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `add_website_to_knowledge_base` | This function adds a website's content to the knowledge base. **NOTE:** The website must start with `https://` and should be a valid website. Use this function to get information about products from the internet. |
| `read_url`                      | This function reads a URL and returns the contents.                                                                                                                                                                  |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/website.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/website_tools.py)


# Wikipedia



**WikipediaTools** enable an Agent to search wikipedia a website and add its contents to the knowledge base.

## Prerequisites

The following example requires the `wikipedia` library.

```shell
pip install -U wikipedia
```

## Example

The following agent will run seach wikipedia for "ai" and print the response.

```python cookbook/tools/wikipedia_tools.py
from agno.agent import Agent
from agno.tools.wikipedia import WikipediaTools

agent = Agent(tools=[WikipediaTools()], show_tool_calls=True)
agent.print_response("Search wikipedia for 'ai'")
```

## Toolkit Params

| Name             | Type                     | Default | Description                                                                                                        |
| ---------------- | ------------------------ | ------- | ------------------------------------------------------------------------------------------------------------------ |
| `knowledge_base` | `WikipediaKnowledgeBase` | -       | The knowledge base associated with Wikipedia, containing various data and resources linked to Wikipedia's content. |

## Toolkit Functions

| Function Name                                | Description                                                                                            |
| -------------------------------------------- | ------------------------------------------------------------------------------------------------------ |
| `search_wikipedia_and_update_knowledge_base` | This function searches wikipedia for a topic, adds the results to the knowledge base and returns them. |
| `search_wikipedia`                           | Searches Wikipedia for a query.                                                                        |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/wikipedia.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/wikipedia_tools.py)


# X (Twitter)



## Prerequisites

The following example requires the `tweepy` library.

```shell
pip install tweepy
```

To set up an X developer account and obtain the necessary keys, follow these steps:

1. **Create an X Developer Account:**
   * Go to the X Developer website: [https://developer.x.com/](https://developer.x.com/)
   * Sign in with your X account or create a new one if you don't have an account.
   * Apply for a developer account by providing the required information about your intended use of the X API.

2. **Create a Project and App:**
   * Once your developer account is approved, log in to the X Developer portal.
   * Navigate to the "Projects & Apps" section and create a new project.
   * Within the project, create a new app. This app will be used to generate the necessary API keys and tokens.
   * You'll get a client id and client secret, but you can ignore them.

3. **Generate API Keys, Tokens, and Client Credentials:**
   * After creating the app, navigate to the "Keys and tokens" tab.
   * Generate the following keys, tokens, and client credentials:
     * **API Key (Consumer Key)**
     * **API Secret Key (Consumer Secret)**
     * **Bearer Token**
     * **Access Token**
     * **Access Token Secret**

4. **Set Environment Variables:**
   * Export the generated keys, tokens, and client credentials as environment variables in your system or provide them as arguments to the `XTools` constructor.
     * `X_CONSUMER_KEY`
     * `X_CONSUMER_SECRET`
     * `X_ACCESS_TOKEN`
     * `X_ACCESS_TOKEN_SECRET`
     * `X_BEARER_TOKEN`

## Example

The following example demonstrates how to use the X toolkit to interact with X (formerly Twitter) API:

```python cookbook/tools/x_tools.py
from agno.agent import Agent
from agno.tools.x import XTools

# Initialize the X toolkit
x_tools = XTools()

# Create an agent with the X toolkit
agent = Agent(
    instructions=[
        "Use your tools to interact with X as the authorized user",
        "When asked to create a tweet, generate appropriate content based on the request",
        "Do not post tweets unless explicitly instructed to do so",
        "Provide informative responses about the user's timeline and tweets",
        "Respect X's usage policies and rate limits",
    ],
    tools=[x_tools],
    show_tool_calls=True,
)

# Example: Get user profile
agent.print_response("Get my X profile", markdown=True)

# Example: Get user timeline
agent.print_response("Get my timeline", markdown=True)

# Example: Create and post a tweet
agent.print_response("Create a post about AI ethics", markdown=True)

# Example: Get information about a user
agent.print_response("Can you retrieve information about this user https://x.com/AgnoAgi ", markdown=True)

# Example: Reply to a post
agent.print_response(
    "Can you reply to this [post ID] post as a general message as to how great this project is: https://x.com/AgnoAgi",
    markdown=True,
)

# Example: Send a direct message
agent.print_response(
    "Send direct message to the user @AgnoAgi telling them I want to learn more about them and a link to their community.",
    markdown=True,
)
```

## Toolkit Params

| Parameter             | Type  | Default | Description                                      |
| --------------------- | ----- | ------- | ------------------------------------------------ |
| `bearer_token`        | `str` | `None`  | The bearer token for X API authentication        |
| `consumer_key`        | `str` | `None`  | The consumer key for X API authentication        |
| `consumer_secret`     | `str` | `None`  | The consumer secret for X API authentication     |
| `access_token`        | `str` | `None`  | The access token for X API authentication        |
| `access_token_secret` | `str` | `None`  | The access token secret for X API authentication |

## Toolkit Functions

| Function            | Description                                 |
| ------------------- | ------------------------------------------- |
| `create_post`       | Creates and posts a new post                |
| `reply_to_post`     | Replies to an existing post                 |
| `send_dm`           | Sends a direct message to a X user          |
| `get_user_info`     | Retrieves information about a X user        |
| `get_home_timeline` | Gets the authenticated user's home timeline |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/x.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/x_tools.py)


# Yfinance



**YFinanceTools** enable an Agent to access stock data, financial information and more from Yahoo Finance.

## Prerequisites

The following example requires the `yfinance` library.

```shell
pip install -U yfinance
```

## Example

The following agent will provide information about the stock price and analyst recommendations for NVDA (Nvidia Corporation).

```python cookbook/tools/yfinance_tools.py
from agno.agent import Agent
from agno.tools.yfinance import YFinanceTools

agent = Agent(
    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, stock_fundamentals=True)],
    show_tool_calls=True,
    description="You are an investment analyst that researches stock prices, analyst recommendations, and stock fundamentals.",
    instructions=["Format your response using markdown and use tables to display data where possible."],
)
agent.print_response("Share the NVDA stock price and analyst recommendations", markdown=True)
```

## Toolkit Params

| Parameter                 | Type   | Default | Description                                                                    |
| ------------------------- | ------ | ------- | ------------------------------------------------------------------------------ |
| `stock_price`             | `bool` | `True`  | Enables the functionality to retrieve current stock price information.         |
| `company_info`            | `bool` | `False` | Enables the functionality to retrieve detailed company information.            |
| `stock_fundamentals`      | `bool` | `False` | Enables the functionality to retrieve fundamental data about a stock.          |
| `income_statements`       | `bool` | `False` | Enables the functionality to retrieve income statements of a company.          |
| `key_financial_ratios`    | `bool` | `False` | Enables the functionality to retrieve key financial ratios for a company.      |
| `analyst_recommendations` | `bool` | `False` | Enables the functionality to retrieve analyst recommendations for a stock.     |
| `company_news`            | `bool` | `False` | Enables the functionality to retrieve the latest news related to a company.    |
| `technical_indicators`    | `bool` | `False` | Enables the functionality to retrieve technical indicators for stock analysis. |
| `historical_prices`       | `bool` | `False` | Enables the functionality to retrieve historical price data for a stock.       |

## Toolkit Functions

| Function                      | Description                                                      |
| ----------------------------- | ---------------------------------------------------------------- |
| `get_current_stock_price`     | This function retrieves the current stock price of a company.    |
| `get_company_info`            | This function retrieves detailed information about a company.    |
| `get_historical_stock_prices` | This function retrieves historical stock prices for a company.   |
| `get_stock_fundamentals`      | This function retrieves fundamental data about a stock.          |
| `get_income_statements`       | This function retrieves income statements of a company.          |
| `get_key_financial_ratios`    | This function retrieves key financial ratios for a company.      |
| `get_analyst_recommendations` | This function retrieves analyst recommendations for a stock.     |
| `get_company_news`            | This function retrieves the latest news related to a company.    |
| `get_technical_indicators`    | This function retrieves technical indicators for stock analysis. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/yfinance.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/yfinance_tools.py)


# Youtube



**YouTubeTools** enable an Agent to access captions and metadata of YouTube videos, when provided with a video URL.

## Prerequisites

The following example requires the `youtube_transcript_api` library.

```shell
pip install -U youtube_transcript_api
```

## Example

The following agent will provide a summary of a YouTube video.

```python cookbook/tools/youtube_tools.py
from agno.agent import Agent
from agno.tools.youtube import YouTubeTools

agent = Agent(
    tools=[YouTubeTools()],
    show_tool_calls=True,
    description="You are a YouTube agent. Obtain the captions of a YouTube video and answer questions.",
)

agent.print_response("Summarize this video https://www.youtube.com/watch?v=Iv9dewmcFbs&t", markdown=True)
```

## Toolkit Params

| Param                | Type        | Default | Description                                                                        |
| -------------------- | ----------- | ------- | ---------------------------------------------------------------------------------- |
| `get_video_captions` | `bool`      | `True`  | Enables the functionality to retrieve video captions.                              |
| `get_video_data`     | `bool`      | `True`  | Enables the functionality to retrieve video metadata and other related data.       |
| `languages`          | `List[str]` | -       | Specifies the list of languages for which data should be retrieved, if applicable. |

## Toolkit Functions

| Function                     | Description                                              |
| ---------------------------- | -------------------------------------------------------- |
| `get_youtube_video_captions` | This function retrieves the captions of a YouTube video. |
| `get_youtube_video_data`     | This function retrieves the metadata of a YouTube video. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/youtube.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/youtube_tools.py)


# Zendesk



**ZendeskTools** enable an Agent to access Zendesk API to search for articles.

## Prerequisites

The following example requires the `requests` library and auth credentials.

```shell
pip install -U requests
```

```shell
export ZENDESK_USERNAME=***
export ZENDESK_PW=***
export ZENDESK_COMPANY_NAME=***
```

## Example

The following agent will run seach Zendesk for "How do I login?" and print the response.

```python cookbook/tools/zendesk_tools.py
from agno.agent import Agent
from agno.tools.zendesk import ZendeskTools

agent = Agent(tools=[ZendeskTools()], show_tool_calls=True)
agent.print_response("How do I login?", markdown=True)
```

## Toolkit Params

| Parameter      | Type  | Default | Description                                                             |
| -------------- | ----- | ------- | ----------------------------------------------------------------------- |
| `username`     | `str` | -       | The username used for authentication or identification purposes.        |
| `password`     | `str` | -       | The password associated with the username for authentication purposes.  |
| `company_name` | `str` | -       | The name of the company related to the user or the data being accessed. |

## Toolkit Functions

| Function         | Description                                                                                    |
| ---------------- | ---------------------------------------------------------------------------------------------- |
| `search_zendesk` | This function searches for articles in Zendesk Help Center that match the given search string. |

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/zendesk.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/zendesk_tools.py)


# Zoom



**Zoom** enables an Agent to interact with Zoom, allowing it to schedule meetings, manage recordings, and handle various meeting-related operations through the Zoom API. The toolkit uses Zoom's Server-to-Server OAuth authentication for secure API access.

## Prerequisites

The Zoom toolkit requires the following setup:

1. Install required dependencies:

```shell
pip install requests
```

2. Set up Server-to-Server OAuth app in Zoom Marketplace:
   * Go to [Zoom Marketplace](https://marketplace.zoom.us/)
   * Click "Develop" → "Build App"
   * Choose "Server-to-Server OAuth" app type
   * Configure the app with required scopes:
     * `/meeting:write:admin`
     * `/meeting:read:admin`
     * `/recording:read:admin`
   * Note your Account ID, Client ID, and Client Secret

3. Set up environment variables:

```shell
export ZOOM_ACCOUNT_ID=your_account_id
export ZOOM_CLIENT_ID=your_client_id
export ZOOM_CLIENT_SECRET=your_client_secret
```

## Example Usage

```python
from agno.agent import Agent
from agno.tools.zoom import ZoomTools

# Initialize Zoom tools with credentials
zoom_tools = ZoomTools(
    account_id="your_account_id",
    client_id="your_client_id",
    client_secret="your_client_secret"
)

# Create an agent with Zoom capabilities
agent = Agent(tools=[zoom_tools], show_tool_calls=True)

# Schedule a meeting
response = agent.print_response("""
Schedule a team meeting with the following details:
- Topic: Weekly Team Sync
- Time: Tomorrow at 2 PM UTC
- Duration: 45 minutes
""", markdown=True)
```

## Toolkit Parameters

| Parameter       | Type  | Default | Description                                       |
| --------------- | ----- | ------- | ------------------------------------------------- |
| `account_id`    | `str` | `None`  | Zoom account ID (from Server-to-Server OAuth app) |
| `client_id`     | `str` | `None`  | Client ID (from Server-to-Server OAuth app)       |
| `client_secret` | `str` | `None`  | Client secret (from Server-to-Server OAuth app)   |

## Toolkit Functions

| Function                 | Description                                       |
| ------------------------ | ------------------------------------------------- |
| `schedule_meeting`       | Schedule a new Zoom meeting                       |
| `get_upcoming_meetings`  | Get a list of upcoming meetings                   |
| `list_meetings`          | List all meetings based on type                   |
| `get_meeting_recordings` | Get recordings for a specific meeting             |
| `delete_meeting`         | Delete a scheduled meeting                        |
| `get_meeting`            | Get detailed information about a specific meeting |

## Rate Limits

The Zoom API has rate limits that vary by endpoint and account type:

* Server-to-Server OAuth apps: 100 requests/second
* Meeting endpoints: Specific limits apply based on account type
* Recording endpoints: Lower rate limits, check Zoom documentation

For detailed rate limits, refer to [Zoom API Rate Limits](https://developers.zoom.us/docs/api/#rate-limits).

## Developer Resources

* View [Tools](https://github.com/agno-agi/agno/blob/main/libs/agno/agno/tools/zoom.py)
* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/tools/zoom_tools.py)


# Cassandra Agent Knowledge



## Setup

Install cassandra packages

```shell
pip install cassandra-driver
```

Run cassandra

```shell
docker run -d \
--name cassandra-db\
-p 9042:9042 \
cassandra:latest
```

## Example

```python agent_with_knowledge.py
from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.cassandra import Cassandra

from agno.embedder.mistral import MistralEmbedder
from agno.models.mistral import MistralChat

# (Optional) Set up your Cassandra DB

cluster = Cluster()

session = cluster.connect()
session.execute(
    """
    CREATE KEYSPACE IF NOT EXISTS testkeyspace
    WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }
    """
)

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=Cassandra(table_name="recipes", keyspace="testkeyspace", session=session, embedder=MistralEmbedder()),
)


# knowledge_base.load(recreate=False)  # Comment out after first run

agent = Agent(
    model=MistralChat(provider="mistral-large-latest", api_key=os.getenv("MISTRAL_API_KEY")),
    knowledge=knowledge_base,
    show_tool_calls=True,
)

agent.print_response(
    "What are the health benefits of Khao Niew Dam Piek Maphrao Awn?", markdown=True, show_full_reasoning=True
)

```

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/vector_dbs/cassandra_db.py)


# ChromaDB Agent Knowledge



## Setup

```shell
pip install chromadb
```

## Example

```python agent_with_knowledge.py
import typer
from rich.prompt import Prompt
from typing import Optional

from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.chroma import ChromaDb

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=ChromaDb(collection="recipes"),
)

# Comment out after first run
knowledge_base.load(recreate=False)

def pdf_agent(user: str = "user"):
    run_id: Optional[str] = None

    agent = Agent(
        run_id=run_id,
        user_id=user,
        knowledge_base=knowledge_base,
        use_tools=True,
        show_tool_calls=True,
        debug_mode=True,
    )
    if run_id is None:
        run_id = agent.run_id
        print(f"Started Run: {run_id}\n")
    else:
        print(f"Continuing Run: {run_id}\n")

    while True:
        message = Prompt.ask(f"[bold] :sunglasses: {user} [/bold]")
        if message in ("exit", "bye"):
            break
        agent.print_response(message)

if __name__ == "__main__":
    typer.run(pdf_agent)
```

## ChromaDb Params

<Snippet file="vectordb_chromadb_params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/vector_dbs/chroma_db.py)


# Clickhouse Agent Knowledge



## Setup

```shell
docker run -d \
  -e CLICKHOUSE_DB=ai \
  -e CLICKHOUSE_USER=ai \
  -e CLICKHOUSE_PASSWORD=ai \
  -e CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT=1 \
  -v clickhouse_data:/var/lib/clickhouse/ \
  -v clickhouse_log:/var/log/clickhouse-server/ \
  -p 8123:8123 \
  -p 9000:9000 \
  --ulimit nofile=262144:262144 \
  --name clickhouse-server \
  clickhouse/clickhouse-server
```

## Example

```python agent_with_knowledge.py

from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.storage.agent.sqlite import SqliteAgentStorage
from agno.vectordb.clickhouse import Clickhouse

agent = Agent(
    storage=SqliteAgentStorage(table_name="recipe_agent"),
    knowledge=PDFUrlKnowledgeBase(
        urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
        vector_db=Clickhouse(
            table_name="recipe_documents",
            host="localhost",
            port=8123,
            username="ai",
            password="ai",
        ),
    ),
    # Show tool calls in the response
    show_tool_calls=True,
    # Enable the agent to search the knowledge base
    search_knowledge=True,
    # Enable the agent to read the chat history
    read_chat_history=True,
)
# Comment out after first run
agent.knowledge.load(recreate=False)  # type: ignore

agent.print_response("How do I make pad thai?", markdown=True)
agent.print_response("What was my last question?", stream=True)
```

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/vector_dbs/clickhouse.py)


# Introduction



Vector databases enable us to store information as embeddings and search for "results similar" to our input query using cosine similarity or full text search. These results are then provided to the Agent as context so it can respond in a context-aware manner using Retrieval Augmented Generation (**RAG**).

Here's how vector databases are used with Agents:

<Steps>
  <Step title="Chunk the information">
    Break down the knowledge into smaller chunks to ensure our search query
    returns only relevant results.
  </Step>

  <Step title="Load the knowledge base">
    Convert the chunks into embedding vectors and store them in a vector
    database.
  </Step>

  <Step title="Search the knowledge base">
    When the user sends a message, we convert the input message into an
    embedding and "search" for nearest neighbors in the vector database.
  </Step>
</Steps>

Many vector databases also support hybrid search, which combines the power of vector similarity search with traditional keyword-based search. This approach can significantly improve the relevance and accuracy of search results, especially for complex queries or when dealing with diverse types of data.

Hybrid search typically works by:

1. Performing a vector similarity search to find semantically similar content.
2. Conducting a keyword-based search to identify exact or close matches.
3. Combining the results using a weighted approach to provide the most relevant information.

This capability allows for more flexible and powerful querying, often yielding better results than either method alone.

The following VectorDb are currently supported:

* [PgVector](/vectordb/pgvector)\*
* [LanceDb](/vectordb/lancedb)\*
* [Pinecone](/vectordb/pinecone)\*
* [Qdrant](/vectordb/qdrant)
* [MongoDb](/vectordb/mongodb)
* [Cassandra](/vectordb/cassandra)
* [ChromaDb](/vectordb/chroma)
* [Clickhouse](/vectordb/clickhouse)
* [Milvus](/vectordb/milvus)
* [Singlestore](/vectordb/singlestore)

\*hybrid search supported

Each of these databases has its own strengths and features, including varying levels of support for hybrid search. Be sure to check the specific documentation for each to understand how to best leverage their capabilities in your projects.


# LanceDB Agent Knowledge



## Setup

```shell
pip install lancedb
```

## Example

```python agent_with_knowledge.py
import typer
from typing import Optional
from rich.prompt import Prompt

from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.lancedb import LanceDb
from agno.vectordb.search import SearchType

# LanceDB Vector DB
vector_db = LanceDb(
    table_name="recipes",
    uri="/tmp/lancedb",
    search_type=SearchType.keyword,
)

# Knowledge Base
knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=vector_db,
)

# Comment out after first run
knowledge_base.load(recreate=True)

def lancedb_agent(user: str = "user"):
    run_id: Optional[str] = None

    agent = Agent(
        run_id=run_id,
        user_id=user,
        knowledge=knowledge_base,
        show_tool_calls=True,
        debug_mode=True,
    )

    if run_id is None:
        run_id = agent.run_id
        print(f"Started Run: {run_id}\n")
    else:
        print(f"Continuing Run: {run_id}\n")

    while True:
        message = Prompt.ask(f"[bold] :sunglasses: {user} [/bold]")
        if message in ("exit", "bye"):
            break
        agent.print_response(message)

if __name__ == "__main__":
    typer.run(lancedb_agent)
```

## LanceDb Params

<Snippet file="vectordb_lancedb_params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/vector_dbs/lance_db.py)


# Milvus Agent Knowledge



## Setup

```shell
pip install pymilvus
```

## Initialize Milvus

Set the uri and token for your Milvus server.

* If you only need a local vector database for small scale data or prototyping, setting the uri as a local file, e.g.`./milvus.db`, is the most convenient method, as it automatically utilizes [Milvus Lite](https://milvus.io/docs/milvus_lite.md) to store all data in this file.
* If you have large scale data, say more than a million vectors, you can set up a more performant Milvus server on [Docker or Kubernetes](https://milvus.io/docs/quickstart.md).
  In this setup, please use the server address and port as your uri, e.g.`http://localhost:19530`. If you enable the authentication feature on Milvus, use `your_username:your_password` as the token, otherwise don't set the token.
* If you use [Zilliz Cloud](https://zilliz.com/cloud), the fully managed cloud service for Milvus, adjust the `uri` and `token`, which correspond to the [Public Endpoint and API key](https://docs.zilliz.com/docs/on-zilliz-cloud-console#cluster-details) in Zilliz Cloud.

## Example

```python agent_with_knowledge.py

from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.milvus import Milvus

vector_db = Milvus(
    collection="recipes",
    uri="./milvus.db",
)
# Create knowledge base
knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=vector_db,
)

knowledge_base.load(recreate=False)  # Comment out after first run

# Create and use the agent
agent = Agent(knowledge_base=knowledge_base, use_tools=True, show_tool_calls=True)
agent.print_response("How to make Tom Kha Gai", markdown=True)
agent.print_response("What was my last question?", stream=True)
```

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/vector_dbs/milvus.py)


# MongoDB Agent Knowledge



## Setup

Follow the instructions in the [MongoDB Setup Guide](https://www.mongodb.com/docs/atlas/getting-started/) to get connection string

Install MongoDB packages

```shell
pip install pymongo
```

## Example

```python agent_with_knowledge.py
from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.mongodb import MongoDb

# MongoDB Atlas connection string
"""
Example connection strings:
"mongodb+srv://<username>:<password>@cluster0.mongodb.net/?retryWrites=true&w=majority"
"mongodb://localhost/?directConnection=true"
"""
mdb_connection_string = ""

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=MongoDb(
        collection_name="recipes",
        db_url=mdb_connection_string,
        wait_until_index_ready=60,
        wait_after_insert=300
    ),
)  # adjust wait_after_insert and wait_until_index_ready to your needs

# knowledge_base.load(recreate=True)  # Comment out after first run

agent = Agent(knowledge_base=knowledge_base, show_tool_calls=True)
agent.print_response("How to make Thai curry?", markdown=True)
```

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/vector_dbs/mongodb.py)


# PgVector Agent Knowledge



## Setup

```shell
docker run -d \
  -e POSTGRES_DB=ai \
  -e POSTGRES_USER=ai \
  -e POSTGRES_PASSWORD=ai \
  -e PGDATA=/var/lib/postgresql/data/pgdata \
  -v pgvolume:/var/lib/postgresql/data \
  -p 5532:5432 \
  --name pgvector \
  agnohq/pgvector:16
```

## Example

```python agent_with_knowledge.py
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.pgvector import PgVector, SearchType

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"
knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=PgVector(table_name="recipes", db_url=db_url, search_type=SearchType.hybrid),
)
# Load the knowledge base: Comment out after first run
knowledge_base.load(recreate=True, upsert=True)

agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    knowledge=knowledge_base,
    # Add a tool to read chat history.
    read_chat_history=True,
    show_tool_calls=True,
    markdown=True,
    # debug_mode=True,
)
agent.print_response("How do I make chicken and galangal in coconut milk soup", stream=True)
agent.print_response("What was my last question?", stream=True)
```

## PgVector Params

<Snippet file="vectordb_pgvector_params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/vector_dbs/pg_vector.py)


# Pinecone Agent Knowledge



## Setup

Follow the instructions in the [Pinecone Setup Guide](https://docs.pinecone.io/guides/get-started/quickstart) to get started quickly with Pinecone.

## Example

```python agent_with_knowledge.py
import os
import typer
from typing import Optional
from rich.prompt import Prompt

from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.pineconedb import PineconeDb

api_key = os.getenv("PINECONE_API_KEY")
index_name = "thai-recipe-hybrid-search"

vector_db = PineconeDb(
    name=index_name,
    dimension=1536,
    metric="cosine",
    spec={"serverless": {"cloud": "aws", "region": "us-east-1"}},
    api_key=api_key,
    use_hybrid_search=True,
    hybrid_alpha=0.5,
)

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=vector_db,
)

# Comment out after first run
knowledge_base.load(recreate=True, upsert=True)

def pinecone_agent(user: str = "user"):
    run_id: Optional[str] = None

    agent = Agent(
        run_id=run_id,
        user_id=user,
        knowledge=knowledge_base,
        show_tool_calls=True,
        debug_mode=True,
    )

    if run_id is None:
        run_id = agent.run_id
        print(f"Started Run: {run_id}\n")
    else:
        print(f"Continuing Run: {run_id}\n")

    while True:
        message = Prompt.ask(f"[bold] :sunglasses: {user} [/bold]")
        if message in ("exit", "bye"):
            break
        agent.print_response(message)

if __name__ == "__main__":
    typer.run(pinecone_agent)
```

## PineconeDb Params

<Snippet file="vectordb_pineconedb_params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/vector_dbs/pinecone_db.py)


# Qdrant Agent Knowledge



## Setup

Follow the instructions in the [Qdrant Setup Guide](https://qdrant.tech/documentation/guides/installation/) to install Qdrant locally. Here is a guide to get API keys: [Qdrant API Keys](https://qdrant.tech/documentation/cloud/authentication/).

## Example

```python agent_with_knowledge.py
import os
import typer
from typing import Optional
from rich.prompt import Prompt

from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.qdrant import Qdrant

api_key = os.getenv("QDRANT_API_KEY")
qdrant_url = os.getenv("QDRANT_URL")
collection_name = "thai-recipe-index"

vector_db = Qdrant(
    collection=collection_name,
    url=qdrant_url,
    api_key=api_key,
)

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=vector_db,
)

# Comment out after first run
knowledge_base.load(recreate=True, upsert=True)

def qdrant_agent(user: str = "user"):
    run_id: Optional[str] = None

    agent = Agent(
        run_id=run_id,
        user_id=user,
        knowledge=knowledge_base,
        tool_calls=True,
        use_tools=True,
        show_tool_calls=True,
        debug_mode=True,
    )

    if run_id is None:
        run_id = agent.run_id
        print(f"Started Run: {run_id}\n")
    else:
        print(f"Continuing Run: {run_id}\n")

    while True:
        message = Prompt.ask(f"[bold] :sunglasses: {user} [/bold]")
        if message in ("exit", "bye"):
            break
        agent.print_response(message)

if __name__ == "__main__":
    typer.run(qdrant_agent)
```

## Qdrant Params

<Snippet file="vectordb_qdrant_params.mdx" />

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/vector_dbs/qdrant_db.py)


# SingleStore Agent Knowledge



## Setup

Follow the instructions in the [SingleStore Setup Guide](https://docs.singlestore.com/cloud/connect-to-singlestore/connect-with-mysql/connect-with-mysql-client/connect-to-singlestore-helios-using-tls-ssl/) to install SingleStore locally.

## Example

```python agent_with_knowledge.py
import typer
from typing import Optional
from os import getenv

from sqlalchemy.engine import create_engine

from agno.agent import Agent
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.singlestore import SingleStore

USERNAME = getenv("SINGLESTORE_USERNAME")
PASSWORD = getenv("SINGLESTORE_PASSWORD")
HOST = getenv("SINGLESTORE_HOST")
PORT = getenv("SINGLESTORE_PORT")
DATABASE = getenv("SINGLESTORE_DATABASE")
SSL_CERT = getenv("SINGLESTORE_SSL_CERT", None)

db_url = f"mysql+pymysql://{USERNAME}:{PASSWORD}@{HOST}:{PORT}/{DATABASE}?charset=utf8mb4"
if SSL_CERT:
    db_url += f"&ssl_ca={SSL_CERT}&ssl_verify_cert=true"

db_engine = create_engine(db_url)

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=SingleStore(
        collection="recipes",
        db_engine=db_engine,
        schema=DATABASE,
    ),
)

# Comment out after first run
knowledge_base.load(recreate=False)

def pdf_assistant(user: str = "user"):
    run_id: Optional[str] = None

    agent = Agent(
        run_id=run_id,
        user_id=user,
        knowledge_base=knowledge_base,
        use_tools=True,
        show_tool_calls=True,
        # Uncomment the following line to use traditional RAG
        # add_references_to_prompt=True,
    )
    if run_id is None:
        run_id = agent.run_id
        print(f"Started Run: {run_id}\n")
    else:
        print(f"Continuing Run: {run_id}\n")

    while True:
        agent.cli_app(markdown=True)

if __name__ == "__main__":
    typer.run(pdf_assistant)
```

## SingleStore Params

<Snippet file="vectordb_singlestore_params.mdx" />

## Developer Resources

* View [Cookbook](https://github.com/agno-agi/agno/blob/main/cookbook/agent_concepts/knowledge/vector_dbs/singlestore_db.py)


# Advanced



Workflows are all about control and flexibility. You have full control over the multi-agent process, how the input is processed, which agents are used and in what order.

You also have full control over how the output is streamed.

## Streaming

To stream the output, yield an `Iterator[RunResponse]` from the `run()` method of your workflow.

```python news_report_generator.py
# Define the workflow
class GenerateNewsReport(Workflow):
    agent_1: Agent = ...

    agent_2: Agent = ...

    agent_3: Agent = ...

    def run(self, ...) -> Iterator[RunResponse]:
        # Run agents and gather the response
        # These can be batch responses, you can also stream intermediate results if you want
        final_agent_input = ...

        # Generate the final response from the writer agent
        agent_3_response_stream: Iterator[RunResponse] = self.agent_3.run(final_agent_input, stream=True)

        # Yield the response
        yield agent_3_response_stream

# Instantiate the workflow
generate_news_report = GenerateNewsReport()

# Run workflow and get the response as an iterator of RunResponse objects
report_stream: Iterator[RunResponse] = generate_news_report.run(...)

# Print the response
pprint_run_response(report_stream, markdown=True)
```

## Batch

Simply return a `RunResponse` object from the `run()` method of your workflow to return a single output.

```python news_report_generator.py
# Define the workflow
class GenerateNewsReport(Workflow):
    agent_1: Agent = ...

    agent_2: Agent = ...

    agent_3: Agent = ...

    def run(self, ...) -> RunResponse:
        # Run agents and gather the response
        final_agent_input = ...

        # Generate the final response from the writer agent
        agent_3_response: RunResponse = self.agent_3.run(final_agent_input)

        # Return the response
        return agent_3_response

# Instantiate the workflow
generate_news_report = GenerateNewsReport()

# Run workflow and get the response as a RunResponse object
report: RunResponse = generate_news_report.run(...)

# Print the response
pprint_run_response(report, markdown=True)
```


# Introduction



Workflows are deterministic, stateful, multi-agent programs that are built for production applications. They're incredibly powerful and offer the following benefits:

* **Full control and flexibility**: You have full control over the multi-agent process, how the input is processed, which agents are used and in what order. This is critical for reliability.
* **Pure python**: Control the agent process using standard python. Having built 100s of AI products, no framework will give you the flexibility of pure-python.
* **Built-in state management and caching**: Store state and cache intermediate results in a database, enabling your agents to re-use results from previous executions.

### How to build a workflow:

1. Define your workflow as a class by inheriting from the `Workflow` class.
2. Add one or more agents to the workflow.
3. Implement your logic in the `run()` method.
4. Cache results in the `session_state` as needed.
5. Run the workflow using the `.run()` method.

## Example: Blog Post Generator

Let's create a blog post generator that can search the web, read the top links and write a blog post for us. We'll cache intermediate results in the database to improve performance.

### Create the Workflow

1. Define your workflow as a class by inheriting from the `Workflow` class.

```python blog_post_generator.py
from agno.workflow import Workflow

class BlogPostGenerator(Workflow):
    pass
```

2. Add one or more agents to the workflow.

```python blog_post_generator.py

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.workflow import Workflow
from agno.tools.duckduckgo import DuckDuckGoTools

class BlogPostGenerator(Workflow):
    # Define an Agent that will search the web for a topic
    searcher: Agent = Agent(
        model=OpenAIChat(id="gpt-4o-mini"),
        tools=[DuckDuckGoTools()],
        instructions=["Given a topic, search for the top 5 articles."],
        response_model=SearchResults,
        structured_outputs=True,
    )

    # Define an Agent that will write the blog post
    writer: Agent = Agent(
        model=OpenAIChat(id="gpt-4o"),
        instructions=[
            "You will be provided with a topic and a list of top articles on that topic.",
            "Carefully read each article and generate a New York Times worthy blog post on that topic.",
            "Break the blog post into sections and provide key takeaways at the end.",
            "Make sure the title is catchy and engaging.",
            "Always provide sources, do not make up information or sources.",
        ],
        markdown=True,
    )
```

3. Implement your logic in the `run()` method.

```python blog_post_generator.py

import json
from typing import Optional, Iterator

from pydantic import BaseModel, Field

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.workflow import Workflow
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.utils.log import logger

class NewsArticle(BaseModel):
    title: str = Field(..., description="Title of the article.")
    url: str = Field(..., description="Link to the article.")
    summary: Optional[str] = Field(..., description="Summary of the article if available.")

class SearchResults(BaseModel):
    articles: list[NewsArticle]

class BlogPostGenerator(Workflow):
    # Define an Agent that will search the web for a topic
    searcher: Agent = Agent(
        model=OpenAIChat(id="gpt-4o-mini"),
        tools=[DuckDuckGoTools()],
        instructions=["Given a topic, search for the top 5 articles."],
        response_model=SearchResults,
        structured_outputs=True,
    )

    # Define an Agent that will write the blog post
    writer: Agent = Agent(
        model=OpenAIChat(id="gpt-4o"),
        instructions=[
            "You will be provided with a topic and a list of top articles on that topic.",
            "Carefully read each article and generate a New York Times worthy blog post on that topic.",
            "Break the blog post into sections and provide key takeaways at the end.",
            "Make sure the title is catchy and engaging.",
            "Always provide sources, do not make up information or sources.",
        ],
        markdown=True,
    )

    def run(self, topic: str, use_cache: bool = True) -> Iterator[RunResponse]:
        """This is where the main logic of the workflow is implemented."""

        logger.info(f"Generating a blog post on: {topic}")

        # Step 1: Search the web for articles on the topic
        search_results: Optional[SearchResults] = self._get_search_results(topic)
        # If no search_results are found for the topic, end the workflow
        if search_results is None or len(search_results.articles) == 0:
            yield RunResponse(
                event=RunEvent.workflow_completed,
                content=f"Sorry, could not find any articles on the topic: {topic}",
            )
            return

        # Step 2: Write a blog post
        yield from self._write_blog_post(topic, search_results)

    def _get_search_results(self, topic: str) -> Optional[SearchResults]:
        """Get the search results for a topic."""

        MAX_ATTEMPTS = 3

        for attempt in range(MAX_ATTEMPTS):
            try:
                searcher_response: RunResponse = self.searcher.run(topic)

                # Check if we got a valid response
                if not searcher_response or not searcher_response.content:
                    logger.warning(f"Attempt {attempt + 1}/{MAX_ATTEMPTS}: Empty searcher response")
                    continue
                # Check if the response is of the expected SearchResults type
                if not isinstance(searcher_response.content, SearchResults):
                    logger.warning(f"Attempt {attempt + 1}/{MAX_ATTEMPTS}: Invalid response type")
                    continue

                article_count = len(searcher_response.content.articles)
                logger.info(f"Found {article_count} articles on attempt {attempt + 1}")
                return searcher_response.content

            except Exception as e:
                logger.warning(f"Attempt {attempt + 1}/{MAX_ATTEMPTS} failed: {str(e)}")

        logger.error(f"Failed to get search results after {MAX_ATTEMPTS} attempts")
        return None

    def _write_blog_post(self, topic: str, search_results: SearchResults) -> Iterator[RunResponse]:
        """Write a blog post on a topic."""

        logger.info("Writing blog post")
        # Prepare the input for the writer
        writer_input = {"topic": topic, "articles": [v.model_dump() for v in search_results.articles]}
        # Run the writer and yield the response
        yield from self.writer.run(json.dumps(writer_input, indent=4), stream=True)
```

4. Add [caching](/workflows/session_state) to the workflow where needed.

```python blog_post_generator.py
import json
from typing import Optional, Iterator

from pydantic import BaseModel, Field

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.workflow import Workflow
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.utils.log import logger

class NewsArticle(BaseModel):
    title: str = Field(..., description="Title of the article.")
    url: str = Field(..., description="Link to the article.")
    summary: Optional[str] = Field(..., description="Summary of the article if available.")

class SearchResults(BaseModel):
    articles: list[NewsArticle]

class BlogPostGenerator(Workflow):
    # Define an Agent that will search the web for a topic
    searcher: Agent = Agent(
        model=OpenAIChat(id="gpt-4o-mini"),
        tools=[DuckDuckGoTools()],
        instructions=["Given a topic, search for the top 5 articles."],
        response_model=SearchResults,
        structured_outputs=True,
    )

    # Define an Agent that will write the blog post
    writer: Agent = Agent(
        model=OpenAIChat(id="gpt-4o"),
        instructions=[
            "You will be provided with a topic and a list of top articles on that topic.",
            "Carefully read each article and generate a New York Times worthy blog post on that topic.",
            "Break the blog post into sections and provide key takeaways at the end.",
            "Make sure the title is catchy and engaging.",
            "Always provide sources, do not make up information or sources.",
        ],
        markdown=True,
    )

    def run(self, topic: str, use_cache: bool = True) -> Iterator[RunResponse]:
        """This is where the main logic of the workflow is implemented."""

        logger.info(f"Generating a blog post on: {topic}")

        # Step 1: Use the cached blog post if use_cache is True
        if use_cache:
            cached_blog_post = self._get_cached_blog_post(topic)
            if cached_blog_post:
                yield RunResponse(content=cached_blog_post, event=RunEvent.workflow_completed)
                return

        # Step 2: Search the web for articles on the topic
        search_results: Optional[SearchResults] = self._get_search_results(topic)
        # If no search_results are found for the topic, end the workflow
        if search_results is None or len(search_results.articles) == 0:
            yield RunResponse(
                event=RunEvent.workflow_completed,
                content=f"Sorry, could not find any articles on the topic: {topic}",
            )
            return

        # Step 3: Write a blog post
        yield from self._write_blog_post(topic, search_results)

    def _get_cached_blog_post(self, topic: str) -> Optional[str]:
        """Get the cached blog post for a topic."""

        logger.info("Checking if cached blog post exists")
        return self.session_state.get("blog_posts", {}).get(topic)

    def _add_blog_post_to_cache(self, topic: str, blog_post: Optional[str]):
        """Add a blog post to the cache."""

        logger.info(f"Saving blog post for topic: {topic}")
        self.session_state.setdefault("blog_posts", {})
        self.session_state["blog_posts"][topic] = blog_post

    def _get_search_results(self, topic: str) -> Optional[SearchResults]:
        """Get the search results for a topic."""

        MAX_ATTEMPTS = 3

        for attempt in range(MAX_ATTEMPTS):
            try:
                searcher_response: RunResponse = self.searcher.run(topic)

                # Check if we got a valid response
                if not searcher_response or not searcher_response.content:
                    logger.warning(f"Attempt {attempt + 1}/{MAX_ATTEMPTS}: Empty searcher response")
                    continue
                # Check if the response is of the expected SearchResults type
                if not isinstance(searcher_response.content, SearchResults):
                    logger.warning(f"Attempt {attempt + 1}/{MAX_ATTEMPTS}: Invalid response type")
                    continue

                article_count = len(searcher_response.content.articles)
                logger.info(f"Found {article_count} articles on attempt {attempt + 1}")
                return searcher_response.content

            except Exception as e:
                logger.warning(f"Attempt {attempt + 1}/{MAX_ATTEMPTS} failed: {str(e)}")

        logger.error(f"Failed to get search results after {MAX_ATTEMPTS} attempts")
        return None

    def _write_blog_post(self, topic: str, search_results: SearchResults) -> Iterator[RunResponse]:
        """Write a blog post on a topic."""

        logger.info("Writing blog post")
        # Prepare the input for the writer
        writer_input = {"topic": topic, "articles": [v.model_dump() for v in search_results.articles]}
        # Run the writer and yield the response
        yield from self.writer.run(json.dumps(writer_input, indent=4), stream=True)
        # Save the blog post in the cache
        self._add_blog_post_to_cache(topic, self.writer.run_response.content)
```

5. Run the workflow

```python blog_post_generator.py
import json
from typing import Optional, Iterator

from pydantic import BaseModel, Field

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.workflow import Workflow, RunResponse, RunEvent
from agno.storage.workflow.sqlite import SqliteWorkflowStorage
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.utils.pprint import pprint_run_response
from agno.utils.log import logger

class NewsArticle(BaseModel):
    title: str = Field(..., description="Title of the article.")
    url: str = Field(..., description="Link to the article.")
    summary: Optional[str] = Field(..., description="Summary of the article if available.")

class SearchResults(BaseModel):
    articles: list[NewsArticle]

class BlogPostGenerator(Workflow):
    # Define an Agent that will search the web for a topic
    searcher: Agent = Agent(
        model=OpenAIChat(id="gpt-4o-mini"),
        tools=[DuckDuckGoTools()],
        instructions=["Given a topic, search for the top 5 articles."],
        response_model=SearchResults,
        structured_outputs=True,
    )

    # Define an Agent that will write the blog post
    writer: Agent = Agent(
        model=OpenAIChat(id="gpt-4o"),
        instructions=[
            "You will be provided with a topic and a list of top articles on that topic.",
            "Carefully read each article and generate a New York Times worthy blog post on that topic.",
            "Break the blog post into sections and provide key takeaways at the end.",
            "Make sure the title is catchy and engaging.",
            "Always provide sources, do not make up information or sources.",
        ],
        markdown=True,
    )

    def run(self, topic: str, use_cache: bool = True) -> Iterator[RunResponse]:
        """This is where the main logic of the workflow is implemented."""

        logger.info(f"Generating a blog post on: {topic}")

        # Step 1: Use the cached blog post if use_cache is True
        if use_cache:
            cached_blog_post = self._get_cached_blog_post(topic)
            if cached_blog_post:
                yield RunResponse(content=cached_blog_post, event=RunEvent.workflow_completed)
                return

        # Step 2: Search the web for articles on the topic
        search_results: Optional[SearchResults] = self._get_search_results(topic)
        # If no search_results are found for the topic, end the workflow
        if search_results is None or len(search_results.articles) == 0:
            yield RunResponse(
                event=RunEvent.workflow_completed,
                content=f"Sorry, could not find any articles on the topic: {topic}",
            )
            return

        # Step 3: Write a blog post
        yield from self._write_blog_post(topic, search_results)

    def _get_cached_blog_post(self, topic: str) -> Optional[str]:
        """Get the cached blog post for a topic."""

        logger.info("Checking if cached blog post exists")
        return self.session_state.get("blog_posts", {}).get(topic)

    def _add_blog_post_to_cache(self, topic: str, blog_post: Optional[str]):
        """Add a blog post to the cache."""

        logger.info(f"Saving blog post for topic: {topic}")
        self.session_state.setdefault("blog_posts", {})
        self.session_state["blog_posts"][topic] = blog_post

    def _get_search_results(self, topic: str) -> Optional[SearchResults]:
        """Get the search results for a topic."""

        MAX_ATTEMPTS = 3

        for attempt in range(MAX_ATTEMPTS):
            try:
                searcher_response: RunResponse = self.searcher.run(topic)

                # Check if we got a valid response
                if not searcher_response or not searcher_response.content:
                    logger.warning(f"Attempt {attempt + 1}/{MAX_ATTEMPTS}: Empty searcher response")
                    continue
                # Check if the response is of the expected SearchResults type
                if not isinstance(searcher_response.content, SearchResults):
                    logger.warning(f"Attempt {attempt + 1}/{MAX_ATTEMPTS}: Invalid response type")
                    continue

                article_count = len(searcher_response.content.articles)
                logger.info(f"Found {article_count} articles on attempt {attempt + 1}")
                return searcher_response.content

            except Exception as e:
                logger.warning(f"Attempt {attempt + 1}/{MAX_ATTEMPTS} failed: {str(e)}")

        logger.error(f"Failed to get search results after {MAX_ATTEMPTS} attempts")
        return None

    def _write_blog_post(self, topic: str, search_results: SearchResults) -> Iterator[RunResponse]:
        """Write a blog post on a topic."""

        logger.info("Writing blog post")
        # Prepare the input for the writer
        writer_input = {"topic": topic, "articles": [v.model_dump() for v in search_results.articles]}
        # Run the writer and yield the response
        yield from self.writer.run(json.dumps(writer_input, indent=4), stream=True)
        # Save the blog post in the cache
        self._add_blog_post_to_cache(topic, self.writer.run_response.content)


# Run the workflow if the script is executed directly
if __name__ == "__main__":
    from rich.prompt import Prompt

    # Get topic from user
    topic = Prompt.ask(
        "[bold]Enter a blog post topic[/bold]\n✨",
        default="Why Cats Secretly Run the Internet",
    )

    # Convert the topic to a URL-safe string for use in session_id
    url_safe_topic = topic.lower().replace(" ", "-")

    # Initialize the blog post generator workflow
    # - Creates a unique session ID based on the topic
    # - Sets up SQLite storage for caching results
    generate_blog_post = BlogPostGenerator(
        session_id=f"generate-blog-post-on-{url_safe_topic}",
        storage=SqliteWorkflowStorage(
            table_name="generate_blog_post_workflows",
            db_file="tmp/workflows.db",
        ),
    )

    # Execute the workflow with caching enabled
    # Returns an iterator of RunResponse objects containing the generated content
    blog_post: Iterator[RunResponse] = generate_blog_post.run(topic=topic, use_cache=True)

    # Print the response
    pprint_run_response(blog_post, markdown=True)
```

### Run the workflow

Install libraries

```shell
pip install agno openai duckduckgo-search sqlalchemy
```

Run the workflow

```shell
python blog_post_generator.py
```

Now the results are cached in the database and can be re-used for future runs. Run the workflow again to view the cached results.

```shell
python blog_post_generator.py
```

<img height="200" src="https://mintlify.s3.us-west-1.amazonaws.com/agno/images/BlogPostGenerator.gif" style={{ borderRadius: '8px' }} />

Checkout more examples in the [examples](/examples/use-cases/advanced) section.


# Caching

**Use the `session_state` to cache intermediate results in a database.**

All Workflows come with a `session_state` dictionary that you can use to cache intermediate results. Provide your workflows with `storage` and a `session_id` to enable caching.

For example, you can use the `SqliteWorkflowStorage` to cache results in a Sqlite database.

```python
# Create the workflow
generate_blog_post = BlogPostGenerator(
    session_id="my-session-id",
    storage=SqliteWorkflowStorage(
        table_name="generate_blog_post_workflows",
        db_file="tmp/workflows.db",
    ),
)
```

Then in the `run()` method, you can read from and add to the `session_state` as needed.

```python

class BlogPostGenerator(Workflow):
    # ... agents
    def run(self, topic: str, use_cache: bool = True) -> Iterator[RunResponse]:
        # Read from the session state cache
        if use_cache and "blog_posts" in self.session_state:
            logger.info("Checking if cached blog post exists")
            for cached_blog_post in self.session_state["blog_posts"]:
                if cached_blog_post["topic"] == topic:
                    logger.info("Found cached blog post")
                    yield RunResponse(
                        run_id=self.run_id,
                        event=RunEvent.workflow_completed,
                        content=cached_blog_post["blog_post"],
                    )
                    return

        # ... generate the blog post

        # Save to session state for future runs
        if "blog_posts" not in self.session_state:
            self.session_state["blog_posts"] = []
        self.session_state["blog_posts"].append({"topic": topic, "blog_post": self.writer.run_response.content})
```

When the workflow starts, the `session_state` for that particular `session_id` is read from the database and when the workflow ends, the `session_state` is stored in the database.

<Tip>
  You can always call `self.write_to_storage()` to save the `session_state` to the database at any time. Incase you need to abort the workflow but want to store the intermediate results.
</Tip>

View the [Blog Post Generator](/workflows/introduction#full-example-blog-post-generator) for an example of how to use session state for caching.


# MongoDB Workflow Storage



Agno supports using MongoDB as a storage backend for Workflows using the `MongoDbWorkflowStorage` class.

## Usage

### Run MongoDB

Install [docker desktop](https://docs.docker.com/desktop/install/mac-install/) and run **MongoDB** on port **27017** using:

```bash
docker run --name mongodb -d -p 27017:27017 mongodb/mongodb-community-server:latest
```

```python storage.py

import json
from typing import Iterator

import httpx
from agno.agent import Agent, RunResponse
from agno.tools.newspaper4k import Newspaper4kTools
from agno.storage.workflow.mongodb import MongoDbWorkflowStorage
from agno.utils.log import logger
from agno.utils.pprint import pprint_run_response
from agno.workflow import Workflow

class HackerNewsReporter(Workflow):
    description: str = (
        "Get the top stories from Hacker News and write a report on them."
    )

    hn_agent: Agent = Agent(
        description="Get the top stories from hackernews. "
        "Share all possible information, including url, score, title and summary if available.",
        show_tool_calls=True,
    )

    writer: Agent = Agent(
        tools=[Newspaper4kTools()],
        description="Write an engaging report on the top stories from hackernews.",
        instructions=[
            "You will be provided with top stories and their links.",
            "Carefully read each article and think about the contents",
            "Then generate a final New York Times worthy article",
            "Break the article into sections and provide key takeaways at the end.",
            "Make sure the title is catchy and engaging.",
            "Share score, title, url and summary of every article.",
            "Give the section relevant titles and provide details/facts/processes in each section."
            "Ignore articles that you cannot read or understand.",
            "REMEMBER: you are writing for the New York Times, so the quality of the article is important.",
        ],
    )

    def get_top_hackernews_stories(self, num_stories: int = 10) -> str:
        """Use this function to get top stories from Hacker News.

        Args:
            num_stories (int): Number of stories to return. Defaults to 10.

        Returns:
            str: JSON string of top stories.
        """

        # Fetch top story IDs
        response = httpx.get("https://hacker-news.firebaseio.com/v0/topstories.json")
        story_ids = response.json()

        # Fetch story details
        stories = []
        for story_id in story_ids[:num_stories]:
            story_response = httpx.get(
                f"https://hacker-news.firebaseio.com/v0/item/{story_id}.json"
            )
            story = story_response.json()
            story["username"] = story["by"]
            stories.append(story)
        return json.dumps(stories)

    def run(self, num_stories: int = 5) -> Iterator[RunResponse]:
        # Set the tools for hn_agent here to avoid circular reference
        self.hn_agent.tools = [self.get_top_hackernews_stories]

        logger.info(f"Getting top {num_stories} stories from HackerNews.")
        top_stories: RunResponse = self.hn_agent.run(num_stories=num_stories)
        if top_stories is None or not top_stories.content:
            yield RunResponse(
                run_id=self.run_id, content="Sorry, could not get the top stories."
            )
            return

        logger.info("Reading each story and writing a report.")
        yield from self.writer.run(top_stories.content, stream=True)

# Run workflow
report: Iterator[RunResponse] = HackerNewsReporter(
        storage=MongoDbWorkflowStorage(
            collection_name="hacker_news_report",
            db_url="mongodb://localhost:27017",
        )).run(num_stories=5)

# Print the report
pprint_run_response(report, markdown=True, show_time=True)
```

## Params

<Snippet file="workflow-storage-mongodb-params.mdx" />


# Postgres Workflow Storage



Agno supports using PostgreSQL as a storage backend for Workflows using the `PostgresWorkflowStorage` class.

## Usage

### Run PgVector

Install [docker desktop](https://docs.docker.com/desktop/install/mac-install/) and run **PgVector** on port **5532** using:

```bash
docker run -d \
  -e POSTGRES_DB=ai \
  -e POSTGRES_USER=ai \
  -e POSTGRES_PASSWORD=ai \
  -e PGDATA=/var/lib/postgresql/data/pgdata \
  -v pgvolume:/var/lib/postgresql/data \
  -p 5532:5432 \
  --name pgvector \
  agno/pgvector:16
```

```python storage.py

import json
from typing import Iterator

import httpx
from agno.agent import Agent, RunResponse
from agno.tools.newspaper4k import Newspaper4kTools
from agno.storage.workflow.postgres import PostgresWorkflowStorage
from agno.utils.log import logger
from agno.utils.pprint import pprint_run_response
from agno.workflow import Workflow

class HackerNewsReporter(Workflow):
    description: str = (
        "Get the top stories from Hacker News and write a report on them."
    )

    hn_agent: Agent = Agent(
        description="Get the top stories from hackernews. "
        "Share all possible information, including url, score, title and summary if available.",
        show_tool_calls=True,
    )

    writer: Agent = Agent(
        tools=[Newspaper4kTools()],
        description="Write an engaging report on the top stories from hackernews.",
        instructions=[
            "You will be provided with top stories and their links.",
            "Carefully read each article and think about the contents",
            "Then generate a final New York Times worthy article",
            "Break the article into sections and provide key takeaways at the end.",
            "Make sure the title is catchy and engaging.",
            "Share score, title, url and summary of every article.",
            "Give the section relevant titles and provide details/facts/processes in each section."
            "Ignore articles that you cannot read or understand.",
            "REMEMBER: you are writing for the New York Times, so the quality of the article is important.",
        ],
    )

    def get_top_hackernews_stories(self, num_stories: int = 10) -> str:
        """Use this function to get top stories from Hacker News.

        Args:
            num_stories (int): Number of stories to return. Defaults to 10.

        Returns:
            str: JSON string of top stories.
        """

        # Fetch top story IDs
        response = httpx.get("https://hacker-news.firebaseio.com/v0/topstories.json")
        story_ids = response.json()

        # Fetch story details
        stories = []
        for story_id in story_ids[:num_stories]:
            story_response = httpx.get(
                f"https://hacker-news.firebaseio.com/v0/item/{story_id}.json"
            )
            story = story_response.json()
            story["username"] = story["by"]
            stories.append(story)
        return json.dumps(stories)

    def run(self, num_stories: int = 5) -> Iterator[RunResponse]:
        # Set the tools for hn_agent here to avoid circular reference
        self.hn_agent.tools = [self.get_top_hackernews_stories]

        logger.info(f"Getting top {num_stories} stories from HackerNews.")
        top_stories: RunResponse = self.hn_agent.run(num_stories=num_stories)
        if top_stories is None or not top_stories.content:
            yield RunResponse(
                run_id=self.run_id, content="Sorry, could not get the top stories."
            )
            return

        logger.info("Reading each story and writing a report.")
        yield from self.writer.run(top_stories.content, stream=True)

# Run workflow
report: Iterator[RunResponse] = HackerNewsReporter(
        storage=PostgresWorkflowStorage(
            table_name="hacker_news_report",
            db_url="postgresql+psycopg://ai:ai@localhost:5532/ai",
        )).run(num_stories=5)

# Print the report
pprint_run_response(report, markdown=True, show_time=True)
```

## Params

<Snippet file="workflow-storage-postgres-params.mdx" />


# SQLite Workflow Storage



Agno supports using SQLite as a storage backend for Workflows using the `SqliteWorkflowStorage` class.

## Usage

```python storage.py

import json
from typing import Iterator

import httpx
from agno.agent import Agent, RunResponse
from agno.tools.newspaper4k import Newspaper4kTools
from agno.storage.workflow.sqlite import SqliteWorkflowStorage
from agno.utils.log import logger
from agno.utils.pprint import pprint_run_response
from agno.workflow import Workflow

class HackerNewsReporter(Workflow):
    description: str = (
        "Get the top stories from Hacker News and write a report on them."
    )

    hn_agent: Agent = Agent(
        description="Get the top stories from hackernews. "
        "Share all possible information, including url, score, title and summary if available.",
        show_tool_calls=True,
    )

    writer: Agent = Agent(
        tools=[Newspaper4kTools()],
        description="Write an engaging report on the top stories from hackernews.",
        instructions=[
            "You will be provided with top stories and their links.",
            "Carefully read each article and think about the contents",
            "Then generate a final New York Times worthy article",
            "Break the article into sections and provide key takeaways at the end.",
            "Make sure the title is catchy and engaging.",
            "Share score, title, url and summary of every article.",
            "Give the section relevant titles and provide details/facts/processes in each section."
            "Ignore articles that you cannot read or understand.",
            "REMEMBER: you are writing for the New York Times, so the quality of the article is important.",
        ],
    )

    def get_top_hackernews_stories(self, num_stories: int = 10) -> str:
        """Use this function to get top stories from Hacker News.

        Args:
            num_stories (int): Number of stories to return. Defaults to 10.

        Returns:
            str: JSON string of top stories.
        """

        # Fetch top story IDs
        response = httpx.get("https://hacker-news.firebaseio.com/v0/topstories.json")
        story_ids = response.json()

        # Fetch story details
        stories = []
        for story_id in story_ids[:num_stories]:
            story_response = httpx.get(
                f"https://hacker-news.firebaseio.com/v0/item/{story_id}.json"
            )
            story = story_response.json()
            story["username"] = story["by"]
            stories.append(story)
        return json.dumps(stories)

    def run(self, num_stories: int = 5) -> Iterator[RunResponse]:
        # Set the tools for hn_agent here to avoid circular reference
        self.hn_agent.tools = [self.get_top_hackernews_stories]

        logger.info(f"Getting top {num_stories} stories from HackerNews.")
        top_stories: RunResponse = self.hn_agent.run(num_stories=num_stories)
        if top_stories is None or not top_stories.content:
            yield RunResponse(
                run_id=self.run_id, content="Sorry, could not get the top stories."
            )
            return

        logger.info("Reading each story and writing a report.")
        yield from self.writer.run(top_stories.content, stream=True)

# Run workflow
report: Iterator[RunResponse] = HackerNewsReporter(
        storage=SqliteWorkflowStorage(
            table_name="hacker_news_report",
            db_file="tmp/workflows.db",
        )).run(num_stories=5)

# Print the report
pprint_run_response(report, markdown=True, show_time=True)
```

## Params

<Snippet file="workflow-storage-sqlite-params.mdx" />


